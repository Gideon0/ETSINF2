ractales
Manuel Alfaro A.
Manuel Murillo T.
Alberto Soto A.

k
Revista Digital MatemÃ¡tica EducaciÃ³n e Internet (www.cidse.itcr.ac.cr/revistamate)
Instituto TecnolÃ³gico de Costa Rica, 2010

FRACTALES

Manuel Alfaro A.
Escuela de MatemÃ¡tica
Instituto TecnolÃ³gico de Costa Rica.

Manuel Murillo T.
Escuela de MatemÃ¡tica
Instituto TecnolÃ³gico de Costa Rica
Universidad Estatal a Distancia.

Alberto Soto A.
Escuela de MatemÃ¡tica
Universidad Estatal a Distancia.

ii

c
Derechos Reservados 
Primera EdiciÃ³n.
Revista digital, MatemÃ¡tica, EducaciÃ³n e Internet (www.cidse.itcr.ac.cr/revistamate/), 2010.
Correo ElectrÃ³nico: wmora2@itcr.ac.cr
Escuela de MatemÃ¡tica
Instituto TecnolÃ³gico de Costa Rica
Apdo. 159-7050, Cartago
TelÃ©fono (506)25502225
Fax (506)25502493

Manuel Alfaro A.,
Fractales / Manuel Alfaro A., Manuel Murillo T. y Alberto Soto A. â€“ 1 ed.
â€“ Escuela de MatemÃ¡tica,Instituto TecnolÃ³gico de Costa Rica. 2010.
82 p.
ISBN 978-9968-641-03-6
1. Fractal 2. Atractor 3. Grafos 4. Espacios mÃ©tricos 5. Medida Hausdorff 6. Enteros gaussianos
7.DimensiÃ³n 8. Conjuntos de Cantor 9. DimensiÃ³n fractal 10. DimensiÃ³n topolÃ³gica

LÃ­mite de responsabilidad y exenciÃ³n de garantÃ­a: El autor o los autores han hecho su mejor esfuerzo en la preparaciÃ³n de este material. Esta
ediciÃ³n se proporciona â€œtal cualâ€. Se distribuye gratuitamente con la esperanza de que sea Ãºtil, pero sin ninguna garantÃ­a expresa o implÃ­cita
respecto a la exactitud o completitud del contenido.
La Revista digital MatemÃ¡ticas, EducaciÃ³n e Internet es una publicaciÃ³n electrÃ³nica. El material publicado en ella expresa la opiniÃ³n de sus
autores y no necesariamente la opiniÃ³n de la revista ni la del Instituto TecnolÃ³gico de Costa Rica.

Este libro se distribuye bajo la licencia: Creative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported License. Esta licencia permite copiado y distribuciÃ³n gratuita, pero no permite venta ni modificaciones de este material.
Ver http://creativecommons.org/about/licenses/.

Prefacio

Esta obra estÃ¡ dirigida, principalmente, a estudiantes de MatemÃ¡tica y de ComputaciÃ³n, sin embargo, estÃ¡ dirigida tambiÃ©n a todas aquellas personas que encuentran en las matemÃ¡ticas el lenguaje universal con el cual se pueden explicar los fenÃ³menos en nuestro entorno y, por supuesto, a
todos los que ven en ella una puerta que los llevarÃ¡ hacia la bÃºsqueda del conocimiento orientado
al desarrollo cientÃ­fico y tecnolÃ³gico.
Se pretende introducir, con un nivel intermedio, el tema de los fractales. Nos interesa rescatar su
desarrollo matemÃ¡tico: topologÃ­a, teorÃ­a de la medida y geometrÃ­a, sin olvidar la parte visual y las
hermosas imÃ¡genes generadas por computadora que tienen estos conjuntos.
Los fractales constituyen un tema matemÃ¡tico de actualidad y se han convertido en algo muy
popular en los Ãºltimos aÃ±os. Las figuras fractales se obtienen de repetir una y otra vez el mismo
procedimiento, en forma recursiva o bien iterada, tÃ­picamente un fractal es algo irregular, pero lo
mÃ¡s importante es que si lo ampliamos arbitrariamente, Ã©l aÃºn sigue irregular.
Para nosotros, los fractales serÃ¡n en general figuras geomÃ©tricas que se caracterizan por su autosemejanza sin embargo existen otros, como la frontera del conjunto de Mandelbrot, que son fractales
no autosemejantes. Son estructuras infinitas contenidas en una superficie finita y resultan de utilidad en el anÃ¡lisis de una gran diversidad de fenÃ³menos como turbulencias, bolsa de valores,
dispersiÃ³n del humo, etc., ademÃ¡s de sintetizar imÃ¡genes como montaÃ±as, nubes, costas rocosas,
rÃ­os y plantas entre otras.
En el CapÃ­tulo 1 se introducen los sistemas iterados de funciones y se muestran algunos ejemplos
de sus atractores como el conjunto de Cantor, el triÃ¡ngulo de SierpinÌski y el dragÃ³n de Heighway y
se define la dimensiÃ³n de semejanza. TambiÃ©n formaliza propiedades de estos conjuntos y detalles
importantes.
En el CapÃ­tulo 2 se representan nÃºmeros complejos usando bases complejas, se discute sobre â€œbuenas" bases y â€œmalas" bases. Se obtienen las figuras de conjuntos de fracciones de nÃºmeros representables en estas bases y se describen propiedades topolÃ³gicas de ellos.
En el CapÃ­tulo 3 se define las dimensiones topolÃ³gica y Hausdorff, cuando la dimensiÃ³n topolÃ³gica
es menor se define un fractal en el sentido original de Mandelbrot. Se trabaja con ejemplos de cÃ³mo
calcular las dimensiones involucradas. Se exhiben otros tipos de dimensiÃ³n fractal y se notan las
similitudes que hay entre ellas.
En el CapÃ­tulo 4 se presentan algunas aplicaciones interesantes, como son la compresiÃ³n de imÃ¡genes, los dilemas espaciales de evoluciÃ³n, asÃ­ como el crecimiento fractal y el modelo D.L.A.
En el ApÃ©ndice A se presentan algunos de los programas computacionales que se han utilizado
para implementar los algoritmos dados y generar las figuras o grÃ¡ficos que se presentan.
Finalmente, la bibliografÃ­a es extensa y los libros, artÃ­culos asÃ­ como los dominios en internet que
se incluyen, le puede servir a los lectores para profundizar en los temas aquÃ­ tratados.

M. ALFARO, M. MURILLO, A. SOTO
San JosÃ©, Costa Rica
2008

iii

Lista de SÃ­mbolos

(S, Ï), ( T, Ï„ ), . . .
( r1 , r2 , . . . , r n )
( f1, f2 , . . . , f n )
Nr ( A)
L( A)

denotan espacios mÃ©tricos
lista de razones
lista de semejanzas
r-vecindario de A
medida de A en el sentido de Lebesgue
C conjunto de Cantor clÃ¡sico
Î“Î± otros conjuntos de Cantor
â„µ0 cardinalidad de
â„µ1 cardinalidad de
(
E Ï‰ ) conjunto de las palabras infinitas
(V, E, i, t, r ) grafo de Mauldin-Williams
R( A) radio espectral de A
dim( F ) dimensiÃ³n fractal

N
R

Contenido

Prefacio

iii

1

1

Autosemejanza
1.1
1.2
1.3
1.4
1.5

2

3

4

Sistemas iterados de funciones
MÃ©trica Hausdorff
Atractores para sistemas iterados de funciones
Espacios de hileras
Grafos

1
2
5
16
19

Sistemas de numeraciÃ³n

26

2.1
2.2
2.3
2.4

26
27
28
30

Bases para nÃºmeros reales
Bases para nÃºmeros complejos
RepresentaciÃ³n de los enteros Gaussianos
Ejemplos de conjuntos de fracciones

DimensiÃ³n Hausdorff

33

3.1
3.2
3.3
3.4
3.5
3.6

33
34
36
39
42
47

DimensiÃ³n topolÃ³gica
GeneraciÃ³n de medidas
Medida Hausdorff
DimensiÃ³n de semejanza vs dimensiÃ³n Hausdorff
DimensiÃ³n Hausdorff vs dimensiÃ³n del grafo
Otras dimensiones fractales

Aplicaciones

50

4.1

50
51
56
57
59
60
61
62
65
66
67
68
70
72

4.2

4.3

Los dilemas espaciales de evoluciÃ³n
4.1.1
Dilema del Prisionero
4.1.2
La invasiÃ³n de delatores: Un caleidoscopio evolutivo.
4.1.3
Un fractal dinÃ¡mico
4.1.4
Conclusiones
CompresiÃ³n de imÃ¡genes
4.2.1
Comprimiendo imÃ¡genes con IFSâ€™s
4.2.2
Descomprimiendo imÃ¡genes con IFSâ€™s.
4.2.3
MÃ©todos de particiÃ³n de imÃ¡genes
4.2.4
Conclusiones
Crecimiento Fractal y el modelo D.L.A.
4.3.1
Procesos de crecimiento fractal.
4.3.2
Simulaciones de algunos procesos de crecimiento.
4.3.3
Estimando la dimensiÃ³n fractal.

v

1

4.3.4

Conclusiones

74

ApÃ©ndice A: Programas
A.1
Mathematica
A.2
Logo
A.3
DraTEX
BibliografÃ­a

75
75
79
81
83

BibliografÃ­a

83

Indice AnalÃ­tico

85

Sobre los autores

87

1

AUTOSEMEJANZA

En esta secciÃ³n se introduce el concepto de autosemejanza de un conjunto, que se formaliza usando
sistemas iterados de funciones, se define el atractor para un sistema y su dimensiÃ³n de semejanza.
Se presentan algunos conjuntos clÃ¡sicos, se muestra que cada uno de ellos es el atractor para un
sistema iterado de funciones y algunas propiedades de estos conjuntos que van a ser de utilidad a
lo largo de este trabajo. Se identifica E(Ï‰ ), el espacio de hileras infinitas, con algÃºn atractor de un
sistema iterado de funciones en n .

R

1.1

Sistemas iterados de funciones

Una de las formas mÃ¡s populares para generar fractales es utilizar el concepto de los sistemas
iterados de funciones, que introdujo Michael Barnsley en el aÃ±o de 1985, dado que estos conjuntos presentan autosemejanza, es decir, el conjunto se puede descomponer en un nÃºmero finito de
partes de modo que una de ellas es idÃ©ntica, salvo escala, al todo. Para definir formalmente autosemejanza de conjuntos, se darÃ¡n algunas definiciones bÃ¡sicas.
Una funciÃ³n f : S â†’ T con (S, Ï) y ( T, Ï„ ) espacios mÃ©tricos, cumple
con la condiciÃ³n de HÃ¶lder de exponente Î± si existe una constante
c > 0 tal que para x, y âˆˆ S se cumple
Ï„ ( f ( x ), f (y)) â‰¤ cÏ( x, y)Î±

(1.1)

Si Î± = 1 se dice de Lipschitz, o de crecimiento acotado. Si cumple
con
Ï„ ( f ( x ), f (y)) â‰¥ cÏ( x, y)

(1.2)

se llama de decrecimiento acotado. Cuando cumple con ser de crecimiento acotado y de decrecimiento acotado se llama distorsiÃ³n acotada.

Una funciÃ³n f : S â†’ T con (S, Ï) y ( T, Ï„ ) espacios mÃ©tricos, es una
semejanza de razÃ³n r, con r > 0, si cumple
Ï„ ( f ( x ), f (y)) = rÏ( x, y)

(1.3)

âˆ€ x, y âˆˆ S.

tambiÃ©n se le conoce como aplicaciÃ³n afÃ­n de razÃ³n r.
Es claro que cuando una funciÃ³n cumple con la condiciÃ³n de HÃ¶lder con Î± > 0, es continua,
ademÃ¡s cuando es una distorsiÃ³n acotada es un homeomorfismo. La continuidad no se asegura
cuando solo es de decrecimiento acotado. Toda semejanza es una distorsiÃ³n acotada. Se pueden
describir las semejanzas de 2 en 2 como traslaciones, rotaciones, reflexiones o composiciones
de estos tres tipos de transformaciones.

R

R

Una lista finita de razones es una n-tupla ordenada (r1 , r2 , . . . , rn )
de nÃºmeros positivos; la lista se llama contractiva cuando ri < 1,
âˆ€i = 1, . . . , n. Un sistema iterado de funciones en un espacio
mÃ©trico S que realiza una lista de razones, es una lista ( f 1 , f 2 , . . . , f n )
de semejanzas de razÃ³n ri res-pectivamente. Un conjunto compacto no
vacÃ­o K âŠ† S es un conjunto invariante del sistema iterado de funciones ( f 1 , f 2 , . . . , f n ) si y solo si
K=

n
[

f i [ K ].

i =1

en este caso se dice que K es autosemejante.
Teorema 1. Sea (r1 , r2 , Â· Â· Â· , rn ) una lista contractiva de razones. Entonces existe un Ãºnico nÃºmero no neg-

ativo s que satisface âˆ‘ni=1 ris = 1. El nÃºmero s es 0 si y solo si n = 1.

dÏ†

DemostraciÃ³n. Sea n â‰¥ 1 y defina Ï†( x ) = âˆ‘ni=1 rix , esta funciÃ³n es continua, derivable y dx =
âˆ‘ni=1 rix ln(ri ); esta derivada es negativa por lo que Ï†( x ) es estrictamente decreciente y como Ï†(0) =
n y limx â†’âˆ Ï†( x ) = 0, por continuidad existe un s > 0 tal que Ï†(s) = 1.

La dimensiÃ³n asociada a (r1 , r2 , . . . , rn ), una lista contractiva de razones, es el nÃºmero positivo s tal que
r1s + r2s + Â· Â· Â· + rns = 1
y se denomina dimensiÃ³n de semejanza.

1.2

MÃ©trica Hausdorff

Felix Hausdorff describe la convergencia de conjuntos definiendo una distancia entre los mismos
que no requiere encontrar parametrizaciones de ellos, lo cual para nuestros propÃ³sitos es conveniente, ya que se desea analizar la convergencia de sucesiones de compactos en un espacio mÃ©trico
completo. AquÃ­ L denota la medida en el sentido de Lebesgue en y Ld la correspondiente para
d.

R
2

R

3

Sean A, B âŠ† S acotados, de un espacio mÃ©trico (S, Ï) y sea r > 0. Se
define un r-vecindario o cuerpo r-paralelo de A por
Nr ( A) = {y âˆˆ S : Ï( x, y) â‰¤ r para algÃºn x âˆˆ A}
Se define la funciÃ³n sobre subconjuntos acotados de S, D ( A, B) como:
D ( A, B) = inf{r : A âŠ† Nr ( B) y B âŠ† Nr ( A)}

Esta funciÃ³n no define una mÃ©trica para los subconjuntos acotados de S, pero si se restringe al
conjunto de los subconjuntos compactos de S no vacÃ­os, K(S), sÃ­ lo es. En este caso D se llama la
mÃ©trica Hausdorff.
Teorema 2. Sea S un espacio mÃ©trico, entonces D ( A, B ) es una mÃ©trica sobre K( S). AdemÃ¡s si S es completo

K(S) es tambiÃ©n completo.

DemostraciÃ³n. VÃ©ase [9, p. 66-67].



Ahora recordemos el teorema de la aplicaciÃ³n contractiva. Este dice que si f : S â†’ S es una aplicaciÃ³n contractiva y S es un espacio mÃ©trico completo existe un Ãºnico punto fijo de f , x âˆˆ S que se
puede encontrar a partir de la sucesiÃ³n:
x0
xn

(1.4)

= aâˆˆS

=

f ( xnâˆ’1 ), n â‰¥ 1.

(1.5)

Esto serÃ¡ especialmente Ãºtil para el siguiente teorema.
Teorema 3. Sea ( S, Ï ) un espacio mÃ©trico completo, sea (r1 , r2 , Â· Â· Â· , rn ) una lista de razones contractiva, y

sea ( f 1 , f 2 , Â· Â· Â· , f n ) un sistema iterado de funciones en S que realiza esta lista de razones. Entonces existe
un Ãºnico conjunto compacto no vacÃ­o, invariante para el sistema iterado de funciones.
DemostraciÃ³n. Sea F : K(S) â†’ K(S) definida por
F ( A) =

n
[

f i [ A]

i =1

Entonces como A es compacto, f i [ A] tambiÃ©n lo es. AsÃ­ F ( A) es la uniÃ³n finita de compactos, que
es compacta. Defina r = mÃ­n{r1 , r2 , . . . , rn }, claramente 0 < r < 1, para usar el teorema del punto
fijo necesitamos demostrar que F es contractiva. Sea B âˆˆ K(S) y sea q > D ( A, B) arbitrario y sea
x âˆˆ F ( A). Entonces para algÃºn i tenemos x = f i ( a) con a âˆˆ A; existe b âˆˆ B tal que Ï( a, b) < q
pues q > D ( A, B) entonces Ï( f i ( a), f i (b)) = ri Ï( a, b) < rq de donde F ( A) âŠ† Nrq ( F ( B)). De forma
similar se obtiene F ( B) âŠ† Nrq ( F ( A)), y D ( F ( A), F ( B)) < rq entonces D ( F ( A), F ( B)) < rD ( A, B)
asÃ­ F es contractiva y utilizando el teorema del punto fijo existe un Ãºnico conjunto compacto no
vacÃ­o invariante.

La unicidad del punto fijo hace que no importe el conjunto de K(S) que se elija para construir una
sucesiÃ³n, el lÃ­mite es siempre el mismo.
Corolario 1. En la notaciÃ³n del teorema anterior, si A0 es cualquier conjunto compacto no vacÃ­o en S, y si
Sn

Ak+1 = i=1 f i [ Ak ], para k â‰¥ 0, entonces la sucesiÃ³n ( Ak ) converge en la mÃ©trica Hausdorff al conjunto
invariante del sistema iterado de funciones.

4

AUTOSEMEJANZA

El conjunto invariante de un sistema iterado de funciones contractivo
es llamado el atractor del sistema. En este caso se define la dimensiÃ³n
de semejanza del atractor como la dimensiÃ³n s asociada a la lista de
razones.
Esta dimensiÃ³n para el atractor es dependiente del sistema de funciones, por ejemplo, dado el

 

intervalo [0, 1] y dos semejanzas de razÃ³n 12 que apliquen [0, 1] a los intervalos 0, 12 y 12 , 1 respectivamente, es claro que la dimensiÃ³n de semejanza es 1. Ahora considere otras semejanzas de

 

razÃ³n 34 que apliquen [0, 1] a los intervalos 0, 34 y 14 , 1 . Al calcular la dimensiÃ³n de semejanza se
n
obtiene un nÃºmero mayor que 1, es mÃ¡s, si se toman dos semejanzas de razÃ³n n+
1 que apliquen




1
n
[0, 1] a los intervalos 0, n+1 y n+1 , 1 se observa que la dimensiÃ³n de semejanza aumenta conforme n crece, esto se debe a que el traslape es muy grande. En el teorema 5 se da una condiciÃ³n
sobre las intersecciones de las imÃ¡genes para evitar esta situaciÃ³n. Algo similar se hace en 3.4.
ProposiciÃ³n 1. Sea S un espacio mÃ©trico completo, (r1 , r2 , Â· Â· Â· , rn ) una lista contractiva de razones, y sea

( f 1 , f 2 , Â· Â· Â· , f n ) un sistema iterado de funciones sobre S que realizan esta lista de razones. Para la sucesiÃ³n
( xm ) definida por: x0 = a, xm = f k j ( xmâˆ’1 ) con k j âˆˆ {1, 2, . . . , n} para m â‰¥ 1, se tiene que
1. Todo punto de acumulaciÃ³n de la sucesiÃ³n ( xm ) pertenece al atractor K del sistema.

2. Todo punto de K es un punto lÃ­mite para alguna sucesiÃ³n de ( xm ) en S.
S
DemostraciÃ³n. Defina A0 = { a} y Ak+1 = ni=1 f i [ Ak ] esta sucesiÃ³n converge por el corolario 1 al
atractor K del sistema y cumple que xm âˆˆ Am para cualquier sucesiÃ³n que se elija. Para probar (1),
dado Îµ > 0 y sea y un punto de acumulaciÃ³n de la sucesiÃ³n ( xm ). Entonces existe N âˆˆ
tal que
D ( Am , K ) < Îµ/2, para todo m â‰¥ N. Como xm âˆˆ Am existe k xm âˆˆ K tal que Ï( xm , k xm ) < Îµ/2, para
este N existe l â‰¥ N tal que Ï( xl , y) < Îµ/2, asÃ­ Ï(k xl , y) â‰¤ Ï( xl , y) + Ï(k xl , xl ) < Îµ, por lo que y es un
punto de acumulaciÃ³n de K, y como K es compacto, y âˆˆ K. Para la parte (2), defina el conjunto

N

A = { x : existe ( xm ) con xm âˆˆ Am , tal que xm â†’ x },
probaremos que A = K. De (1) se tiene que A âŠ† K, y para la otra inclusiÃ³n basta ver que para todo
x âˆˆ K existe xm âˆˆ Am tal que Ï( xm , x ) < D ( Am , A) + m1 lo que implica que xm â†’ x.

Teorema 4. Sea A âŠ†

Rd un conjunto medible en el sentido de Lebesgue, y sea f : Rd â†’ Rd una semejanza

con razÃ³n r, entonces, f [ A] es medible en el sentido de Lebesgue y Ld ( f [ A]) = r d Ld ( A).
DemostraciÃ³n. [19, p. 64].



El siguiente teorema se usa para ver cÃ³mo se utiliza la teorÃ­a de la medida, en el cÃ¡lculo de la dimensiÃ³n fractal (capÃ­tulo 3) para el atractor de un sistema iterado de funciones dado, por medio de
la dimensiÃ³n de semejanza de la lista de razones. AdemÃ¡s da condiciones para calcular la dimensiÃ³n de semejanza de un atractor de una forma indirecta, en este caso la dimensiÃ³n de semejanza
es Ãºnica.
Teorema 5. Sea (r1 , r2 , Â· Â· Â· , rn ) una lista contractiva de razones y s su dimensiÃ³n. Sea ( f 1 , f 2 , Â· Â· Â· , f n ) su
correspondiente sistema iterado de funciones en d , y sea A âŠ† d un conjunto no vacÃ­o medible en el sentido
S
de Lebesgue. Suponga que Ld ( f j [ A] âˆ© f k [ A]) = 0 para j 6= k, y A = nj=1 f j [ A]. Si 0 < Ld ( A) < âˆ,
entonces s = d.
DemostraciÃ³n. Sean los conjuntos Bk definidos en forma recursiva como B1 = f 1 [ A] y Bi+1 =
S
f i+1 [ A] \ ij=1 ( Bj âˆ© f i+1 [ A]). Estos forman una familia finita y disjunta dos a dos, ademÃ¡s se tiene

R

que A =

Sn

j =1 f j [ A ]

=

Sn

R

Bj . Como Ld ( f j [ A] âˆ© f k [ A]) = 0 se tiene que Ld ( Bj ) = Ld ( f j [ A]), ahora
ï£«
ï£¶
ï£«
ï£¶

j =1

Ld ( A) = Ld ï£­

n
[

j =1

f j [ A]ï£¸ = Ld ï£­

n
[

j =1

Bj ï£¸ =

n

n

j =1

j =1

âˆ‘ Ld ( Bj ) = âˆ‘ Ld ( f j [ A])

5

y por el teorema 4 se tiene

Ld ( A) =

n

n

j =1

j =1

âˆ‘ rdj Ld ( A) = Ld ( A) âˆ‘ rdj

y como Ld ( A) es finito y diferente de cero, se obtiene 1 = âˆ‘nj=1 r dj es decir, la dimensiÃ³n de semejanza s es d.

El teorema anterior muestra que si las imÃ¡genes de cada par de semejanzas no se traslapan â€œmucho", y si la medida del atractor del sistema iterado de funciones es positiva, entonces el interior
del atractor es no vacÃ­o. Esto serÃ¡ particularmente Ãºtil para indicar cuando un atractor â€œllena a d ".

R

1.3

Atractores para sistemas iterados de funciones

En esta secciÃ³n se discute sobre tres conjuntos que son clÃ¡sicos dentro del estudio de los fractales. En primer lugar, el Conjunto de Cantor, que presentÃ³ Georg Cantor en 1883, despertÃ³ gran
polÃ©mica a finales del siglo pasado. Es un subconjunto de
que tiene propiedades analÃ­ticas y
topolÃ³gicas no intuitivas, poco usuales en subconjuntos de nÃºmeros reales, por lo que es usado
en el anÃ¡lisis para construir contraejemplos. En segundo lugar, el triÃ¡ngulo de SierpinÌski, descrito
por WacÅ‚aw SierpinÌski en 1915, cuya construcciÃ³n es similar al conjunto de Cantor y como Ã©ste, es
un fractal. Por Ãºltimo, se presenta una construcciÃ³n del dragÃ³n Heighway descubierto por John E.
Heighway en 1967. Es una curva que llena el plano y cuya frontera es un fractal. Todos se pueden
ver como atractores para sistemas iterados de funciones.

R

Los conjuntos de Cantor.. Considere el intervalo C0 = [0, 1] y divÃ­dalo en tres partes iguales. Al
remover el intervalo abierto que corresponde al tercio central, obtenemos

 

1
2
C1 = 0,
âˆª ,1
3
3
El siguiente conjunto C2 lo obtenemos removiendo el tercio central a cada intervalo de C1 , de
manera que

 
 
 

1
2 1
2 7
8
âˆª ,
âˆª ,
âˆª ,1
C2 = 0,
9
9 3
3 9
9
y siguiendo de la misma forma obtenemos una sucesiÃ³n anidada de conjuntos cerrados C0 âŠ‡ C1 âŠ‡
C2 âŠ‡ . . . cuyo lÃ­mite llamamos conjunto de Cantor Ã³ conjunto de los tercios centrales omitidos,
vÃ©ase figura 1.1, y lo denotamos por C.
C0

............................................................................................................................................................................................................................................................................................................................

C1

..........................................................................................................

..........................................................................................................

C2

....................................

....................................

....................................

....................................

C3

............

............

............

............

............

............

............

............

C4

.... ....

.... .....

.... ....

.... .....

.... ....

.... .....

.... ....

.... .....

..
.

Figura 1.1

C = limkâ†’âˆ Ck = Tâˆk=0 Ck .

ProposiciÃ³n 2. La dimensiÃ³n de semejanza de C es ln 2/ ln 3.

6

AUTOSEMEJANZA

DemostraciÃ³n. Se tiene que la construcciÃ³n anterior, conocida como construcciÃ³n por tremas1, cor2
responde a la aplicaciÃ³n del corolario 1 para A0 = C0 = [0, 1] con f 0 ( x ) = 3x y f 1 ( x ) = x +
3 ,
asÃ­, el conjunto de Cantor es el conjunto invariante para el sistema iterado de funciones ( f 0 , f 1 ),
que realizan la lista de razones (1/3, 1/3). Y resolviendo la ecuaciÃ³n ( 31 )s + ( 13 )s = 1 se obtiene el
resultado.

 k
Note que cada Ck contiene 2k intervalos cerrados, cada uno de ellos de longitud 31 , y que en
1
3,

en el segundo paso dos intervalos de
 k
longitud 91 , en general, en el k-Ã©simo removemos 2kâˆ’1 intervalos de longitud 31 . AsÃ­, la suma de

el primer paso quitamos un subintervalo de longitud

las longitudes de los intervalos que eliminamos del intervalo [0, 1] es:
1
1
1
+ 2 Â· 2 + 22 Â· 3 + Â· Â· Â·
3
3
3

=

1
3

=

1
3

!
 2
2
2
1+ +
+Â·Â·Â·
3
3
!
1
=1
1 âˆ’ 32

es decir, al conjunto inicial [0, 1], cuya longitud es 1, le hemos quitado intervalos que tienen la
misma longitud 1.
Â¿QuiÃ©n vive en C?
Vamos a determinar ahora, cuÃ¡les nÃºmeros reales pertenecen a C, es decir vamos a caracterizarlos.
En primer lugar, por la forma de construirlo, es claro que los extremos de cada intervalo de Ck
pertenecen a C, pues si un nÃºmero es extremo de algÃºn intervalo de Ck , serÃ¡ extremo de algÃºn
intervalo de Cn para cualquier n â‰¥ k, y por lo tanto estarÃ¡ en C. Por ejemplo 0, 91 , 29 , 13 , 23 , 79 , 89 , 1,
que son los extremos de los intervalos de C2 , estÃ¡n en C. Para buscar una caracterizaciÃ³n de todos
los elementos de C, representaremos los nÃºmeros en base 3 (representaciÃ³n triÃ¡dica). Recordemos
que para cualquier x âˆˆ , existe n âˆˆ y an , . . . , a0 , aâˆ’1 , . . . âˆˆ {0, 1, 2}, con an 6= 0, tales que

R

x

N

= ( a n a n âˆ’1 . . . a1 a0 , a âˆ’1 . . . ) 3

= a n Â· 3 n + Â· Â· Â· + a 1 Â· 31 + a 0 Â· 30 + a âˆ’ 1 Â· 3 âˆ’ 1 + Â· Â· Â·
NÃ³temos que la representaciÃ³n triÃ¡dica parah cualquier
x âˆˆ [0, 1] es (0, a1 a2 . h. . ak .i. . )3 , con ai âˆˆ
i
1
{0, 1, 2}, âˆ€i âˆˆ . Si a1 = 0 entonces x âˆˆ 0, 3 , si a1 = 1 entonces x âˆˆ 13 , 23 , y si a1 = 2
i
h


entonces x âˆˆ 23 , 1 . Como en el primer paso de la construcciÃ³n de C removimos 13 , 23 , cualquier
i
h
nÃºmero en C tiene una expresiÃ³n con a1 6= 1; luego si a1 âˆˆ {0, 2} y a2 = 1 entonces x âˆˆ 19 , 92 âˆª
7 8
9 , 9 , por lo que no estarÃ¡ en C2 y por consiguiente tampoco en C, o bien es un extremo de estos
subintervalos y tiene otra representaciÃ³n con a2 6= 1. AsÃ­, en el k-Ã©simo paso de la construcciÃ³n de
C quedan solamente los nÃºmeros que tengan una representaciÃ³n con a1 6= 1,. . . , ak 6= 1, de esta
forma obtenemos el siguiente resultado:

N

Teorema 6. Para x âˆˆ [0, 1]: x âˆˆ

C si y solo si se puede representar en base 3 usando solamente 0 y 2 como

dÃ­gitos.

Si se numeran los intervalos de Ck de 1 a 2 k , se puede mostrar que ak = 0 si el nÃºmero estÃ¡ en un
intervalo impar y 2 si estÃ¡ en uno par.
1 Del

latÃ­n tremissis, moneda romana que valÃ­a la tercera parte de un sÃ³lido de oro.

7
Ejemplo 1. Algunos elementos de C son:

(0, 02)3 = (0, 020202 . . . )3 = 2 Â· 3âˆ’2 + 2 Â· 3âˆ’4 + Â· Â· Â· =
(0, 022)3 = (0, 022022022 . . . )3

=

(0, 0022)3 = (0, 002200220022 . . . )3

=

(0, 20022)3 = (0, 200222002220022 . . . )3

=

1
4
4
13
1
10
85
121


Los elementos que pertenecen al conjunto C, dados en el ejemplo anterior, son todos racionales,
sin embargo, algunos elementos de este conjunto son irracionales.
Ejemplo 2. Es claro que (0, 202002000200002 . . . )3 es un nÃºmero irracional y ademÃ¡s, pertenece a

C.



Teorema 7. Si x âˆˆ

C, entonces 1 âˆ’ x, x3 , x+3 2 âˆˆ C.

DemostraciÃ³n. Como x âˆˆ C, sea x = (0, a1 a2 . . . ak . . . )3 , con ai âˆˆ {0, 2}, âˆ€i âˆˆ

N:

1. Como
1âˆ’x

âˆ

âˆ

i =1
âˆ

i =1

= 2 âˆ‘ 3âˆ’i âˆ’ âˆ‘ a i 3âˆ’i
=

âˆ‘ (2 âˆ’ a i )3âˆ’ i

i =1

y como ai âˆˆ {0, 2} entonces 2 âˆ’ ai âˆˆ {0, 2}, por lo tanto 1 âˆ’ x âˆˆ C.
2. Como
1
x
= Â·x
3
3

se tiene que

x
3

= (0, 1)3 Â· (0, a1 a2 . . . ak . . . )3
= (0, 0 a1 a2 . . . ak . . . )3

âˆˆC

3. Como
x+2
3

= (0, 1)3 Â· [(0, a1 a2 . . . ak . . . )3 + (2)3 ]

= (0, 1)3 Â· (2, a1 a2 . . . ak . . . )3 = (0, 2 a1 a2 . . . ak . . . )3
se tiene que

x +2
3

âˆˆC


Ejemplo 3. Como sabemos que 14 âˆˆ
1
12

=

1/4
3 .

C, se tiene que

3
4

âˆˆ C pues

3
4

= 1 âˆ’ 14 , ademÃ¡s,

1
12

âˆˆ C pues


8

AUTOSEMEJANZA

Cardinalidad y algunas propiedades de C
Consideremos el conjunto
A = {f :

N â†’ {0, 2}

/

f es funciÃ³n}

La cardinalidad de A es | A| = |{0, 2}||N| = 2â„µ0 = â„µ1 = | |, de manera que A es no numerable.
AdemÃ¡s, para toda f âˆˆ A, existe un Ãºnico x = (0, f (1) f (2) f (3) . . . ) tal que x âˆˆ C, es decir, existe
una biyecciÃ³n entre A y C, por lo que |C| = â„µ1 . En otras palabras, Â¡C tiene la misma cantidad de
elementos que tiene !. A pesar de esto C posee una estructura topolÃ³gica muy diferente:

R

R

1.

C es compacto: Es cerrado pues es la intersecciÃ³n numerable de conjuntos cerrados, y C es
acotado, por el teorema de Heine-Borel, es compacto.

2.

N

C no contiene ningÃºn intervalo: Suponga que I

=] a, b[âŠ† C, entonces I âŠ† Ck âˆ€k âˆˆ . Como
Ck esta formado por 2 k intervalos cerrados disjuntos, I es subconjunto de algÃºn intervalo de
 k
 k
âˆ€k âˆˆ , lo que implicarÃ­a que b = a.
tamaÃ±o 31 , por lo que b âˆ’ a â‰¤ 13

N

3.

C no tiene puntos aislados: Si x no es extremo de ningÃºn intervalo de Ck para algÃºn
  k, sea xn el
n

extremo izquierdo del intervalo de Cn que contiene a x; luego 0 < x âˆ’ xn â‰¤ 13 , por lo que
xn â†’ x. Si x es extremo izquierdo en algÃºn intervalo de Ck para algÃºn k, tome xn como el
extremo derecho de ese intervalo para n â‰¥ k y xn = 1 en otro caso; por un argumento similar,
xn â†’ x.

En suma C es un conjunto totalmente disconexo, compacto y perfecto. AdemÃ¡s es no numerable
y tiene medida cero. En general un conjunto de Cantor es un conjunto que cumple con estas tres
primeras propiedades, y se puede demostrar que todos los conjuntos de Cantor son homeomorfos.
2
Sean f 1 ( x ) = x3 y f 2 ( x ) = x +
3 con dominio y codominio igual a C; ambas funciones son inyectivas
y:






1
2
âˆ’1
âˆ’1
f1
C âˆ© 0, 3 = f2 C âˆ© 3 , 1 = C
Esto significa que si observamos solamente la mitad derecha o la mitad izquierda del conjunto de
Cantor obtenemos una copia homeomorfa de este. De manera que podemos encontrar una copia
homeomorfa del conjunto de Cantor incluida en la intersecciÃ³n de C con cualquier intervalo de Ck
(tan pequeÃ±o como queramos tomando k suficientemente grande).
GeneralizaciÃ³n de C
La construcciÃ³n de C se puede generalizar de manera evidente, quitando un subintervalo abierto
1
centrado de longitud Î±, con Î± âˆˆ ]0, 1[, y seguir con un proceso anÃ¡logo
h ali del casoÎ± =
h 3 . Por
i




4
6 2
ejemplo, para Î± = 51 se tiene C0 = [0, 1], C1 = 0, 25 âˆª 35 , 1 , C2 = 0, 25
âˆª 25
, 5 âˆª 53 , 19
25 âˆª
h
i
21
,
1
. Al conjunto lÃ­mite de esta sucesiÃ³n lo denotamos Î“ 1 , en general a conjuntos generados asÃ­
25
5

los denotamos por Î“Î± . Note que C = Î“ 1 .
3
Notemos que el tamaÃ±o de C1 es 1 âˆ’ Î± y estÃ¡ compuesto de dos intervalos cada uno de longitud
1âˆ’ Î±
=: Î²; asÃ­ cada Ck estÃ¡ compuesto por 2 k intervalos de longitud Î²k y los intervalos que re2
movemos en el kâ€“Ã©simo paso miden Î±Î²kâˆ’1 . Por ejemplo con Î² = 25 tenemos Î“ 1 y Î“ 3 se obtiene con
5

5

Î² = 15 .
Para cualquier Î± âˆˆ]0, 1[ y x en Î“Î± , definimos la direcciÃ³n de x en Î“Î± como la suceciÃ³n {s0 , s1 , s2 , . . . },
donde cada si es 0 Ã³ 1. Para saber quÃ© valor asignamos a sn basta con enumerar los intervalos de

9

Ck de 1 hasta 2 k , skâˆ’1 serÃ¡ 0 si x estÃ¡ en un intervalo impar y 1 si estÃ¡ en uno par. AsÃ­ definida la
direcciÃ³n de x en Î“Î± , es fÃ¡cil ver que este tiene representaciÃ³n Ãºnica de la forma:
âˆ

x=

âˆ‘ si Î² i (1 âˆ’ Î² )

i =0

AsÃ­ como caracterizamos los elementos de C como los nÃºmeros que se pueden representar en base
3 usando solamente 0 y 2 como dÃ­gitos, podemos caracterizar algunos Î“Î± de la siguiente manera:
Teorema 8. Si n âˆˆ

N, n â‰¥ 3 y Î² = n1 entonces
Î“Î± = {(0, a1 a2 . . . ak . . . )n /

ak âˆˆ {0, n âˆ’ 1}}

Ejemplo 4. Con n = 4 obtenemos

Î“ 1 = {(0, a1 a2 . . . ak . . . )4 /
2

AsÃ­

4
5

= (0, 30)4 âˆˆ Î“ 1 . Otros elementos de Î“ 1 son:
2

funciones: g1 ( x ) = 1 âˆ’ x, g2 ( x ) =
elementos.

x +3
4

2

y g3 ( x ) =

ak âˆˆ {0, 3}}

1
1 63
16 , 20 , 64

x
4,

y 15 . Aplicando reiteradamente las

a elementos de Î“ 1 , obtenemos otros de sus
2


25
Ejemplo 5. Con n = 5 obtenemos Î“ 3 , y algunos de sus elementos son: 61 , 56 , 29
30 y 31 .
5



Se pueden construir conjuntos de Cantor dividiendo a [0, 1] en n partes iguales y dejar algunos
subintervalos de longitud Î² = n1 (no necesariamente los intervalos laterales como en C).
Teorema 9. Sea n âˆˆ

N, n â‰¥ 3, D = {0, . . . , n âˆ’ 1} y B subconjunto propio de D con |B| â‰¥ 2, entonces
Î“nB = {(0, a1 a2 . . . ak . . . )n / ak âˆˆ B}

es un conjunto de Cantor.
En la figura 1.2, con n = 5 y B = {1, 2, 4}, se muestra Î“5{1,2,4} . Se debe notar que este conjunto estÃ¡
formado por los nÃºmeros en [0, 1] que en base 5 tienen representaciÃ³n utilizando solamente a 1, 2
y 4 como posibles dÃ­gitos.
C0
C1
C2

...............................................................................................................................................................................................................................................................................................................................................................
.............................................................................................................................................
.........................................................

.......................................................................

.............................

.............................

...............

C3

.......................

............

............ ......

............ ......

...... ...

C4

......... .....

........

........ .....

........ .....

..... ...

..
.

Figura 1.2

Î“5{1,2,4} = limkâ†’ âˆ Ck .

En general a partir de un elemento x de Î“nB se pueden obtener mÃ¡s elementos aplicando reiteradamente las funciones: f i ( x ) = x +n ai , con ai âˆˆ B.
RelaciÃ³n de C con el espacio de arreglos

R

Denotamos por E(Ï‰ ) el espacio de los arreglos infinitos de 0 y 1. Sea g : E(Ï‰ ) â†’ , que interpreta un
arreglo como un nÃºmero en base 2, cuya parte decimal es el arreglo y la parte entera es cero.

10

AUTOSEMEJANZA

Ejemplo 6. g (001) = (0, 001)2 = 17 .



Como todo nÃºmero real tiene expansiÃ³n en base 2, tenemos que g( E(Ï‰ )) = [0, 1], y si definimos
f : E(Ï‰ ) â†’ de la misma forma que g, pero cambiando los dÃ­gitos 1 por 2 y la representaciÃ³n en
base 3, tenemos que f ( E(Ï‰ ) ) = C. Es claro que f asÃ­ definida es un homeomorfismo entre E(Ï‰ ) y
C.

R

1
Ejemplo 7. f (001) = (0, 002)3 = 13
âˆˆ

C.



Un resultado muy interesante es el hecho que un conjunto cero dimensional y separable es de
Cantor si es homeomorfo a un subconjunto de E(Ï‰ ), vÃ©ase [9].
Sobre el tamaÃ±o de Î“Î±
En este momento es oportuno preguntarnos Â¿serÃ¡ Î“ 1 mÃ¡s grande que Î“ 3 ?. El siguiente grÃ¡fico
5
5
indica que la sucesiÃ³n de Ck que converge a Î“ 3 se desvanece mÃ¡s rÃ¡pido que la sucesiÃ³n que
5
converge a Î“ 1 , por lo que en algÃºn sentido Î“ 3 serÃ¡ â€œmÃ¡s pequeÃ±o" que Î“ 1 .
5

5

5

..............................................................................................................................

..............................................................................................................................

..........................

..........................

...................................................

...................................................

......

......

......

......

.....................

.....................

.....................

.....................

.. ..

....

.. ..

....

......... .........

......... .........

......... .........

......... .........

Figura 1.3 ComparaciÃ³n de Î“ 3 y Î“ 1 .
5

5

El anÃ¡lisis sobre el tamaÃ±o no es evidente ya que ambos conjuntos tienen la misma cardinalidad,
ademÃ¡s son conjuntos de medida cero. Para poder hacer alguna diferencia entre estos definimos el
conjunto:
Î“Î± âˆ’ Î“Î± = { x âˆ’ y / x, y âˆˆ Î“Î± } = {t / Î“Î± âˆ© (Î“Î± + t) 6= âˆ…}

con Î“Î± + t = { x + t / x âˆˆ Î“Î± }, que es una traslaciÃ³n de Î“Î± en [t, 1 + t], y asÃ­ Î“Î± âˆ’ Î“Î± se puede
interpretar como los tiempos donde una copia de Î“Î± interseca a Î“Î± recorriendo el eje x con velocidad constante. Con este conjunto podemos diferenciar Î“ 1 de Î“ 3 en el siguiente sentido: cuanto
5
5
mayor sea Î“Î± âˆ’ Î“Î± , significa que Î“Î± se intersecarÃ¡ durante mÃ¡s tiempo con una copia suya, por lo
que en este sentido Î“Î± serÃ¡ un conjunto mÃ¡s grande. Por ejemplo, en [25] se prueba que Î“ 3 âˆ’ Î“ 3 es
5

5

un conjunto de Cantor de medida cero, y es fÃ¡cil ver que Î“ 1 âˆ’ Î“ 1 = [âˆ’1, 1], por lo que Î“ 1 es mÃ¡s
grande que Î“ 3 . El valor Î² =
5

1
3

5

5

5

es lÃ­mite para comparar conjuntos de esta naturaleza [25], en este se

L(Î“Î± âˆ’ Î“Î± ) = 2 y si Î² < 13 , L(Î“Î± âˆ’ Î“Î± ) = 0.
âˆ—
Recordemos que en la construcciÃ³n de C removimos el tercio central a cada intervalo. Sea C =
Î“3{0,1} , cuya construcciÃ³n es anÃ¡loga a la de C pero quitando en cada paso el intervalo semiabierto,
cerrado a la derecha, correspondiente al tercer
h tercioide cada intervalo. El lector puede verificar que
âˆ—
âˆ—
C âˆ’ C = [âˆ’1, 1] mientras que C âˆ’ C = âˆ’ 12 , 12 , de donde se concluye que C es mÃ¡s grande
prueba que si Î² >

1
3,

âˆ—

que C .
Notemos que para algunos t âˆˆ [âˆ’1, 1] se tiene que Î“Î± âˆ© (Î“Î± + t) 6= âˆ…. Â¿CuÃ¡ntos elementos tiene
Î“Î± âˆ© (Î“Î± + t) dependiendo de la escogencia de t?. Un resultado muy interesante es el siguiente:


âˆš
1âˆ’ Î²
Teorema 10. Si Î² < 2 âˆ’ 1 y t n = Î²n 1+ Î² , entonces Î“Î± âˆ© ( Î“Î± + t n ) contiene exactamente 2n puntos.

DemostraciÃ³n. Sea x âˆˆ Î“Î± , entonces

âˆ

x=

âˆ‘ si Î² i (1 âˆ’ Î² )

i =0

11

y ademÃ¡s
âˆ

âˆ‘ sâ€²i Î²i (1 âˆ’ Î²)

x + tn =

i =0

con si y sâ€²i , Ãºnicos, que pertenecen a {0, 1}. Por otro lado, se tiene que
âˆ

x + tn

=

âˆ‘ si Î² i (1 âˆ’ Î² ) + Î² n

i =0
âˆ

=

=

1âˆ’Î²
1+Î²

âˆ



âˆ‘ si Î²i (1 âˆ’ Î²) + Î² n âˆ‘ (âˆ’1)i Î²i (1 âˆ’ Î²)

i =0

=



i =0

n âˆ’1

âˆ

âˆ

i =0

âˆ‘ si Î²i (1 âˆ’ Î²)+ âˆ‘ si+n Î²i+n (1 âˆ’ Î²)+ âˆ‘ (âˆ’1)i Î²i+n (1 âˆ’ Î²)

i =0

i =0

n âˆ’1

âˆ

i =0

i =0

âˆ‘ si Î²i (1 âˆ’ Î²) + âˆ‘ [sn+i + (âˆ’1)i ] Î²i+n (1 âˆ’ Î²)

Es decir, se tiene dos representaciones para x + t, sin embargo, la direcciÃ³n es Ãºnica y por lo tanto,
tenemos que sâ€²i = si para i â‰¤ n âˆ’ 1 y sâ€²i = si + (âˆ’1)iâˆ’n para i â‰¥ n. Por esto las direcciones de
los x en Î“Î± âˆ© (Î“Î± + tn ) son {s0 , s1 , . . . , snâˆ’1 , 0, 1, 0, 1, . . . } con si âˆˆ {0, 1}, âˆ€i â‰¤ n âˆ’ 1, con lo que
obtenemos 2 n puntos en esta intersecciÃ³n.

1âˆ’ Î²

Ejemplo 8. Utilizando el teorema anterior en el caso n = 0, encontramos que para t = 1+ Î² , el Ãºnico
1
1+ Î² ,

punto de intersecciÃ³n entre Î“Î± y (Î“Î± + t) es de la forma

C âˆ© C + 21




 
3
=
,
4

por ejemplo,

5
Î“1 âˆ© Î“1 +
4
4
11




=



8
11



en general se tiene que


n+1
Î“1 âˆ© Î“1 +
n
n
3n âˆ’ 1

=



2n
3n âˆ’ 1




Al aplicar el teorema 10 con n = 1 y Î± = 35 , se tiene que los conjuntos Î“ 3 y Î“ 3 +
solamente en los dos puntos

1
6

y

29
30 ,

lo cual se ilustra en la figura 1.4.

5

5

2
15

se intersecan

.............................................................................................................................................................................................................................................................
...
...
..
..
...
...
.
....................................................
.....................................................
...............................................................................................................................................................................................................................................................
..
..
...
...
.............
...........
.............
...........
.....................................................
.....................................................
..
..
...
...
... .....
... ..
... .....
... ...
...........
.............
...........
.............
..
..
...
...
..
..
.
.
... ..
.... ...
... ...
... ...
..
..
...
...

Figura 1.4


Î“3 âˆ© Î“3 +
5

5

2
15



=

n

1 29
6 , 30

o

.

Es fÃ¡cil notar que los Î“Î± son atractores para ( f 0 , f 1 ) con f 0 ( x ) = Î²x y f 1 ( x ) = Î²x + 1 âˆ’ Î² que realizan la lista de razones ( Î², Î²) por lo que otra forma de comparar su tamaÃ±o es usando la dimensiÃ³n
ln 2
de semejanza, que en este caso es s = âˆ’ ln
Î² , si Î² â†’ 0, entonces Î“Î± es mÃ¡s pequeÃ±o tambiÃ©n.

12

AUTOSEMEJANZA

TriÃ¡ngulo de SierpiÂ«ski.. El triÃ¡ngulo de SierpinÌski es un conjunto plano que puede ser obtenido
por medios iterados de muchas formas, una de ellas es generada a partir de un triÃ¡ngulo equilÃ¡tero,
removiendo una cuarta parte de la figura que queda en el paso anterior. Otra es a partir de un
conjunto compacto y tres semejanzas del plano; una variaciÃ³n de Ã©sta es usando solamente un
punto como conjunto inicial, Ã©sta construcciÃ³n presenta la ventaja de ser mÃ¡s â€œeconÃ³mica" que
otras, pues representa a este conjunto como el Ã¡mbito de una sucesiÃ³n en 2 , por lo que puede
aproximarse con la exactitud deseada por medio de un conjunto finito de puntos. No debe perderse
de vista la utilidad que esto conlleva para representar objetos un poco mÃ¡s naturales, pues este
conjunto se usa tambiÃ©n como una proyecciÃ³n en el plano de cadenas de nuclÃ©otidos en el anÃ¡lisis
de secuencias de ADN [1], dicha representaciÃ³n se llama RepresentaciÃ³n del Juego del Caos (CGR
por sus siglas en inglÃ©s) que permite una mejor comprensiÃ³n de hileras de nuclÃ©otidos de ADN.
Jeffrey en 1990 [23] afirma que este conjunto ha revelado visualmente â€œestructuras previamente
desconocidas".

R

ConstrucciÃ³n por tremas.. Sea S0 un triÃ¡ngulo equilÃ¡tero de lado 1 incluyendo su frontera. Ãšnase
los puntos medios de cada lado, de esta forma S0 queda dividido en 4 triÃ¡ngulos congruentes de
lado 12 , elimine el interior del triÃ¡ngulo central, el que estÃ¡ invertido, y sea S1 el conjunto formado.
Proceda de la misma forma con los tres triÃ¡ngulos restantes para formar a S2 . Continuando con
este proceso se obtiene una sucesiÃ³n decreciente anidada S0 âŠ‡ S1 âŠ‡ S2 Â· Â· Â· de subconjuntos del
T
plano. Al conjunto S = limnâ†’âˆ Sn = âˆ
n =0 Sn se le llama el triÃ¡ngulo de SierpinÌski.

Medida y dimensiÃ³n de S.. El triÃ¡ngulo de SierpinÌski, por ser un conjunto de Borel ya que es
compacto, es medible en el sentido de Lebesgue en 2 , pero se necesita otra medida dado que,
al calcular el Ã¡rea se obtiene poca informaciÃ³n pues se âˆš
debe calcular el lÃ­mite del Ã¡rea de Sk para

R

k â†’ âˆ. De esta forma se nota que el Ã¡rea de Sk es ( 43 )k Â· 43 cuyo lÃ­mite es 0 si k â†’ âˆ. Esto dice que
S es un conjunto de medida cero en 2 por lo que no es topolÃ³gicamente equivalente con 2 . En
la secciÃ³n 3 se verifica que su dimensiÃ³n topolÃ³gica es uno.
Para describir a S, se introduce un sistema de coordenadas en el cual un vÃ©rtice de S0 serÃ¡ el origen
y los lados de este vÃ©rtice en la parte positiva de cada eje (por supuesto el eje Y estarÃ¡ rotado 30o
a favor de las manecillas del reloj). AsÃ­, los vÃ©rtices de S0 son (0,0), (1,0) y (0,1). Como se reduce
en cada paso de la construcciÃ³n de S los lados a la mitad, serÃ¡ Ãºtil considerar las coordenadas
de los puntos ( x, y) en su expansiÃ³n en base 2, x = (0.a1 a2 Â· Â· Â· )2 y y = (0.b1 b2 Â· Â· Â· )2 con ai , bi âˆˆ
{0, 1}, i âˆˆ . Para que ( x, y) âˆˆ S0 , ( x, y) debe cumplir 0 â‰¤ x + y â‰¤ 1 de manera que (0.a1 a2 Â· Â· Â· )2 +
(0.b1 b2 Â· Â· Â· )2 â‰¤ (1.000 . . . )2 = (0.111 . . . )2 en particular

R

R

N

a1 + b1 â‰¤ 1 âˆ¨ ( a1 + b1 = 2 âˆ§ ak + bk = 0, âˆ€k > 1)

(1.6)

en el primer caso se tiene que a1 Â· b1 = 0; en el segundo caso x = 21 y y = 12 y en este caso se puede
cambiar la representaciÃ³n de x o de y para que a1 Â· b1 = 0.
Denote con S0k el triÃ¡ngulo con vÃ©rtice (0, 0) en el paso k-Ã©simo, asÃ­ S00 = S0 , S01 = {( x, y) : 0 â‰¤
x + y â‰¤ 21 } en general S0k = {( x, y) : 0 â‰¤ x + y â‰¤ 21k }, nÃ³tese que

( x â€² , yâ€² )

=

((0.00 Â· Â· Â· ak+1 ak+2 Â· Â· Â· )2 , (0.00 Â· Â· Â· bk+1 bk+2 Â· Â· Â· )2 ) âˆˆ S0k

â‡” ak+1 Â· bk+1 = 0.

AdemÃ¡s, cualquier triÃ¡ngulo de Sk es de la forma (u, v) + S0k donde (u, v) es un vÃ©rtice izquierdo
de algÃºn triÃ¡ngulo de Sk . AsÃ­, dada una combinaciÃ³n de a1 , . . . , an , b1 , . . . , bn âˆˆ {0, 1} tal que si

13

ai = 1 entonces bi = 0, la expresiÃ³n

(0, 0) +

a1
b
a
b
(1, 0) + 1 (0, 1) + 2 (1, 0) + 2 (0, 1)
2
2
4
4

+ Â·Â·Â·

Â·Â·Â· +

an
bn
(1, 0)+ n (0, 1)
2n
2

es un vÃ©rtice izquierdo de Sn generado a partir de (0,0) y los pasos 1, 2 . . . n. En base 2 este vÃ©rtice
se escribe

(u, v) = ((0.a1 a2 Â· Â· Â· an )2 , (0.b1 b2 Â· Â· Â· bn )2 ) .

(1.7)

Hay 3n de estos puntos en Sn pues, al escoger ai1 = ai2 = Â· Â· Â· = ai j = 1, con j = 0, . . . , n y el resto

cero, se tiene 2nâˆ’ j formas de escoger b1 , b2 , . . . , bn con ai Â· bi = 0 y como hay (nj) formas de elegir

los aik = 1, k = 1, . . . , j en total se tienen (nj) Â· 2nâˆ’ j formas de escogerlos. Variando j = 0, . . . , n se
obtiene
 
 
n
n
n
n âˆ’1
2 +
Â·2
+
Â· 2 n âˆ’2 + Â· Â· Â· + 1 = ( 2 + 1 ) n = 3 n
(1.8)
1
2
formas diferentes de escoger los ai , i = 1, . . . , n y bi , i = 1, . . . , n con ai Â· bi = 0. Por lo tanto todos
los vÃ©rtices izquierdos de Sn son de la forma (1.7). Algunos vÃ©rtices de la forma (1.7) son:


3 1
,
= ((0.110)2, (0.001)2)
4 8


11 1
,
= ((0.10110)2, (0.00001)2)
16 32
Esto permite dar una descripciÃ³n de los elementos de S, que se resume en el siguiente teorema.
Teorema 11. Sea S0 un triÃ¡ngulo equilÃ¡tero de lado 1. Introduzca un sistema de coordenadas con origen en

un vÃ©rtice de S0 y los lados adyacentes en la parte positiva de cada eje. Entonces, ( x, y) âˆˆ S si y solo silas
expansiones binarias de ambas coordenadas se pueden escribir sin que tengan un 1 en la misma posiciÃ³n.
DemostraciÃ³n. Sea s = ((0.a1 a2 Â· Â· Â· )2 , (0.b1 b2 Â· Â· Â· )2 ) con ai , bi âˆˆ {0, 1}, i âˆˆ
fijo, como
s âˆˆ Sn â‡” s = (u, v) + ( x â€² , yâ€² )

N. Sea s âˆˆ S y n âˆˆ N

con (u, v) un vÃ©rtice izquierdo de la forma (1.7) y ( x â€² , yâ€² ) âˆˆ S0n entonces an+1 Â· bn+1 = 0. Por
otro lado si, s = ((0.a1 a2 Â· Â· Â· )2 , (0.b1 b2 Â· Â· Â· )2 ) no tiene un 1 en la misma posiciÃ³n, sea n natural
fijo, entonces se tiene que ((0.a1 a2 Â· Â· Â· an )2 , (0.b1 b2 Â· Â· Â· bn )2 ) es un vÃ©rtice izquierdo de Sn y x â€² =
(0.00 Â· Â· Â· an+1 Â· Â· Â· )2 y yâ€² = (0.00 Â· Â· Â· bn+1 Â· Â· Â· )2 cumplen con ( x â€² , yâ€² ) âˆˆ S0n pues an+1 Â· bn+1 = 0
entonces s âˆˆ Sn âˆ€n âˆˆ por lo tanto s âˆˆ S.


N

Algunos elementos de S son


272 68
,
341 341


7 10
,
9 63

=
=


(0.1100110000 2 , (0.0011001100)2 )

(0.110001 2 , (0.001010)2 )

Se puede observar de la construcciÃ³n por tremas de S, que Ã©ste es semejante a su parte superior,
o a la parte derecha o a la parte izquierda, independiente de la escala, pues no importa cuÃ¡nto se
aumente una parte adecuada de la figura, siempre se observa el mismo detalle, la razÃ³n de esto es
que S se puede construir por medio de un sistema iterado de funciones .

14

AUTOSEMEJANZA

R

R

Sean f 0 , f 1 , f 2 : 2 â†’ 2 tal que f 0 (( x, y)) = 12 ( x, y), f 1 (( x, y)) = 12 ( x, y) + 12 (1, 0) y f 2 (( x, y)) =
1
1
o
2 ( x, y ) + 2 (0, 1). RÃ³tese el eje Y un Ã¡ngulo de 30 a favor de las manecillas del reloj, note que
1
estas funciones son semejanzas de razÃ³n 2 . Con esto se define un sistema iterado de funciones
que realizan la lista contractiva de razones ( 21 , 12 , 12 ). El atractor del sistema iterado de funciones
( f 0 , f 1 , f 2 ) es S. Esto dice tambiÃ©n que la dimensiÃ³n de semejanza de S = ln(3)/ ln(2).
Una sucesiÃ³n que aproxima a un conjunto.. En las construcciones anteriores se necesita de un
conjunto, y a partir de Ã©ste se construye por un mÃ©todo iterativo a S. Es posible sin embargo,
ocupar en la computadora mucha memoria para hacer tales iteraciones sobre todos o una gran
parte de los elementos de un conjunto, ya sea un triÃ¡ngulo o cualquier otro compacto. AÃºn asÃ­, el
corolario 1 afirma que cualquier compacto no vacÃ­o sirve como primera aproximaciÃ³n para S, de
manera que si se utiliza un punto y sobre Ã©l se evalÃºa iteradamente las funciones f 0 , f 1 , f 2 en un
orden aleatorio eventualmente se tendrÃ¡ una aproximaciÃ³n de S.
Â¿CuÃ¡l serÃ¡ un buen punto de partida y un buen orden de iteraciÃ³n para asegurar que por igual se
estÃ© aproximando a todos los puntos de S? Defina Ak al conjunto formado por todos los vÃ©rtices
izquierdos de cada triÃ¡ngulo en Sk . Ak es una aproximaciÃ³n de todos los puntos de Sk y tambiÃ©n
a los elementos de S, ademÃ¡s, la distancia de algÃºn elemento de Ak a otro de S es a lo sumo 21k
por lo que es clara la convergencia. Basta entonces definir una sucesiÃ³n en que todos los vÃ©rtices
izquierdos de Sk formen parte de ella.
Observe que, como todos los vÃ©rtices izquierdos de Sk son de la forma (1.7) se les puede codificar
con la expresiÃ³n ck ckâˆ’1 Â· Â· Â· c1 de la siguiente forma: ci = 0 si ai = 0 y bi = 0, ci = 1 si ai = 1 y
bi = 0 y ci = 2 si ai = 0 y bi = 1, y como a ck ckâˆ’1 Â· Â· Â· c1 se le asocia un Ãºnico nÃºmero entero n tal
que n = (ck ckâˆ’1 Â· Â· Â· c1 )3 , asÃ­ se tiene una forma de asociar todos los vÃ©rtices izquierdos de Sk con
un Ãºnico nÃºmero entero, por ejemplo


11 1
,
= ((0.10110)2, (0.00001)2) âˆ’â†’ (21101)3 = 199,
16 32


3 17
,
= ((0.011000)2, (0.100010)2) âˆ’â†’ (020112)3 = 176,
8 32
Ã‰sta es la sucesiÃ³n que se define en el siguiente teorema.
ProposiciÃ³n 3. Sea f 0 , f 1 , f 2 las funciones definidas en la construcciÃ³n anterior. Sea n = ( ck ckâˆ’1 . . . c2 c1 )3
la expansiÃ³n triÃ¡dica para el nÃºmero entero no negativo n, defina xn = ( f c1 â—¦ f c2 â—¦ . . . f ck âˆ’1 â—¦ f ck )((0, 0)),
y sea Ak el conjunto formado por los vÃ©rtices izquierdos de cada triÃ¡ngulo que forma Sk . Entonces Ak =
{ x 0 , x 1 , x 2 , . . . , x 3 k âˆ’1 }.

N

R

DemostraciÃ³n. Sea k âˆˆ
y 0 â‰¤ n < 3k , n = (ck ckâˆ’1 . . . c2 c1 )3 y sea (u, v) âˆˆ 2 tal que u =
0.a1 a2 Â· Â· Â· ak y v = 0.b1 b2 Â· Â· Â· bk con ai = ci (2 âˆ’ ci ) y bi = c2i (ci âˆ’ 1) para todo i = 1, . . . , k, es
claro que (u, v) âˆˆ Sk , ademÃ¡s que f c1 ((0.a2 Â· Â· Â· ak )2 , (0.b2 Â· Â· Â· bk )2 ) = (u, v), en consecuencia ( f c1 â—¦
f c2 )((0.a3 Â· Â· Â· ak )2 , (0.b3 Â· Â· Â· bk )2 ) = (u, v) y en general
xn = ( f c1 â—¦ f c2 â—¦ . . . f ck âˆ’1 â—¦ f ck )((0, 0)) = (u, v)
entonces xn âˆˆ Ak y como |{ xn : 0 â‰¤ n < 3k }| = 3k por lo que Ak = { x0 , x1 , . . . , x3k âˆ’1 }.
Corolario 2. S = { x n }0âˆ .

DemostraciÃ³n. Basta notar que Ak+1 = f 0 [ Ak ]
la convergencia.

S

f 1 [ Ak ]

S



f 2 [ Ak ] y usando el corolario 1 se obtiene


En la Figura 1.5, se observan algunas aproximaciones de S, usando la sucesiÃ³n anterior con k = 1,
2, 3, 5, 6 y 7.

15

Figura 1.5 VÃ©rtices de Sk

Teorema 12. El atractor del sistema iterado de funciones ( f 0 , f 1 , f 2 ) es el triÃ¡ngulo de SierpinÌski S.

Luego la dimensiÃ³n de semejanza de S =
f i [S0 ] no traslapan demasiado.
Corolario 3. Sea A0 âŠ†

ln(3)
ln(2)

es igual a la dimensiÃ³n fractal que sucede cuando

R2 compacto y no vacÃ­o, defina
A n +1 = f 0 [ A n ]

[

f 1 [ An ]

[

f 2 [ An ]

entonces esta sucesiÃ³n converge a S en la mÃ©trica Hausdorff del espacio de los compactos no vacÃ­os de

R2 .

DragÃ³n de Heighway.. Este conjunto se define como el lÃ­mite H de la sucesiÃ³n de polÃ­gonos Hn
dada por la Figura 1.6. Este fue descubierto por el fÃ­sico John E. Heighway que junto con Bruce A.
Banks y William Harter estudiaron algunas propiedades de los polÃ­gonos aproximantes, entre ellas
el hecho de que Ã©stos nunca se cruzan [9, p. 21].
Q â€¢...
...
..
...
...
â€¢
P ....
..
...
...
...
.

Q.....â€¢
...
....
...
.
.
.
..
.
.
.
..
P â€¢.......
....
...
....
....
....
..

Figura 1.6

â€¢......
....
....
.......
.
.
....
.
.. ..... ......
.
.
.
......
â€¢.........
....
....
..
....
....
.......
....
....
.... ......
.....

â€¢...............
...
................
...............
.
...
...
.
.
.
.
.
â€¢...............................
...
...............
...
..
..............
...
...
....
................

ConstrucciÃ³n del DragÃ³n de Heighway.

ProposiciÃ³n 4. Existen dos semejanzas f 1 , f 2 :

sistema iterado.

â€¢..
....
..
...
..
â€¢.............................
...
..
....
..
...........................

R2

â†’

R2 con razÃ³n âˆš12 tal que H es el atractor de este

DemostraciÃ³n. Sean P y Q los puntos de la Figura 1.6. Considere P como el origen de coordenadas,
asÃ­, el punto Q = (q1 , q2 ) tiene coordenadas (0, 1/2) en el caso H0 y (1/2, 1/2) en el caso Hk para
S
k â‰¥ 1. Se necesita que Hk+1 = f 1 [ Hk ] f 2 [ Hk ]. Se va a describir el efecto sobre Hk , de cada una de
las funciones. f 1 primero
âˆš traslada Hk de modo que el punto Q coincida con el origen, luego contrae
por un factor de 1/ 2 y por Ãºltimo rota un Ã¡ngulo de 135o ; anÃ¡logamente se describe f 2 con la
diferencia de que la rotaciÃ³n es con un Ã¡ngulo de 45o . AsÃ­, para un punto ( x, y) âˆˆ Hk se obtiene


1
cos 135o sen 135o
f 1 ( x, y) = âˆš ( x âˆ’ q1 , y âˆ’ q2 ) Â·
âˆ’ sen 135o cos 135o
2


1
cos 45o sen 45o
f 2 ( x, y) = âˆš ( x âˆ’ q1 , y âˆ’ q2 ) Â·
âˆ’ sen 45o cos 45o
2

16

AUTOSEMEJANZA

simplificando para k â‰¥ 1, f 1 ( x, y) = 12 (1 âˆ’ x âˆ’ y, x âˆ’ y) y f 2 ( x, y) =
semejanzas de razÃ³n âˆš1 y describen la construcciÃ³n anterior.
2

Figura 1.7

1
2 (x

âˆ’ y, x + y âˆ’ 1), que son


DragÃ³n de Heighway.

Con esta lista de razones se calcula la dimensiÃ³n de semejanza de H la cual es 2.

1.4

Espacios de hileras

Considere un alfabeto E = {1, 2, . . . , n} de n letras, y el conjunto E(m) de todas las palabras o hileras
finitas usando m letras de E. Se denota por E(âˆ—) el conjunto formado por todas las palabras finitas
y por E(Ï‰ ), el conjunto de las infinitas.
La hilera de longitud cero es la palabra vacÃ­a y se denota por Î›. La hilera finita Î± representa un
ancestro de Î² si y solo si Î± es un segmento inicial de Î² esto es Î² = Î±Î³ para alguna hilera Î³, se dice
tambiÃ©n que Î± es un prefijo de Î²; la longitud de Î± se denota |Î±|. Sobre E(âˆ—) se define una relaciÃ³n
de orden parcial â€œâ‰¤" tal que Î± â‰¤ Î² si Î± es un prefijo comÃºn de Î². AsÃ­ para Î± âˆˆ E(âˆ—) se define por:
n
o
[Î±] = Ïƒ âˆˆ E(Ï‰ ) : Î± â‰¤ Ïƒ ,
el conjunto de todos las hileras infinitas que empiezan con Î± , y satisfacen [Î±] = [Î±1] âˆª [Î±2] âˆª Â· Â· Â· âˆª
[Î±n] y âˆ… = [Î±1] âˆ© [Î±2] âˆ© Â· Â· Â· âˆ© [Î±n].
Sobre E(Ï‰ ) Ã— E(Ï‰ ) se define Ïr por Ïr (Ïƒ, Ï„ ) = r k donde k es el largo del mayor prefijo comÃºn de Ïƒ y
Ï„. Esta funciÃ³n define una mÃ©trica en E(Ï‰ ) cuando 0 < r < 1 como se verÃ¡ en el siguiente teorema.
Teorema 13. Sea ( E ( Ï‰ ) , Ïr ) definida anteriormente. Entonces, se cumple

(1) Ïr es una ultramÃ©trica2 sobre E(Ï‰ ).
(2) Los conjuntos [Î±] tienen diÃ¡metro r |Î±| .
(3) El espacio ( E(Ï‰ ), Ïr ) es completo.
DemostraciÃ³n. Para (1) se probarÃ¡ Ïr (Ïƒ, Ï„ ) â‰¤ mÃ¡x{Ï(Ïƒ, Î¸ ), Ï(Î¸, Ï„ )} Ãºnicamente pues las otras condiciones son claramente satisfechas. Sea k1 la longitud del mayor prefijo comÃºn a Ïƒ y Î¸, k2 la longitud
del mayor prefijo comÃºn a Î¸ y Ï„, y k la longitud del mayor prefijo comÃºn a Ïƒ y Ï„. Ahora considere
m = mÃ­n{k1 , k2 }, se cumple que k â‰¥ m y por lo tanto Ïr (Ïƒ, Ï„ ) = r k â‰¤ r m = mÃ¡x{r k1 , r k2 } =
2 Una

ultramÃ©trica es una mÃ©trica que cumple Ï( x, y) â‰¤ mÃ¡x{ Ï( x, z), Ï( z, y)}, âˆ€ x, y, z.

17

mÃ¡x{Ïr (Ïƒ, Î¸ ), Ïr (Î¸, Ï„ )}, como se deseaba. Para la parte (2) escoja Ïƒ = Î±Ïƒ â€² y Ï„ = Î±Ï„ â€² donde Î± es su
mayor prefijo comÃºn, se tiene que Ïƒ, Ï„ âˆˆ [Î±] y por lo tanto diam [Î±] â‰¥ Ïr (Ïƒ, Ï„ ) = r |Î±| . Para obtener
la otra desigualdad, sean Ïƒ, Ï„ âˆˆ [Î±] cualesquiera, y sea Î² el mayor prefijo comÃºn entre ellos, se
cumple que | Î²| â‰¥ |Î±| asÃ­ que Ïr (Ïƒ, Ï„ ) = r | Î²| â‰¤ r |Î±| y por lo tanto diam [Î±] â‰¤ r |Î±| . Para la Ãºltima
parte, dada (Ïƒp ) sucesiÃ³n de Cauchy en E(Ï‰ ), para cada k âˆˆ existe un pk âˆˆ de modo que para
todo p, m â‰¥ pk se tiene que Ïr (Ïƒp , Ïƒm ) < r k , es decir, Ïƒpk coincide con Ïƒm en las primeras k letras
para todo m â‰¥ k, es por esto que se define Ï„, donde su k-Ã©sima letra sea la k-Ã©sima de Ïƒpk . Resulta
que Ïƒp â†’ Ï„, pues dado Îµ > 0, se puede encontrar k âˆˆ tal que r k < Îµ, y entonces para todo m > pk
se tiene que Ïr (Ïƒm , Ï„ ) â‰¤ r k < Îµ. Con lo que se finaliza la demostraciÃ³n de este teorema.


N

N

N

Se puede dotar a E(Ï‰ ) de otra mÃ©trica a partir de una familia de pesos wÎ± > 0, Î± âˆˆ E(âˆ—) que satisface
wÎ± > w Î² si Î± < Î² siempre y cuando para toda Ïƒ âˆˆ E(Ï‰ ) la sucesiÃ³n de pesos al recorrer la hilera Ïƒ
tienda a cero. Esta tambiÃ©n cumplirÃ¡ que diam [Î±] = wÎ± .
ProposiciÃ³n 5. Si Ï ( Ïƒ, Ï„ ) = wÎ± , donde Î± es el mayor prefijo comÃºn entre Ïƒ, Ï„ y Ï ( Ïƒ, Ï„ ) = 0 si Ïƒ = Ï„

entonces Ï define una ultramÃ©trica sobre E(Ï‰ ).
DemostraciÃ³n. VÃ©ase [9, p. 71].



Sea (r1 , r2 , Â· Â· Â· , rn ) una lista de razones contractiva, E =
{1, 2, Â· Â· Â· , n} el alfabeto de n letras y E(Ï‰ ) el espacio de las hileras infinitas sobre E. La lista de razones (r1 , Â· Â· Â· , rn ) se denota por (re )eâˆˆ E .
Para cada e âˆˆ E, existe una funciÃ³n Î¸e : E(Ï‰ ) â†’ E(Ï‰ ), que se llama
corrimiento a la derecha, definida por Î¸e (Ïƒ ) = eÏƒ.
ProposiciÃ³n 6. Sea Î± âˆˆ E (âˆ—) , (re ) e âˆˆ E una lista de razones contractiva y sean wÎ± definidos recursivamente

por: wÎ› = 1, wÎ±e = re Â· wÎ± . Entonces existe una ultramÃ©trica Ï en E(Ï‰ ) tal que Ï(Ïƒ, Ï„ ) = wÎ± , donde Î± es
el mayor prefijo comÃºn de Ïƒ y Ï„ y se cumple que el diam [Î±] = wÎ± .

DemostraciÃ³n. Es inmediata de la proposiciÃ³n 5 pues la lista de razones define una familia con las
condiciones de esta proposiciÃ³n.

A la mÃ©trica Ï definida en la proposiciÃ³n 6 se le llama la mÃ©trica inducida por la lista de razones
(re )eâˆˆ E . Con esta mÃ©trica los corrimientos a la derecha forman un sistema iterado de funciones,
esto se formaliza en la siguiente proposiciÃ³n.
ProposiciÃ³n 7. Sea la lista contractiva de razones (re ) e âˆˆ E y ( Î¸e ) e âˆˆ E los corrimientos a la derecha y sea

( E(Ï‰ ), Ï) el espacio de hileras infinitas de n letras con la mÃ©trica inducida por la lista de razones. Entonces
( E(Ï‰ ), Ï) es un espacio compacto y separable.

DemostraciÃ³n. Con una demostraciÃ³n similar a la del teorema 13, el espacio ( E(Ï‰ ), Ï) es completo,
ademÃ¡s, se puede ver que el sistema iterado de funciones (Î¸e )eâˆˆ E realiza la lista de razones (re )eâˆˆ E,
dado que si Î± es el mayor prefijo comÃºn entre Ïƒ y Ï„ se tiene que eÎ± es el mayor prefijo comÃºn de
eÏƒ y eÏ„, de donde
Ï (Î¸e (Ïƒ ) , Î¸e (Ï„ )) = weÎ± = re wÎ± = re Ï(Ïƒ, Ï„ ). Esto significa que Î¸e es una semejanza


en E(Ï‰ ), Ï con razÃ³n re . Se verifica que E(Ï‰ ) es el conjunto invariante de este sistema iterado de
funciones, y usando el teorema 3 se prueba la compacidad. Para ver que es separable basta recordar
que todo espacio compacto es separable.


R

El espacio E(Ï‰ ) se puede identificar con algÃºn atractor de un sistema iterado de funciones en n .
El siguiente teorema define una aplicaciÃ³n h : E(Ï‰ ) â†’ n cuyo rango es este atractor. A esta aplicaciÃ³n se le llama la â€œaplicaciÃ³n modelo". Este teorema es un caso particular del teorema 41, que
demostraremos en el capÃ­tulo 3.

R

18

AUTOSEMEJANZA

Teorema 14. (AplicaciÃ³n Modelo del Espacio de Hileras). Sea S un espacio mÃ©trico completo no vacÃ­o, y

sea ( f e )eâˆˆ E un sistema iterado de funciones que realiza la lista contractiva de razones (re )eâˆˆ E en S. Entonces
existe una Ãºnica funciÃ³n continua h : E(Ï‰ ) â†’ S tal que h(eÏƒ ) = f e (h(Ïƒ )) para todo Ïƒ âˆˆ E(Ï‰ ) y para todo
e âˆˆ E. El rango h[ E(Ï‰ ) ] es el conjunto invariante del sistema iterado de funciones ( f e )eâˆˆ E.
ProposiciÃ³n 8. La aplicaciÃ³n modelo tiene crecimiento acotado.



DemostraciÃ³n. Sea B = diam h[ E(Ï‰ ) ] . B es finito y positivo pues h[ E(Ï‰ ) ] es compacto. Sean Ïƒ y Ï„

en E(Ï‰ ) y k = |Î±| donde Î± = e1 Â· Â· Â· ek es el mayor prefijo comÃºn de Ïƒ y Ï„, es decir Ïƒ = Î±Ïƒ â€² y Ï„ = Î±Ï„ â€²
entonces Ï (h(Ïƒ ) , h(Ï„ )) = re1 Â· Â· Â· rek Ï (h(Ïƒ â€² ) , h(Ï„ â€² )) â‰¤ wÎ± Â· B = B Â· Ï(Ïƒ, Ï„ ).


R â†’ R y f1 : R â†’ R tales que f0 (x) = 3x y f1 (x) = x+3 2 . La aplicaciÃ³n
h ( Ïƒ )+2
h(Ïƒ)
y cumple con
modelo h : E(Ï‰ ) â†’ R, descrita en el teorema 14, es h(0Ïƒ ) = 3 y h(1Ïƒ ) =
3
Si E = {0, 1} y f 0 :
h [ E ( Ï‰ ) ] = C.

ProposiciÃ³n 9. h : ( E ( Ï‰ ) , Ïr ) â†’

C es un homeomorfismo.

R tiene distorsiÃ³n acotada si y solo si r = 13 . En este caso h : (E(Ï‰), Ï1/3) â†’

DemostraciÃ³n. Suponga que h tiene distorsiÃ³n acotada, asÃ­ existen a y b tales que:
aÏr (Ïƒ, Ï„ ) â‰¤ |h(Ïƒ ) âˆ’ h(Ï„ )| â‰¤ bÏr (Ïƒ, Ï„ ),

(1.9)

ademÃ¡s se tiene:


 h(Ïƒ ) + 2 h(Ï„ ) + 2 
 = |h(Ïƒ ) âˆ’ h(Ï„ )|

|h(1Ïƒ ) âˆ’ h(1Ï„ )| = 
âˆ’

3
3
3
Ïr (1Ïƒ, 1Ï„ ) = rÏr (Ïƒ, Ï„ )

(1.10)
(1.11)

en forma similar

|h(0Ïƒ ) âˆ’ h(0Ï„ )| =

Ïr (0Ïƒ, 0Ï„ ) =

1
|h(Ïƒ ) âˆ’ h(Ï„ )|
3
rÏr (Ïƒ, Ï„ )

Si |Î±| = n, se puede multiplicar la desigualdad (1.9) por
se obtiene:
a

Ïr (Î±Ïƒ, Î±Ï„ )
3n r n
Si r >

1
3

â‰¤ |h(Î±Ïƒ ) âˆ’ h(Î±Ï„ )| â‰¤

se puede encontrar n tal que

ecuaciÃ³n (1.12) se tiene que

1
3n ,

b

Ïr (Î±Ïƒ, Î±Ï„ )
3n r n

y usando las ecuaciones (1.10) y (1.11)
b

Ïr (Î±Ïƒ, Î±Ï„ )
3n r n

(1.12)

< aÏr (Î±Ïƒ, Î±Ï„ ), con esta desigualdad y la

|h(Î±Ïƒ ) âˆ’ h(Î±Ï„ )| < aÏr (Î±Ïƒ, Î±Ï„ )

que contradice la hipÃ³tesis. Si r < 13 se tendrÃ­a de manera anÃ¡loga que |h(Î±Ïƒ ) âˆ’ h(Î±Ï„ )| > bÏr (Î±Ïƒ, Î±Ï„ )
que tambiÃ©n la contradice, de donde se debe tener r = 13 . En [9, p. 70] se prueba el recÃ­proco. Una
distorsiÃ³n acotada es biyectiva y su inversa es continua, con lo cual se completa la prueba.

Sea E = {L, R, U} y sean f L , f R , f U :

R2 â†’ R2 tales que

f L (( x, y))

=

f R (( x, y))

=

f U (( x, y))

=

1
( x, y)
2
1
( x, y) +
2
1
( x, y) +
2

1
(1, 0)
2
1
(0, 1)
2

19

Se sabe que estas funciones son semejanzas de razÃ³n 12 . Con esto se define un sistema iterado de
funciones que realizan la lista contractiva de razones ( 12 , 12 , 12 ). Para describir a h, la aplicaciÃ³n del
teorema 14, se usa la expansiÃ³n en base 2 de las coordenadas del punto (u, v). Si Ïƒ âˆˆ E(Ï‰ ) y la
i-Ã©sima letra de Ïƒ es L entonces el i-Ã©simo dÃ­gito de u y v es 0; si es U entonces el i-Ã©simo dÃ­gito de
u es 0 y el de v es 1, si es R entonces el i-Ã©simo dÃ­gito de u es 1 y el i-Ã©simo dÃ­gito de v es 0. Por
ejemplo
h(RULRRUL Â· Â· Â· ) = ((0.1001100 Â· Â· Â· )2 , (0.0100010 Â· Â· Â· )2 )

De aquÃ­ se tiene que h[ E(Ï‰ ) ] = S. AdemÃ¡s h cumple con h(LÏƒ ) = f L (h(Ïƒ )), h(UÏƒ ) = f U (h(Ïƒ )) y
h(RÏƒ ) = f R (h(Ïƒ )), y es continua para todo Ïƒ âˆˆ E(Ï‰ ).
Si se considera E(Ï‰ ) con la mÃ©trica Ï1/2 se tiene que diam [Î±] = ( 12 )|Î±| . Se sabe que h tiene crecimiento acotado, sin embargo no es una distorsiÃ³n acotada.
ProposiciÃ³n 10. La aplicaciÃ³n h definida como antes no es de decrecimiento acotado.

DemostraciÃ³n. Si se toma Ïƒ = (LRRR Â· Â· Â· ) y Ï„ = (RLLL Â· Â· Â· ), se tiene que Ï1/2 (Ïƒ, Ï„ ) = 1 y ademÃ¡s

kh(Ïƒ ) âˆ’ h(Ï„ )k

= k ((0.0111 Â· Â· Â· )2 , (0.0 Â· Â· Â· )2 ) âˆ’ ((0.1000 Â· Â· Â· )2 , (0.0 Â· Â· Â· )2 )k
= 0



1.5

Grafos

Los grafos se utilizan para dar una generalizaciÃ³n de los espacios de hileras E(Ï‰ ) . Para hablar de
grafos deben existir un conjunto V de vÃ©rtices o nodos y un conjunto E de aristas o flechas. Cada
arista va de un nodo a otro nodo cualquiera. La direcciÃ³n de la arista en nuestro caso es importante
de tomar en cuenta, y por esto se trabajarÃ¡ con grafos dirigidos. Cuando exista mÃ¡s de una arista
conectando un par de nodos dados se le llamarÃ¡ multigrafo. Es por esto que se darÃ¡n las siguientes
definiciones.
Sea V un conjunto finito no vacÃ­o y E âŠ† V Ã— V, entonces al par (V, E)
se le llama grafo dirigido. Los elementos de V son llamados vÃ©rtices o
nodos y los de E serÃ¡n llamados aristas o flechas.
Ahora se extiende esta definiciÃ³n para que pueda existir mÃ¡s de una arista conectando un mismo
par de nodos.
Un multigrafo dirigido (V, E, i, t), consiste de dos conjuntos finitos
V, E, y dos funciones i : E â†’ V y t : E â†’ V, tales que para cada e âˆˆ E,
i (e) es el vÃ©rtice inicial de e, y t(e) su vÃ©rtice terminal. Denotaremos
Euv al conjunto de aristas e, tales que i (e) = u y t(e) = v. Un camino
en un multigrafo dirigido es una sucesiÃ³n de aristas, tomadas en cierto
orden de modo que el vÃ©rtice terminal de cada arista sea el vÃ©rtice inicial
de la siguiente arista. Un multigrafo es fuertemente conectado si,
para cada par de vÃ©rtices u,v de E, existe un camino de u a v.
Un camino serÃ¡ a menudo identificado con una hilera de etiquetas de las aristas. AdemÃ¡s el vÃ©rtice
inicial de un camino es el vÃ©rtice inicial de la primera arista, anÃ¡logamente se define el vÃ©rtice final

20

AUTOSEMEJANZA

de un camino. El nÃºmero de aristas de un camino Î± diremos que es su longitud, la denotamos con
|Î±|. Un camino Î± que cumple que i (Î±) = t(Î±) es llamado ciclo, y un lazo es un ciclo de longitud 1.
(âˆ—)

Escribiremos Euv para denotar el conjunto de caminos con vÃ©rtice inicial u y vÃ©rtice terminal v o
(n)

sea los caminos que van de u a v o que conectan u con v. Escribiremos Euv para todos los caminos
(0)

de u a v con longitud n. Diremos para cada u âˆˆ V que el conjunto Euu tiene un elemento, a saber
el camino vacÃ­o de u en sÃ­ mismo, escrito Î›u . Por supuesto que vamos a identificar E con E(1) y a
(1)

Euv con Euv . Vamos a considerar E(âˆ—) como el conjunto de todos los caminos finitos en el grafo.
Sea (V, E, i, t) un multigrafo, vamos a considerar E(âˆ—) con una estructura de Ã¡rbol, es decir, si Î± es
un camino entonces los hijos de Î± son los caminos de la forma Î±e, para las aristas e que cumplan que
i (e) = t(Î±). Realmente esto no es un Ã¡rbol sino mÃ¡s bien una uniÃ³n disjunta de Ã¡rboles, un Ã¡rbol
(âˆ—)

Ev para cada nodo v âˆˆ V. Una uniÃ³n disjunta de Ã¡rboles es llamada â€œbosque". AsÃ­ llamaremos a
esto el bosque de caminos del grafo.

Una hilera infinita Ïƒ = (e1 e2 . . . ) corresponde a un camino infinito
si el vÃ©rtice terminal de cada arista coincide con el vÃ©rtice inicial de
la prÃ³xima arista, es decir, t(en ) = i (en+1 ) âˆ€n âˆˆ . Dado un grafo
(V, E, i, t) escribimos E(Ï‰ ) para el conjunto de todos los caminos infini-

N

(Ï‰ )

tos, Ev para el conjunto de todos los caminos infinitos que empiezan
en v, v âˆˆ V. AdemÃ¡s si Î± âˆˆ E(âˆ—) , [Î±] = {Ïƒ âˆˆ E(Ï‰ ) : Î± â‰¤ Ïƒ }, el
conjunto de todos los caminos infinitos que comienzan con Î±.

(Ï‰ )

Algunas mÃ©tricas pueden ser definidas sobre los espacios Ev en forma similar a lo hecho en
espacios de hileras en la secciÃ³n 1.4. Debe tomarse en cuenta la posibilidad de que algunos nodos
de E(âˆ—) no tengan hijos o tengan un Ãºnico hijo. AsÃ­, si Î± no tiene hijos, entonces [Î±] = âˆ…, y por lo
tanto su diÃ¡metro es 0. Si Î± tiene un Ãºnico hijo Î², entonces [Î±] = [ Î²], asÃ­ se debe cumplir diam [Î±] =
diam [ Î²]. Estos casos no ocurren en grafos (V, E, i, t) donde cada nodo tiene al menos dos aristas
partiendo de este.
Sea (V, E, i, t) un multigrafo dirigido. Dada una familia wÎ± de nÃºmeros reales positivos, uno para
cada camino finito Î± âˆˆ E(âˆ—) , se definen mÃ©tricas Ï; de hecho Ãºnicamente se necesita definir distan(Ï‰ )

cias entre hileras con el mismo vÃ©rtice inicial, y asÃ­ obtenemos espacios mÃ©tricos Ev , disjuntos,
uno para cada nodo v âˆˆ V, que llamaremos en adelante espacios de caminos. MasÌ aÃºn, cada Ï
(Ï‰ )

define una ultramÃ©trica sobre los espacios Ev tal que diam [Î±] = wÎ± para la mayorÃ­a de los Î±,
anÃ¡logo a lo hecho en la proposiciÃ³n 5. Pero vamos a estudiar lo anterior, con mÃ¡s detalle, en la
prÃ³xima secciÃ³n con el fin de definir la dimensiÃ³n de un grafo.

Autosemejanza de Grafos
Algunos conjuntos no presentan autosemejanza como los vistos en la secciÃ³n 1.1, es decir, una
parte no es semejante al todo. MÃ¡s bien, el conjunto presenta autosemejanza por pedazos, o sea,
este se puede dividir en varias partes que a su vez, cada una de ellas se descompone utilizando
las partes originales afectadas por algÃºn factor de escala. Esto nos permite estudiar una mayor
cantidad de conjuntos. Mauldin y Williams en [29] hacen una formulaciÃ³n de este tema y dan una
correspondencia entre estos conjuntos y los multigrafos dirigidos. Es por ello que vamos a definir
a continuaciÃ³n algunas estructuras nuevas.

21

La estructura involucrada, un multigrafo dirigido (V, E, i, t) junto con
una funciÃ³n r : E â†’]0, âˆ[, serÃ¡ llamado un grafo de MauldinWilliams y se denotarÃ¡ por (V, E, i, t, r ). Un sistema iterado de
funciones que realiza este grafo estÃ¡ compuesto de espacios mÃ©tricos
Sv , uno para cada nodo v, y semejanzas f e , una para cada arista e âˆˆ E,
tales que f e : Sv â†’ Su si e âˆˆ Euv , cada una con una razÃ³n de semejanza r (e). Un grafo de Mauldin-Williams (V, E, i, t, r ) serÃ¡ llamado
estrictamente contractivo si r (e) < 1 para todo e âˆˆ E.
La definiciÃ³n de la funciÃ³n r que evalÃºa aristas puede ser extendida a caminos definiendo r (Î›u ) =
1 para caminos vacÃ­os, y r (eÎ±) = r (e)r (Î±) para cualquier camino Î± y cualquier arista e con t(e) =
i ( Î± ).
La prÃ³xima definiciÃ³n generaliza la definiciÃ³n 1.1, que en este contexto corresponderÃ­a a un Ãºnico
nodo y un lazo para cada una de las semejanzas.
Una lista invariante para un sistema iterado de funciones, es una lista
de conjuntos compactos no vacÃ­os Kv âŠ† Sv , uno para cada nodo v âˆˆ V,
tales que
[

Ku =

(1.13)

f e [Kv ]

vâˆˆV
e âˆˆ Euv

para todo u âˆˆ V. Cada uno de los conjuntos compactos Kv que satisface
tal ecuaciÃ³n se dirÃ¡ que tiene autosemejanza de grafo.
Teorema 15. Dado (V, E, i, t, r ) un grafo de Mauldin-Williams estrictamente contractivo y sea ( f e ) e âˆˆ E un

sistema iterado de funciones que realiza este grafo en espacios mÃ©tricos completos Sv . Entonces existe una
Ãºnica lista (Kv )vâˆˆV de conjuntos compactos (Kv âŠ† Sv ) tales que
[

Ku =

f e [Kv ]

vâˆˆV
e âˆˆ Euv

para todo u âˆˆ V.

DemostraciÃ³n. Sabemos que los espacios mÃ©tricos de los subconjuntos compactos no vacÃ­os de Sv ,
K(Sv ) son completos, por lo tanto el producto cartesiano

âˆ K(Sv )

v âˆˆV

es tambiÃ©n completo con la mÃ©trica usual del producto cartesiano. Vamos a escribir ( Av )vâˆˆV para
un elemento tÃ­pico del espacio producto. La funciÃ³n definida por
ï£«
ï£¶
ï£¬ [
ï£·
F (( Av )vâˆˆV ) = ï£­
f e [ Av ]ï£¸
vâˆˆV
e âˆˆ Euv

v âˆˆV

es una aplicaciÃ³n contractiva, y su Ãºnico punto fijo es
Ku =

[

f e [Kv ]

vâˆˆV
e âˆˆ Euv

para todo u âˆˆ V. Y esto es lo que se deseaba.



22

AUTOSEMEJANZA

A continuaciÃ³n vamos a definir la dimensiÃ³n del multigrafo asociado a esta clase de conjuntos,
para luego encontrar una fÃ³rmula para el caso de dos nodos y finalmente damos un ejemplo para
aplicar los resultados de esta subsecciÃ³n. En la secciÃ³n 3.5 vamos a necesitar esta dimensiÃ³n para
calcular la dimensiÃ³n Hausdorff de los conjuntos autosemejantes, (Kv )vâˆˆV , que nos proporciona el
teorema 15.
NÃºmeros de Perron.. Para definir la dimensiÃ³n de un grafo de Mauldin-Williams introduciremos
los â€œnÃºmeros de Perron". Consideraremos Ãºnicamente el caso cuando el grafo sea fuertemente
conectado y estrictamente contractivo.
Dado un grafo de Mauldin-Williams, sea s un nÃºmero real positivo. Entonces los nÃºmeros de Perron s-dimensionales para el grafo son nÃºmeros
positivos qv , uno para cada nodo v âˆˆ V, tales que se cumpla:
qsu =

âˆ‘
vâˆˆV
e âˆˆ Euv

r (e)s Â· qsv

para todo u âˆˆ V.
Se puede probar bajo ciertas consideraciones sobre un grafo de Mauldin-Williams que existe un
Ãºnico nÃºmero real s â‰¥ 0 tal que los nÃºmeros de Perron qv asociados al grafo existen. Este nÃºmero
s serÃ¡ utilizado para definir la dimensiÃ³n del grafo. La existencia y unicidad de la dimensiÃ³n son
probadas en el teorema 17. Pero antes, recordemos algunos resultados de Ã¡lgebra lineal.
Sea A una matriz cuadrada. El radio espectral de A, R( A), es el mÃ¡ximo de los mÃ³dulos de todos
los valores propios de A. TambiÃ©n diremos que: A â‰¥ 0 si todas las entradas de A son no negativas,
A > 0 si todas las entradas de A son positivas. Una matriz A â‰¥ 0 se dice reducible si por medio
de permutaciones sobre las filas y las columnas, A se puede escribir de la forma:


B O
A=
C D
donde B y D son matrices cuadradas â€“con al menos una fila cada unaâ€“ y O es una matriz rectangular de ceros. Si una matriz no es reducible, entonces se dice que es irreducible.
AdemÃ¡s se necesita citar el teorema de Perron-Frobenius cuya prueba se puede encontrar en [15,
cap. 13].
Teorema 16. Sea A â‰¥ 0 una matriz cuadrada irreducible, y sea Î» âˆˆ

R. Entonces:

1. Si Î» = R( A), entonces existe un vector columna x > 0 con Ax = Ë˜x.
2. Si existe un vector columna x â‰¥ 0 con Ax = Ë˜x, entonces Î» = R( A).
3. Si existe un vector columna x â‰¥ 0 con Ax < Ë˜x, entonces Î» > R( A).
4. Si existe un vector columna x â‰¥ 0 con Ax > Ë˜x, entonces Î» < R( A).
Ahora enunciamos el teorema que garantiza la existencia y unicidad de la dimensiÃ³n de un grafo.
Teorema 17. Sea (V, E, i, t, r ) un grafo de Mauldin-Williams fuertemente conectado y estrictamente con-

tractivo. Existe un Ãºnico nÃºmero s â‰¥ 0 tal que existen nÃºmeros positivos qv uno para cada nodo del grafo
tales que se satisface
qsu =

âˆ‘
vâˆˆV
e âˆˆ Euv

r (e)s Â· qsv

(1.14)

23

para todo u âˆˆ V.
DemostraciÃ³n. Una prueba completa puede encontrarse en [9, p. 190]. En resumen esta prueba
usa el hecho de que si A(s) es la matriz con entradas Auv (s) = âˆ‘eâˆˆ Euv r (e)s y Î¦(s) = R( A(s))
entonces A(s) es irreducible âˆ€s â‰¥ 0, pues si suponemos que A(s) es reducible, entonces debe tener
la siguiente forma:


B ( s) O ( s)
A( s) =
C ( s) D ( s)
y si el grafo tiene n nodos, u1 , u2 , . . . , un y en este mismo orden se describen las filas y columnas
de A(s), entonces la matriz cuadrada B(s) es de orden k, donde 0 < k â‰¤ n âˆ’ 1. Al quedar el
bloque superior derecho de ceros, O(s), esto nos dice que los nodos u1 , u2 , . . . , uk pueden conectarse
Ãºnicamente entre ellos mismos, lo que contradice que el grafo sea fuertemente conectado pues no
se podrÃ¡ establecer un camino desde u1 hasta un . Usando el teorema 16 se prueba que Î¦(s) es
una funciÃ³n continua y que la ecuaciÃ³n Î¦(s) = 1 tiene una soluciÃ³n Ãºnica en el intervalo [0, âˆ[.
AdemÃ¡s en esta demostraciÃ³n se prueba que los nÃºmeros de Perron existen si y solo si Î¦(s) = 1.
El nÃºmero s dado por el teorema anterior lo llamaremos la dimensiÃ³n
del grafo de Mauldin-Williams.
Si tomamos el caso de dos nodos podemos encontrar explÃ­citamente la expresiÃ³n para Î¦(s), ya que
la matriz


A11 (s) A12 (s)
A( s) =
A21 (s) A22 (s)
tiene polinomio caracterÃ­stico pc (Î») = Î»2 âˆ’ traza( A(s)) Â· Î» + det( A(s)) y los valores propios para
este polinomio son


q
1
2
traza( A(s)) Â± (traza( A(s)) âˆ’ 4 det( A(s))
Î»=
2
ambos reales. Como necesitamos que pc (1) = 0 tenemos que s es la dimensiÃ³n del grafo si:
1=

A11 ( s ) + A22 ( s ) +

p

( A11 ( s ) + A22 ( s ))2 âˆ’ 4( A11 ( s ) A22( s ) âˆ’ A12 ( s ) A21( s ))
2

(1.15)

El Polvo en dos partes.. Considere el grafo definido por dos nodos {U, V } y cuatro aristas E =
{ a, b, c, d} y la lista de razones r a = 1/2, rb = 1/4, rc = 1/2, rd = 3/4, descrito en la Figura 1.8.
Podemos aplicar los resultados de esta secciÃ³n encontrando una lista de conjuntos invariante.

Figura 1.8

Grafo para el Polvo en dos partes.

Sean U0 , V0 ambos como el segmento de lÃ­nea que une el punto (0, 0) con (1, 0). Sea la aplicaciÃ³n
a de razÃ³n 21 que fija el punto (0, 0) y rota 30o . La aplicaciÃ³n b de razÃ³n 14 que fija el punto (1, 0) y
rota âˆ’60o . La aplicaciÃ³n c de razÃ³n 12 que fija el punto (0, 0) y rota 90o . Y por Ãºltimo la aplicaciÃ³n

24

AUTOSEMEJANZA

Figura 1.9

d de razÃ³n
obtienen

3
4

ConstrucciÃ³n del Polvo en dos partes.

que fija el punto (1, 0) y rota âˆ’120o . Algebraicamente, para un punto ( x, y) âˆˆ

a(x, y)

=

b(x, y)

=

c(x, y)

=

d(x, y)

=

R2 se

âˆš 
1 âˆš
3x âˆ’ y, x + 3y
4

âˆš
âˆš
1
x âˆ’ 3y + 7, 3 (1 âˆ’ x ) âˆ’ y
8
1
(âˆ’y, x )
2

âˆš âˆš
3 11
âˆ’ x âˆ’ 3y, 3 (1 âˆ’ x ) + y
8 3

Ahora defina recursivamente:
Un + 1
Vn+1

= a[Un ] âˆª b[Vn ]

= c[Un ] âˆª d[Vn ].

Esto define una sucesiÃ³n de aproximaciones que son mostradas en la Figura 1.9, ellas convergen
en la mÃ©trica Hausdorff a P; es mÃ¡s, podemos empezar con cualesquiera dos conjuntos compactos
no vacÃ­os U0 y V0 en 2 .

R

Figura 1.10 Polvo en dos partes.

Por el teorema 15 sabemos que existe un par de conjuntos compactos no vacÃ­os U, V subconjuntos
de 2 , satisfaciendo:

R

U
V

= a [U ] âˆª b [V ]
= c [U ] âˆª d [V ]

25

A este par de conjuntos U, V se le conoce como el Polvo en dos partes que denotamos por P, Figura
1.10.
Usando la igualdad (1.15) este grafo tiene dimensiÃ³n 1. En este caso, los nÃºmeros de Perron, uno
para cada nodo, son qu = 1/3 y qv = 2/3. Lo importante acerca de estos nÃºmeros es que son
positivos y que satisfacen las ecuaciones:
qu = r ( a ) qu + r ( b ) qv
qv = r ( c ) qu + r ( d ) qv .

2

SISTEMAS DE
NUMERACIÃ“N

Algunos conjuntos se pueden ver como los atractores de un sistema iterado de funciones pero
tambiÃ©n como el conjunto de elementos representables en un sistema de numeraciÃ³n. Esto permite
estudiarlos desde otra perspectiva. En esta secciÃ³n se presentan algunos de estos conjuntos.

2.1

Bases para nÃºmeros reales

Los enteros positivos se pueden representar en cualquier base entera b > 1 usando 0, 1, . . . , b âˆ’
1 como dÃ­gitos. Los sistemas decimal y binario son los mÃ¡s conocidos. Los enteros positivos y
negativos se pueden representar en cualquier base b < âˆ’1, usando los dÃ­gitos desde 0 a |b| âˆ’ 1.
Se generalizarÃ¡ esto; para ello se considera un nÃºmero b âˆˆ con |b| > 1 como base, y un conjunto
finito de nÃºmeros D = {d1 , d2 , Â· Â· Â· , dk }, llamados â€œdÃ­gitos", y se supone que 0 âˆˆ D. Los nÃºmeros
â€œenteros" en esta base, son los que tienen la forma:

C

M

âˆ‘ dj bj

(2.1)

j =0

con a j âˆˆ D. Sea W el conjunto formado por estos nÃºmeros. Las â€œfracciones" para este sistema tienen
la forma:
âˆ’1

dj bj

âˆ‘

(2.2)

j =âˆ’ âˆ

con d j âˆˆ D. Sea F el conjunto formado por las fracciones. Un nÃºmero arbitrario x âˆˆ
sentable en este sistema se puede ver como la suma de un entero y una fracciÃ³n, esto es
M

x=

âˆ‘

dj bj

j =âˆ’ âˆ

Es claro que para la convergencia de esta serie se debe tener que |b| > 1.

R, repre(2.3)

Teorema 18. Sea b âˆˆ

C tal que |b| > 1 y D = {d1, d2, Â· Â· Â· , dk }. Entonces el conjunto F de las fracciones

es compacto y no vacÃ­o.

DemostraciÃ³n. Considere las funciones f i ( x ) = di bâˆ’1 + bâˆ’1 x, como

R

| f i ( x ) âˆ’ f i (y)| = |b|âˆ’1 | x âˆ’ y|

se tiene que son semejanzas en 2 de razÃ³n ri = |b|âˆ’1 < 1, por lo que forman un sistema iterado
de funciones contractivo. Se probarÃ¡ que F es el atractor del sistema, es decir,
F=

k
[

f i [ F]

i =1
2
i
Para ello, sea y âˆˆ F entonces y = aâˆ’1 bâˆ’1 + âˆ‘âˆ’
i =âˆ’ âˆ a i b . Como a âˆ’1 âˆˆ D se tiene que a âˆ’1 = d j para
2
âˆ’
1
âˆ’
2
i
algÃºn j. Tomando x = aâˆ’2 b + aâˆ’3 b + Â· Â· Â· âˆˆ F se tiene que f j ( x ) = aâˆ’1 bâˆ’1 + âˆ‘âˆ’
i =âˆ’ âˆ a i b = y,
Sn
Sn
por lo que y âˆˆ f j [ F ] âŠ† i=1 f i [ F ]. Por otro lado, sea y âˆˆ i=1 f i [ F ], entonces y âˆˆ f j [ F ] para algÃºn j,
de esta forma
!

y = fj

âˆ’1

âˆ‘

a i bi

= d j b âˆ’1 +

i =âˆ’ âˆ

âˆ’2

âˆ‘

i =âˆ’ âˆ

a i +1 b i âˆˆ F

AsÃ­, F es el atractor y por el teorema 3 el conjunto invariante es compacto.



Corolario 4. La dimensiÃ³n de semejanza de F es s = lnln|kb| .

En el caso decimal o el binario se tiene que: W estÃ¡ formado por los nÃºmeros enteros no negativos,
F = [0, 1] y cualquier x âˆˆ [0, âˆ[ se puede escribir de la forma x = âˆ‘ jM=âˆ’âˆ a j b j .
Si se usa b = âˆ’2 y D = {0, 1}, los nÃºmeros de la forma (2.1) son los enteros, el conjunto de las
fracciones es [âˆ’2/3, 1/3]. Todo nÃºmero real tiene la forma (2.3).
En el sistema decimal o el binario algunos nÃºmeros no tienen representaciÃ³n Ãºnica, por ejemplo
0.1 = 0.09, sin embargo el conjunto de los nÃºmeros con representaciÃ³n mÃºltiple es numerable.
Pero ocurre que hay nÃºmeros que no tienen representaciÃ³n del todo. Por ejemplo, para b = 3
y D = {0, 2}, el nÃºmero 1/2 = (0.1)3 no tiene representaciÃ³n de la forma (2.3). De hecho los
nÃºmeros en [0, 1] que tienen representaciÃ³n de la forma (2.2) forman el conjunto de Cantor.
Es usual trabajar con bases enteras positivas, pero para representar nÃºmeros negativos se deben
usar bases negativas. Un artÃ­culo muy interesante que discute el uso de bases fraccionarias es [6].
Nos interesa extender estos resultados para representar nÃºmeros complejos en bases complejas.

C

con |b| > 1, y sea D un conjunto finito de nÃºmeros reales que incluyen al cero.
Entonces, o bien algunos nÃºmeros reales no tienen representaciÃ³n en la forma (2.3) o algunos nÃºmeros reales
tienen mÃ¡s de una expansiÃ³n en la forma (2.3).
Teorema 19. Sea b âˆˆ

DemostraciÃ³n. VÃ©ase [9, p. 84].



Lo que indica este teorema es que no existe una base en donde todos los nÃºmeros complejos puedan
ser representados en forma Ãºnica.

2.2

Bases para nÃºmeros complejos

Z

Se dice que el entero Gaussiano z = x + iy con x, y âˆˆ se puede expresar en la base compleja
b si este se puede escribir de la forma z = âˆ‘rk=0 ar br para algÃºn k âˆˆ , donde los nÃºmeros ar
son llamados los dÃ­gitos de la representaciÃ³n, y se escribe z = ( ak akâˆ’1 . . . a0 )b . El algoritmo para

Z

27

28

SISTEMAS DE NUMERACIÃ“N

representar nÃºmeros en una base entera se puede extender a bases complejas si el conjunto de
dÃ­gitos escogidos forman un sistema completo de residuos mÃ³dulo el cuadrado del mÃ³dulo de la
base.
Se darÃ¡ un algoritmo para representar nÃºmeros complejos en bases complejas, este algoritmo se
determina para enteros Gaussianos.
El siguiente teorema fundamenta el nÃºmero de dÃ­gitos que debe tener una base para que se puedan
representar todos los nÃºmeros complejos.
Teorema 20. Sea b âˆˆ

C, sea D un conjunto finito de nÃºmeros complejos que incluye al 0. Suponga que

| D | = k, que todo nÃºmero complejo se puede representar en este sistema y que la medida bidimensional de
Lebesgue del conjunto de los nÃºmeros con mÃºltiple representaciÃ³n es 0. Entonces |b|2 = k.

DemostraciÃ³n. Como todo nÃºmero complejo se puede representar en este sistema, se tiene que el
conjunto de la fracciones F cumple con 0 < L2 ( F ) < âˆ. Este conjunto es el atractor del sistema
iterado de funciones descrito en la prueba del teorema 18, y se sabe por el corolario 4, que su dimensiÃ³n de semejanza es ln k/ ln |b|. AdemÃ¡s el hecho de que la medida bidimensional de Lebesgue
del conjunto de los nÃºmeros con mÃºltiple representaciÃ³n es 0, significa que L2 ( f i [ F ] âˆ© f j [ F ]) = 0,
con esto se cumplen todas las hipÃ³tesis del teorema 5, por lo que la dimensiÃ³n de semejanza s es
igual a 2. Igualando se tiene que ln k/ ln |b| = 2 y despejando se obtiene el resultado.

Gauss demostrÃ³ que si n y m son primos relativos entonces los nÃºmeros 0, 1, . . . , n2 + m2 âˆ’ 1 forman un sistema completo de residuos mÃ³dulo |b|2 . MÃ¡s aÃºn, si n y m tienen un factor comÃºn,
entonces cualquier sistema completo de residuos mÃ³dulo b debe contener algunos nÃºmeros con
parte imaginaria distinta de cero. Una condiciÃ³n necesaria para que la base b = n + im represente
todos los enteros Gaussianos, usando sÃ³lo enteros como dÃ­gitos es que m = Â±1, dado que todas
las potencias de la base (n + im)r tienen su parte imaginaria divisible por m. Con esto, solo se
considerarÃ¡n bases de la forma âˆ’n Â± i con dÃ­gitos 0, 1, . . . , n2 .
Como ejemplo se considera como base al nÃºmero complejo b = âˆ’1 + i que provee una representaciÃ³n binaria de todos los nÃºmeros complejos. Algunas representaciones son
9 = (111000001)âˆ’1+i ya que (âˆ’1 + i )8 + (âˆ’1 + i )7 + (âˆ’1 + i )6 + 1 = 9,
5 âˆ’ 3i = (101110)âˆ’1+i.

Al conjunto de todas estas fracciones, que se denota con T, se le llama usualmente Twindragon3 ,
Figura 2.1 izquierda. Una construcciÃ³n de Ã©ste se encuentra en [16]. Note que este conjunto es el
atractor para el sistema iterado de funciones definido por f 0 ( x ) = bâˆ’1 x y f 1 ( x ) = bâˆ’1 + bâˆ’1 x y la
razÃ³n para ambas funciones es |(âˆ’1 + i )âˆ’1 | = âˆš1 , resolviendo la ecuaciÃ³n ( âˆš1 )s + ( âˆš1 )s = 1, se
2
2
2
tiene que s = 2.

2.3

RepresentaciÃ³n de los enteros Gaussianos

Se dice que el nÃºmero complejo b es una â€œbuena" base, si cada entero Gaussiano puede ser representado en la forma (2.1) en la base b, si esto no ocurre se dice que b es una â€œmala" base. Por
ejemplo en este sentido âˆ’2 es una buena base para pues todos los nÃºmeros enteros se pueden
representar en esta base de la forma (2.1), asÃ­: âˆ’1 = (11)âˆ’2, âˆ’9 = (1011)âˆ’2, y 7 = (11011)âˆ’2.
Para representar nÃºmeros complejos en bases complejas se ocupa un algoritmo de divisiÃ³n semejante a la divisiÃ³n entera. Se esboza aquÃ­ este mÃ©todo, para dividir q0 = a + bi por âˆ’n Â± i:

R

3 Se

le dÃ¡ este nombre pues estÃ¡ formado de dos copias del DragÃ³n de Heighway.

29

Figura 2.1

Twindragon y teselaciÃ³n fractal del plano.

a + bi
r0

âˆ’n Â± i
Â± b âˆ’ na + nr0
âˆ“ s0 i = : q 1
n2 + 1

donde r0 y s0 son el residuo y el cociente de dividir a + nb por n2 + 1, recordando que el residuo
es no negativo y menor que n2 + 1. Se divide ahora q1 por âˆ’n Â± i y se obtiene r1 , siguiendo este
proceso, que para âˆ’n Â± i se sabe que es finito por ser buena base, hasta que qk = 0 se tiene que
a + bi = (rk rkâˆ’1 . . . r0 )âˆ’nÂ±i . Como ejemplo, el nÃºmero complejo âˆ’6 + 31i se representa en la base
âˆ’2 + i como sigue:
âˆ’6 + 31i
1

âˆ’2 + i
9 âˆ’ 11i
2

âˆ’2 + i
âˆ’5 + 3i
1

âˆ’2 + i
3 + 0i
3

âˆ’2 + i
0

asÃ­ âˆ’6 + 31i = (3121)âˆ’2+i, es decir âˆ’6 + 31i = 3(âˆ’2 + i )3 + 1(âˆ’2 + i )2 + 2(âˆ’2 + i )1 + 1(âˆ’2 + i )0 .
Otras representaciones son por ejemplo: âˆ’1 = (144)âˆ’2+i, 8 + 3i = (1204)âˆ’2+i, 5 = (1310)âˆ’2+i, y
10 = (133120)âˆ’2+i. De estas dos Ãºltimas representaciones se pueden inferir las reglas de la suma
en esta base.
Se considerarÃ¡n algunas bases de nÃºmeros complejos y se verÃ¡ la forma que tiene el conjunto de
las fracciones en esta base.
Sea b = âˆ’1 + i, se ha mencionado que el conjunto de las fracciones T, con los dÃ­gitos {0, 1} se llama
Twindragon. Este conjunto representa en el plano complejo todos los nÃºmeros cuya representaciÃ³n
es (0.a1 a2 . . . an . . . )âˆ’1+i . Ver Figura 2.1.
Se puede cubrir el plano con una cantidad numerable de conjuntos idÃ©nticos a este conjunto, de
la forma T + w donde w es un entero gaussiano, y como todos los enteros gaussianos se pueden
representar en esta base, se puede obtener un mosaico o â€œteselaciÃ³n" fractal del plano, Figura 2.1
derecha. Se dice fractal pues las fronteras de estos conjuntos son fractales [27], cuya dimensiÃ³n
fractal es aproximadamente 1.52.
Con la base b = 1 âˆ’ i, aunque su conjunto de fracciones es simÃ©trico a T, no se pueden representar
todos los enteros gaussianos, por ejemplo a âˆ’1:

âˆ’1 = (âˆ’1 âˆ’ i )(1 âˆ’ i ) + 1

âˆ’1 âˆ’ i = (âˆ’i )(1 âˆ’ i ) + 0
âˆ’i
âˆ’i

= (âˆ’i )(1 âˆ’ i ) + 1
= (âˆ’i )(1 âˆ’ i ) + 1

30

SISTEMAS DE NUMERACIÃ“N

este procedimiento no es finito, de manera que no es posible representar a âˆ’1 en esta base con los
dÃ­gitos 0 y 1.
KÃ¡tai y SzabÃ³ probaron en [24] que los Ãºnicos enteros gaussianos que pueden ser usados para
representar todos los nÃºmeros complejos, usando nÃºmeros naturales como dÃ­gitos son âˆ’n + i y
âˆ’n âˆ’ i para n entero positivo. Para b = 2 âˆ’ i con D = {0, 1, 2, 3, 4}, la representaciÃ³n del conjunto

Figura 2.2

Fracciones con b = 2 âˆ’ i

de las fracciones en el plano complejo es una curva dragÃ³n, Figura 2.2. Mandelbrot la utilizÃ³ en
[27] como un modelo para responder a la pregunta Â¿cuÃ¡nto mide la costa de BretaÃ±a?

Figura 2.3

1
Fracciones con b = âˆ’ 21 + 32 i y b = âˆ’ 10
+i

Se pueden generar diferentes curvas dragÃ³n, considerando cualquier entero gaussiano como base,
sin embargo, al considerar bases que no son de este tipo se obtienen conjuntos interesantes, por
1
ejemplo, al considerar como base b = âˆ’ 10
+ i, el conjunto de las fracciones en esta base con D =
{0, 1} se representa en el plano complejo en la Figura 2.3 derecha.
Los conjuntos de fracciones en la Figura 2.3, estÃ¡n representados con los nÃºmeros complejos cuya
expansiÃ³n binaria en estas bases es de la forma (0.a1 a2 . . . a14 )b con ai âˆˆ {0, 1}, es decir, es una
aproximaciÃ³n de los conjuntos reales. En algunos se muestran como figuras disconexas, sin embargo, solamente para b = âˆ’ 12 + 32 i lo es, enâˆšeste caso se tiene que |b| â‰ˆ 1.58 y en [3], se prueba que
los conjuntos de fracciones tales que |b| > 2 son totalmente disconexos.
Usando el programa A.1.1, hecho en Mathematica, se obtuvo la Figura 2.2. Cambiando el conjunto
de dÃ­gitos y la base, se obtienen las Figuras 2.3, 2.4.

2.4

Ejemplos de conjuntos de fracciones

31

En esta parte se presentarÃ¡n diferentes tipos de conjuntos de fracciones que se obtienen de variar
bases y sus conjuntos de dÃ­gitos; nos interesa los conjuntos de fracciones para nÃºmeros reales y
nÃºmeros complejos.
Fracciones de Eisenstein..
Considere ahora dÃ­gitos complejos, por ejemplo D = {0, 1, Ï‰, Ï‰ 2}
âˆš
donde Ï‰ = 12 (âˆ’1 + i 3) y b = âˆ’2 da una representaciÃ³n de todos los nÃºmeros complejos. Al
conjunto de todas las fracciones se le llama Fracciones de Eisenstein, Figura 2.4.

Figura 2.4

Fracciones de Eisenstein

Note que este conjunto es el atractor para el sistema iterado de funciones definido por f 0 ( x ) = âˆ’ 12 x,
f 1 ( x ) = âˆ’ 21 (1 + x ), f 2 ( x ) = âˆ’ 12 (Ï‰ + x ) y f 3 ( x ) = âˆ’ 12 (Ï‰ 2 + x ). La razÃ³n para estas funciones es
|(âˆ’2)âˆ’1 | = 12 , resolviendo la ecuaciÃ³n 4( 12 )s = 1 se tiene que la dimensiÃ³n de semejanza es s = 2.
Note que todos los dÃ­gitos no nulos tienen mÃ³dulo igual a 1.
El conjunto de Cantor como conjunto de fracciones.. Si se usan los dÃ­gitos D = {0, 1, 2} y la
base b = 3, el conjunto de las fracciones es el intervalo [0, 1], asÃ­, la representaciÃ³n triÃ¡dica para
cualquier x âˆˆ [0, 1] es (0.a1 a2 . . . ak . . . )3 , con ai âˆˆ {0, 1, 2}, âˆ€i âˆˆ . En el teorema 6 del capÃ­tulo
anterior, se probÃ³ que x âˆˆ C si y solo si se puede representar en base 3 utilizando solamente 0 y 2
como dÃ­gitos.

N

El triÃ¡ngulo de SierpiÂ«ski como conjunto de fracciones.. Al describir el triÃ¡ngulo de SierpinÌski se
usÃ³ la representaciÃ³n de las coordenadas del plano en base 2, esto nos permite dar una descripciÃ³n
exacta de cuÃ¡les son puntos de S. Se puede encontrar un subconjunto de los nÃºmeros complejos
a partir de las coordenadas del triÃ¡ngulo de SierpinÌski e identificar este conjunto con el triÃ¡ngulo
mismo, de esta manera si ( x, y) son las coordenadas de un punto en S se dice que el nÃºmero
complejo x + iy pertenece al triÃ¡ngulo de SierpinÌski. Si se usan los dÃ­gitos D = {0, 1, i } con b = 2
como base, se puede describir el conjunto de una forma sencilla.
ProposiciÃ³n 11. El conjunto de las fracciones de nÃºmeros complejos para b = 2 y D = {0, 1, i } es el

triÃ¡ngulo de SierpinÌski S.

DemostraciÃ³n. Recordemos la construcciÃ³n por tremas. Se empieza con S0 , los vÃ©rtices de S0 , son
0, 1 e i. Como se reduce en cada paso de la construcciÃ³n de S los lados a la mitad, pertenecen
1
i
1
i
2 = (0.1)2 , 2 = (0.i )2 y 2 + 2 = (0.1i)2 en general al considerar las coordenadas de los puntos
( x, y) en su expansiÃ³n en base 2, x = (0.a1 a2 Â· Â· Â· )2 y y = (0.b1 b2 Â· Â· Â· )2 con ai , bi âˆˆ {0, 1}, i âˆˆ . Se
sabe por el teorema 11 que todas las expansiones de las coordenadas no tienen un uno en la misma

N

32

SISTEMAS DE NUMERACIÃ“N

posiciÃ³n, por lo que se puede representar
âˆ

x + iy =

âˆ‘ (ak + ibk )2âˆ’k

k =1

donde ( ak + ibk ) âˆˆ D.



Algunos nÃºmeros del triÃ¡ngulo de SierpinÌski son:
3
1
+i
4
8
272
68
+i
341
341
7
10
+i
9
63
3
17
+i
8
32

= (0.110)2 + (0.00i )2 = (0.11i )2
= (0.1100110000)2 + (0.00ii00ii00)2 = (0.11ii11ii00)2
= (0.110001)2 + (0.00i0i0)2 = (0.11i0i1)2
= (0.01100)2 + (0.i000i )2 = (0.i110i )2

Es claro que S no va a rellenar el plano pues el nÃºmero mÃ­nimo de dÃ­gitos que debe tener esta base
para que todo nÃºmero complejo se pueda representar es 4, pues el teorema 20 da una condiciÃ³n
necesaria, ademÃ¡s 2 no es una buena base para los nÃºmeros reales por lo que no serÃ¡ Ãºtil tampoco
para los complejos.
Otros conjuntos similares.. Si se completa el nÃºmero de dÃ­gitos en la base 2 resultan conjuntos
de fracciones que presentan alguna semejanza con el triÃ¡ngulo de SierpinÌski pero que tampoco
pueden ser usados para representar a todos los nÃºmeros complejos. Considere D = {0, 1, i, âˆ’1}
con b = 2. El conjunto de fracciones en esta base puede ser construido por tremas de la siguiente forma; tome un triÃ¡ngulo rectÃ¡ngulo isÃ³sceles con la base en la hipotenusa, Ãºnase los puntos
medios de cada lado, el triÃ¡ngulo queda dividido en cuatro triÃ¡ngulos congruentes, elimine el interior del triÃ¡ngulo central y agrÃ©guese el triÃ¡ngulo formado por los puntos medios de las bases de
los triÃ¡ngulos que han quedado, de la misma forma continÃºese con el proceso en cada uno de los
cuatro triÃ¡ngulos. El Ã¡rea eliminada en cada paso es 81 del Ã¡rea total por lo que tambiÃ©n tiende a
cero.
Ahora se considerarÃ¡ el conjunto de los dÃ­gitos
1
D = {0, 1, i, âˆ’ âˆš (1 + i )}
2
con la base b = 2, el nÃºmero que se ha usado para completar tiene mÃ³dulo igual a 1 y se encuentra
en el tercer cuadrante, el mÃ³dulo para los dÃ­gitos es 1 para los no nulos.
El conjunto de las fracciones tambiÃ©n se pueden construir por un proceso similar a los anteriores,
solamente que en este caso se elimina tambiÃ©n el triÃ¡ngulo central y se agrega el triÃ¡ngulo formado
por los puntos medios de los segmentos que forman cada vÃ©rtice con el circuncentro, cada uno de
estos segmentos mide igual y el triÃ¡ngulo formado es semejante con razÃ³n de proporciÃ³n 12 . En
ambos casos se tienen figuras en alguna forma parecidas al triÃ¡ngulo de SierpinÌski, pero por la
base no se pueden representar todos los complejos.

3

DIMENSIÃ“N HAUSDORFF

En esta secciÃ³n se define un fractal en el sentido original de Mandelbrot. Esta se harÃ¡ comparando
la dimensiÃ³n Hausdorff y una dimensiÃ³n topolÃ³gica de un conjunto dado. La dimensiÃ³n Hausdorff fue introducida por Felix Hausdorff, en 1919, cuando trabajÃ³ con conjuntos de dimensiÃ³n
fraccionaria, mientras que la dimensiÃ³n topolÃ³gica toma valores enteros o es infinita.

3.1

DimensiÃ³n topolÃ³gica

AquÃ­ se define una dimensiÃ³n topolÃ³gica, es decir, invariante bajo homeomorfismos, y se verÃ¡ que
se pueden caracterizar los conjuntos con dimensiÃ³n cero.
Un subconjunto de un espacio mÃ©trico se llama clopen1 si es cerrado
y abierto, es decir, si su frontera es vacÃ­a. AdemÃ¡s se dice que un espacio mÃ©trico es cero-dimensional si existe una base para los abiertos
formada por conjuntos

A un espacio mÃ©trico S, se le asocia un nÃºmero entero o infinito, denotada por ind S, que se llama dimensiÃ³n inductiva pequeÃ±a y estÃ¡
definida recursivamente asÃ­: ind âˆ… = âˆ’1, para k â‰¥ 0 se dice que
ind S â‰¤ k si y solo si existe una base para los abiertos de S formada
por conjuntos U que cumplen ind âˆ‚U â‰¤ k âˆ’ 1. AsÃ­ que ind S = k si
y solo si ind S â‰¤ k y ind S 6â‰¤ k âˆ’ 1. Por Ãºltimo si ind S â‰¤ k no es
cierto para todo k, se dice que ind S = âˆ.
Teorema 21. Sean S y T espacios topolÃ³gicos. Si T âŠ† S entonces ind T â‰¤ ind S y si S y T son homeomorfos

entonces ind S = ind T.
1 ContracciÃ³n

del inglÃ©s â€œclosed and open"

33

34

DIMENSIÃ“N HAUSDORFF

DemostraciÃ³n. [9, p. 82].



Teorema 22. Si S es separable, entonces ind S = 0 si y solo si S es homeomorfo a algÃºn subconjunto de

{0, 1}(Ï‰ ).

DemostraciÃ³n. VÃ©ase [9, p. 83].



En la proposiciÃ³n 9 se probÃ³ que C, el conjunto de Cantor de los tercios centrales es homeomorfo a
( E(Ï‰ ), Ï1/3 ) por lo que ind C = 0. Todos los espacios que cumplen con el teorema 22 son llamados
genÃ©ricamente â€œConjuntos de Cantor", aunque no todos los conjuntos de Cantor tienen medida en
el sentido de Lebesgue igual a cero, [48].
ProposiciÃ³n 12. El triÃ¡ngulo de SierpinÌski S, cumple ind S = 1.

DemostraciÃ³n. Es claro que ind S no puede ser 2, pues el triÃ¡ngulo de SierpinÌski no contiene a
alguna bola de radio r > 0. Y no es 0 pues una base para los abiertos de S formada por las intersecciones de S con cada triÃ¡ngulo de Sn , no tienen frontera vacÃ­a, por lo que no son clopenes.


3.2

GeneraciÃ³n de medidas

En esta parte se recordarÃ¡n algunos resultados sobre medidas. Estos se usarÃ¡n para construir a
partir de una funciÃ³n no negativa, una medida. SerÃ¡ de utilidad especialmente para definir la
medida Hausdorff que se ocuparÃ¡ en 3.3. Nos interesa este tipo de enfoque por su construcciÃ³n.
Sea X un conjunto cualquiera. Recordemos que si F es una Ïƒ-Ã¡lgebra de subconjuntos de X, una
medida sobre F es una funciÃ³n M : F â†’ [0, âˆ] que cumple lo siguiente
1. M(âˆ…) = 0;
2. Si An es una sucesiÃ³n disjunta de conjuntos, entonces
!
âˆ

M

[

nâˆˆ

N

An

=

âˆ‘ M( An )

(3.1)

n =1

AdemÃ¡s, si P denota el conjunto de partes de X, una medida exterior sobre X es una funciÃ³n
M : P â†’ [0, âˆ] que satisface las siguientes condiciones
1. M(âˆ…) = 0;
2. Si A âŠ† B, entonces M( A) â‰¤ M( B);
3. M (

S

nâˆˆ

N An ) â‰¤ âˆ‘âˆn=1 M( An ).

Teorema 23. Teorema del MÃ©todo I. Sea X un conjunto, A una familia de subconjuntos de X que lo

cubren. Sea C : A â†’ [0, âˆ] una funciÃ³n. Entonces, existe una Ãºnica medida exterior M sobre X tal que
1. M( A) â‰¤ C ( A) para todo A âˆˆ A,

2. Si N es otra medida exterior sobre X con N ( A) â‰¤ C ( A) para todo A âˆˆ A, entonces N ( B) â‰¤ M( B)
para todo B âŠ† X.

DemostraciÃ³n. [9, p. 134]. En esta prueba se da una fÃ³rmula explÃ­cita para M. Si D es un cubrimiento numerable de B con subconjuntos de A, M( B) = inf âˆ‘ AâˆˆD C ( A).


35

Una medida exterior M sobre un espacio mÃ©trico ( X, Ï), se llama medida exterior mÃ©trica sii M( A âˆª B) = M( A) + M( B) para conjuntos A y B cuya distancia entre ellos es positiva. Se dice que es finita
si M( A) < âˆ.
La razÃ³n de definir una medida exterior mÃ©trica, y eventualmente una medida mÃ©trica al restringir
a los conjuntos medibles, es porque todo conjunto de Borel es medible, hecho que no se cumple
con cualquier medida exterior.
Teorema 24. Sea M una medida exterior mÃ©trica sobre un espacio mÃ©trico S, entonces todo conjunto de
Borel en S es M-medible.

DemostraciÃ³n. VÃ©ase [9, p. 138].



Si M es una medida mÃ©trica finita sobre un espacio mÃ©trico compacto S, se puede probar que

M( E) = inf{M(U ) : E âŠ† U, abierto}
ademÃ¡s

M( E) = sup{M(K ) : K âŠ† E, compacto}

para todo conjunto medible E âŠ† S, asÃ­ que dado Îµ > 0 existe un conjunto compacto K y un abierto
U con K âŠ† E âŠ† U tal que M(U \ K ) < Îµ para todo Îµ > 0, pues M(U ) âˆ’ 2Îµ < M( E) < M(K ) + 2Îµ y
como M(K ) + M(U \ K ) = M(U ) < M(K ) + Îµ de donde M(U \ K ) < Îµ. Esto dice que para todo
conjunto medible, se pueden encontrar un conjunto compacto K y un abierto U con K âŠ† E âŠ† U tal
que la medida de su diferencia es tan pequeÃ±a como se quiera.
MÃ©todo II.. Este es mÃ¡s complicado que el MÃ©todo I, pero lo importante es que se construye una
medida exterior mÃ©trica.
ProposiciÃ³n 13. Sean A âŠ† B dos cubrimientos de X y C : B â†’ [0, âˆ] una funciÃ³n sobre conjuntos dada.

Si M es la medida exterior sobre X definida a partir del MÃ©todo I, teorema 23, por C y A, y si N es la medida
exterior sobre X definida a partir del MÃ©todo I por C y B entonces N ( A) â‰¤ M( A) para todo A âŠ† X.
DemostraciÃ³n. Sea D un cubrimiento numerable de A, por el teorema 23 tenemos

M( B) = inf

âˆ‘

C ( A ),

A âˆˆD

como D es un cubrimiento numerable de B se tiene que N ( B) = inf âˆ‘ AâˆˆD C ( A) y como el Ã­nfimo
se toma uno sobre un subconjunto del otro, se tiene que N ( B) â‰¤ M( B).

Sea A una familia de subconjuntos de un espacio mÃ©trico S. Suponga
que para todo x âˆˆ S y Îµ > 0 existe A âˆˆ A con x âˆˆ A y diam A â‰¤ Îµ.
Suponga que C : A â†’ [0, âˆ] es una funciÃ³n sobre conjuntos dada. Sea
AÎµ = { A âˆˆ A : diam A â‰¤ Îµ}. Sea MÎµ la medida exterior sobre X
definida a partir del MÃ©todo I por C y AÎµ . Se define

M( E) = lim MÎµ ( E) = sup MÎµ ( E)
Îµ â†’0

Îµ >0

de esta forma M es una medida exterior. A esta construcciÃ³n se le llama
el MÃ©todo II.

36

DIMENSIÃ“N HAUSDORFF

Teorema 25. La funciÃ³n sobre conjuntos M definida por el MÃ©todo II es una medida exterior mÃ©trica.

DemostraciÃ³n. VÃ©ase [9, p. 141].



Teorema 26. Sea E ( Ï‰ ) un espacio de hileras infinitas. Suponga que nÃºmeros no negativos wÎ± satisfacen

wÎ± = âˆ‘eâˆˆ E wÎ±e para Î± âˆˆ E(âˆ—) . Entonces la medida exterior, M, definida por el teorema 23 para la funciÃ³n
sobre conjuntos C ([Î±]) = wÎ± es una medida exterior mÃ©trica sobre E(Ï‰ ) que cumple con M([Î±]) = wÎ± . AsÃ­
0 < M( E(Ï‰ )) < âˆ.
DemostraciÃ³n. VÃ©ase [9, p. 143].

3.3



Medida Hausdorff

Sea S un espacio mÃ©trico y s un nÃºmero positivo. La medida exterior Hausdorff s-dimensional es la medida exterior definida por el
mÃ©todo II, a partir de la funciÃ³n sobre conjuntos C ( A) = diam ( A)s ,
s
la cual se denota por H . La restricciÃ³n a los conjuntos medibles es llamada medida Hausdorff s-dimensional, y se escribe H s .
s

Dado que H es construido por el mÃ©todo II, esta es una medida exterior mÃ©trica. AsÃ­ en particular, todo conjunto de Borel es medible (abiertos, cerrados, compactos etc.). El teorema 23 da una
fÃ³rmula explÃ­cita de la definiciÃ³n.
Sea Îµ un nÃºmero positivo. El cubrimiento A es un Îµ-cubrimiento si y
solo si el diam ( A) â‰¤ Îµ para todo A âˆˆ A. En este caso defina:
s

HÎµ ( F ) = inf

âˆ‘

diam ( A)s

(3.2)

A âˆˆA

donde el Ã­nfimo se toma sobre todos los Îµ-cubrimientos numerables A
de F.
s

s

ObsÃ©rvese que si Îµ 1 â‰¤ Îµ 2 entonces H Îµ 1 ( F ) â‰¥ H Îµ 2 ( F ) como se tiene de la proposiciÃ³n 13. Finalmente,
de la definiciÃ³n 3.2 se tiene:
s

s

s

H ( F ) = lim H Îµ ( F ) = sup H Îµ ( F )
Îµ â†’0

(3.3)

Îµ >0

es la medida exterior Hausdorff s-dimensional del conjunto F. NÃ³tese que si F es un conjunto finito
o numerable, entonces H s ( F ) = 0 para todo s > 0, ya que se puede tomar el propio conjunto como
un Îµ-cubrimiento de diÃ¡metro igual a cero.
Teorema 27. En

R la medida Hausdorff unidimensional H1 coincide con la medida de Lebesgue L.

DemostraciÃ³n. VÃ©ase [9, p. 149].



Para un conjunto F dado, la medida Hausdorff H s ( F ) se comporta como una funciÃ³n de s decreciente que toma a lo sumo tres valores. El siguiente teorema muestra esto y otros detalles mÃ¡s
importantes.

37
Teorema 28. Sea F un conjunto de Borel. Sea 0 < s < t, si H s ( F ) < âˆ entonces H t ( F ) = 0, si H t ( F ) > 0

entonces H s ( F ) = âˆ.

s

DemostraciÃ³n. Si diam ( A) â‰¤ Îµ â‡’ H Îµ ( A) â‰¤ (diam ( A))t â‰¤ Îµtâˆ’s Â· (diam ( A))s . Por lo tanto por el
t
s
teorema del mÃ©todo I H Îµ ( F ) â‰¤ Îµtâˆ’s Â· HÎµ ( F ). Ahora si H s ( F ) es finito entonces H t ( F ) â‰¤ limÎµâ†’0 Îµtâˆ’s Â·
s
s
H Îµ ( F ) = 0 Â· H Îµ ( F ) = 0. La segunda afirmaciÃ³n es la contrapositiva.

Esto significa que hay un valor crÃ­tico s0 en [0, âˆ] tal que H s ( F ) = âˆ si s < s0 y H s ( F ) = 0 si
s > s0 .
Al valor s0 se le llama la dimensiÃ³n Hausdorff o dimensiÃ³n fractal
del conjunto F, que se denota por dim( F ).
Es posible que H s ( F ) = 0, âˆ€s > 0 por lo que dim( F ) = 0. De la misma forma puede suceder que
dim( F ) = âˆ.
Se puede usar en los cubrimientos conjuntos abiertos, cerrados o hasta subconjuntos del propio
conjunto al que le quiere calcular la dimensiÃ³n Hausdorff. Si un conjunto es compacto, se pueden
usar cubiertas finitas para calcular la dimensiÃ³n del compacto. En particular se puede asumir que
los cubrimientos usan sÃ³lo subconjuntos de F.
La dimensiÃ³n Hausdorff satisface propiedades esperadas para una definiciÃ³n de dimensiÃ³n tales
como las de los teoremas 29 y 33 y la proposiciÃ³n 18; ademÃ¡s se cumple que si F es un conjunto
numerable entonces dim( F ) = 0 y dim( d ) = d. Existen otras dimensiones fractales que cumplen
con estas mismas propiedades.

R

Teorema 29. Sean A, B y ( Ai ) i âˆˆN, conjuntos de Borel.

(1) Si A âŠ† B entonces, dim( A) â‰¤ dim( B),
(2) dim

S

kâˆˆ

N Ak = sup{dim( Ak ), k âˆˆ N}.

DemostraciÃ³n. (1) Suponga que A âŠ† B, si s > dim( B) entonces se cumple que H s ( A) â‰¤ H s ( B) = 0,
por lo tanto la dim( A) â‰¤ s, esto es cierto para todo s > dim( B) asÃ­ que dim( A) â‰¤ dim( B).
(2) Si s > sup{dim( Ak ), k âˆˆ } entonces s > dim( Ak ) luego H s ( Ak ) = 0, por lo que


[
Hs
Ak â‰¤ âˆ‘ H s ( Ak ) = 0

N

kâˆˆ

N

kâˆˆ

N

esto es cierto para todo s > supkâˆˆN {dim( Ak )} asÃ­
[

sup{dim( Ak )} â‰¥ dim
kâˆˆ

y como Ak âŠ†

S

kâˆˆ

N

kâˆˆ

N Ak se tiene que
dim( Ak ) â‰¤ dim(

por lo que supkâˆˆN {dim( Ak )} â‰¤ dim(

S

kâˆˆ

N A k ).

[

kâˆˆ

N

N

Ak

!

Ak )



Teorema 30. Sea f : S â†’ T una semejanza con razÃ³n r > 0, sea s un nÃºmero real positivo, y sea F âŠ† S un

conjunto de Borel entonces, H s ( f [ F ]) = r s H s ( F ). AsÃ­ la dim( f [ F ]) = dim( F ).

DemostraciÃ³n. Sea T = f [S]. Como f es inyectiva sobre el Ã¡mbito, es biyectiva y posee inversa f âˆ’1 .
Como para A âŠ† S se cumple que diam ( f [ A]) = r diam ( A), entonces si A es un Îµ-recubrimiento
para F âŠ† S entonces f [ A], A âˆˆ A, es un rÎµ-recubrimiento para f [ F ] âŠ† T entonces
s

H ( f [ A]) â‰¤ diam ( f [ A])s = r s (diam ( A))s

38

DIMENSIÃ“N HAUSDORFF

s

s

Por el teorema del mÃ©todo I se tiene HrÎµ ( f [ F ]) â‰¤ r s H Îµ ( F ) y viceversa si B âŠ† A es un rÎµ-recubrimiento
para f [ F ], f âˆ’1 [ B] es un Îµ-recubrimiento para F entonces
s

HÎµ ( f âˆ’1 [ B]) â‰¤ (diam ( f âˆ’1 [ B]))s = r âˆ’s (diam ( B))s
s

s

por lo tanto r s H Îµ ( F ) â‰¤ HrÎµ f [ F ] por lo que son iguales y haciendo Îµ â†’ 0 se obtiene H s ( F ) =
r s H s ( f [ F ]) y dim( f [ F ]) = dim( F ).

Los elementos de esta demostraciÃ³n son los mismos para la demostraciÃ³n del siguiente resultado
y por esto se omite; se puede consultar [11, p. 27].
ProposiciÃ³n 14. Sea F âŠ†

c| x

âˆ’ y|Î±

Rn y suponga que f : F â†’ Rm satisface la condiciÃ³n de HÃ¶lder | f (x) âˆ’ f (y)| â‰¤

con c y Î± positivos. Entonces para cada s se cumple

H s/Î± ( f [ F ]) â‰¤ cs/Î± H s ( F )
ProposiciÃ³n 15. Sea f : S â†’ T una funciÃ³n y sea A âŠ† S un conjunto de Borel:

(1) Si f es de crecimiento acotado entonces dim( f [ A]) â‰¤ dim( A).
(2) Si f es de decrecimiento acotado entonces dim( f [ A]) â‰¥ dim( A).

DemostraciÃ³n. (1) Como diam ( f [ A]) = sup{Ï( f ( x ), f (y)) : x, y âˆˆ A} â‰¤ sup{rÏ( x, y) : x, y âˆˆ
A} = r sup{Ï( x, y), x, y âˆˆ A} = r diam ( A) y como en la primera parte de la prueba del teorema
30 se concluye que dim( f [ A]) â‰¤ dim( A). La parte (2) es totalmente anÃ¡loga.


R

R

n y suponga que f : F â†’
m satisface la ecuaciÃ³n (1.1). Entonces dim f [ F ] â‰¤
1
dim F.
Î±
DemostraciÃ³n. Si s > dim F se tiene que H s ( F ) = 0, de la proposiciÃ³n 14 se tiene que H s/Î± ( f [ F ]) â‰¤
s
1
cs/Î± H s ( F ) = 0, de donde dim f [ F ] â‰¤ para todo s > dim F, asÃ­ dim f [ F ] â‰¤ dim F.

Î±
Î±

ProposiciÃ³n 16. Sea F âŠ†

Rd con dim F < 1 entonces F es totalmente desconectado.
Sean x y y puntos distintos de F. Defina f : Rd â†’ [0, âˆ[ por f (z) = kz âˆ’ x k, nÃ³tese

ProposiciÃ³n 17. Si F âŠ†

DemostraciÃ³n.
que f ( x ) = 0 y f (y) > 0. De la desigualdad triangular se tiene que k f (z) âˆ’ f (w)k â‰¤ kz âˆ’ x k,
de la proposiciÃ³n 15 se ve que dim( f [ A]) â‰¤ dim( A) â‰¤ 1, con lo que f [ F ] es un subconjunto de
[0, âˆ[ de medida en el sentido de Lebesgue cero y asÃ­ su complemento es denso en [0, âˆ[. Por la
densidad,
un r 6âˆˆ f [ F ] que cumpla con 0 < r < f (y) y se tiene que F =
h
i se puede
h encontrar
i
f âˆ’1 [0, r [

[

f âˆ’1 ]r, âˆ[ , que son dos abiertos disjuntos que incluyen a x y y respectivamente. 
Un fractal es un conjunto tal que ind ( A) < dim( A).

En las siguientes proposiciones se verÃ¡ como el espacio de hileras E(Ï‰ ) dependiendo de la mÃ©trica
que se use puede tener diferentes dimensiones Hausdorff.
Teorema 31. Si E = {0, 1} entonces dim( E ( Ï‰ ) , Ï1/2 ) = 1.

DemostraciÃ³n. [9, p. 151]



Como en el teorema 22 se viÃ³ que ind ( E(Ï‰ ) ) = 0 se concluye que E(Ï‰ ) es un fractal.
Teorema 32. Sea E un alfabeto de n letras. Suponga que nÃºmeros no negativos wÎ± satisfacen

wÎ± =

âˆ‘ wÎ±e
eâˆˆ E

(3.4)

39

para Î± âˆˆ E(âˆ—) Sea M la medida del mÃ©todo I con M([Î±]) = wÎ± . Si Ï es una mÃ©trica en E(Ï‰ ) y s > 0
satisface M([Î±]) = (diam ([Î±]))s para todo Î± âˆˆ E(âˆ—) . Entonces M( B) = H s ( B) para todo conjunto de
Borel en E(Ï‰ ).
DemostraciÃ³n. Tome A = {[Î±]} para diam [Î±] â‰¤ Îµ y la funciÃ³n sobre conjuntos C : A â†’ [0, âˆ]
definida por C ([Î±]) = (diam [Î±])s y aplique la construcciÃ³n del Metodo II.

ProposiciÃ³n 18. La dimensiÃ³n Hausdorff de

R es 1.

DemostraciÃ³n. Por el teorema 27 se tiene que H1 ([0, 1]) = L([0, 1]) = 1. Por lo tanto dim[0, 1] = 1.
Ahora [0, 1] âŠ† , asÃ­ dim( ) â‰¥ dim[0, 1] = 1. Si s > 1, entonces H s ([0, 1]) = 0. Los intervalos
[n, n + 1] son isomÃ©tricos a [0, 1], se sigue que H s ([n, n + 1]) = 0. Por lo tanto:

R

R

H s ( R) â‰¤

R

âˆ

âˆ‘
n =âˆ’ âˆ

H s ([n, n + 1]) = 0

R

Esto significa que dim( ) â‰¤ s. Pero esto es correcto para cualquier s > 1, asÃ­ dim( ) â‰¤ 1. Por lo
tanto se ha visto que dim( ) = 1.


R

R

De donde no es un fractal.
Dado que la medida de Lebesgue es Ãºtil para calcular la dimensiÃ³n de , no es difÃ­cil adivinar que
L2 sea Ãºtil para computar dim 2 . En general dim d = d.
La medida Hausdorff H d ( B), de cualquier conjunto de Borel en d es un mÃºltiplo de la medida de
Lebesgue Ld para este mismo conjunto [11, p. 26]. El factor de multiplicaciÃ³n es Ï€ d/2 /2d Î“(d/2), el
volumen de la bola d-dimensional de diÃ¡metro 1, y Î“ es la funciÃ³n Gama de Euler.

R

Teorema 33. Sea B âŠ†

R

R

R

Rd . Si B tiene interior no vacÃ­o entonces dim( B) = d.

DemostraciÃ³n. Se sabe, por el teorema 29, que si existe BÎµ ( x ) âŠ† B â‡’ dim BÎµ ( x ) â‰¤ dim B y como
H d ( BÎµ ( x )) â‰¥ aLd ( BÎµ ( x )) > 0 entonces dim( BÎµ ( x )) â‰¥ d por lo que dim B â‰¥ d. Entonces por el
mismo teorema se tiene dim B = d.

Teorema 34. Sea S es un espacio mÃ©trico. Si ind S â‰¥ 1 entonces dim S â‰¥ 1.

DemostraciÃ³n. Suponga que ind S â‰¥ 1. Entonces S no tiene una base de abiertos que consisten solo
de clopen. Sea a âˆˆ S y Îµ > 0 el conjunto Br ( a) no es clopen para todo 0 < r < Îµ. Defina h : S â†’
tal que h( x ) = Ï( x, a), esta funciÃ³n es continua y cumple con ser de crecimiento acotado.

R

|h( x ) âˆ’ h(y)| â‰¤ Ï( x, y).
Su Ã¡mbito incluye a ]0, Îµ[ pues como Br ( a) no es clopen, su frontera no es vacÃ­a. Y dado x âˆˆ
Fr ( Br ( a)), |h( x ) âˆ’ h( a)| â‰¤ Ï( x, a) â‰¤ r < Îµ, de manera que dim(S) â‰¥ dim h[S] â‰¥ dim(]0, Îµ[) = 1. 
Teorema 35. Si S es un espacio mÃ©trico compacto entonces ind S â‰¤ dim S.

DemostraciÃ³n. VÃ©ase [9, p. 155].

3.4



DimensiÃ³n de semejanza vs dimensiÃ³n Hausdorff

Usar un sistema iterado de funciones es una de las formas mÃ¡s sencillas de producir ejemplos de
fractales y poder calcular la dimensiÃ³n Hausdorff a partir de la dimensiÃ³n de semejanza s. Suponga
que K es el conjunto invariante para el sistema iterado de funciones. Como K es compacto se tiene

40

DIMENSIÃ“N HAUSDORFF

que es medible. Se verÃ¡ que es cierta la desigualdad dim K â‰¤ s, ademÃ¡s esta desigualdad puede
ser estricta si los f i [K ] se traslapan mucho. Bajo ciertas condiciones se tiene la igualdad.
ProposiciÃ³n 19. La dimensiÃ³n Hausdorff para E ( Ï‰ ) con mÃ©trica Ï1/3 es ln 2/ ln 3.

DemostraciÃ³n. Sea s = ln 2/ ln 3. Considere la mÃ©trica Ï1/3 y la medida M1/2 . Si |Î±| = k, entonces
M1/2 ([Î±]) = 2âˆ’k = (3âˆ’k )s = (diam [Î±])s . Por tanto, por el teorema 32, se tiene H s ( E(Ï‰ )) =
M1/2 ( E(Ï‰ )) = 1; de esta manera se concluye que dim E(Ï‰ ) = s = ln 2/ ln 3.

Corolario 5. La dimensiÃ³n Hausdorff de C es ln 2/ ln 3.

DemostraciÃ³n. Por la proposiciÃ³n 15 toda aplicaciÃ³n con distorsiÃ³n acotada preserva la dimensiÃ³n
Hausdorff. La aplicaciÃ³n modelo h de E(Ï‰ ) sobre C tiene distorsiÃ³n acotada, esto se probÃ³ en el
proposiciÃ³n 9. Con esto y la proposiciÃ³n 19 se completa la demostraciÃ³n.

Esto prueba que el conjunto de Cantor es un fractal pues como se sabe ind C = 0.
Sea E = {L, U, R} un alfabeto de tres letras. Sea Ï la mÃ©trica sobre E(Ï‰ ) para la lista de razones
(1/2, 1/2, 1/2). Sea Ï(Ïƒ, Ï„ ) = 2âˆ’k donde k es el largo del mayor prefijo comÃºn entre Ïƒ y Ï„. Los
corrimientos a la derecha realizan la lista de razones con razÃ³n 12 :
Ï(LÏƒ, LÏ„ ) =

1
1
1
Ï(Ïƒ, Ï„ ), Ï(UÏƒ, UÏ„ ) = Ï(Ïƒ, Ï„ ), Ï(RÏƒ, RÏ„ ) = Ï(Ïƒ, Ï„ )
2
2
2

con esto se puede calcular la dimensiÃ³n Hausdorff de E(Ï‰ ) .
ln 3
.
ln 2
DemostraciÃ³n. Sea s = ln 3/ ln 2. Considere la mÃ©trica Ï1/2 y la medida M([Î±]) = 3âˆ’|Î±| = wÎ± . Se
cumplen las condiciones del teorema 32 y se tiene que H s ( E(Ï‰ ) ) = M( E(Ï‰ ) ) = 1; asÃ­ dim E(Ï‰ ) =
s = ln 3/ ln 2.


ProposiciÃ³n 20. La dimensiÃ³n Hausdorff de ( E ( Ï‰ ) , Ï1/2 ) es s =

ln 3
.
ln 2
DemostraciÃ³n. Por la proposiciÃ³n 8, la aplicaciÃ³n modelo h es de crecimiento acotado y por la
proposiciÃ³n 15, se tiene dim S â‰¤ dim E(Ï‰ ).

Corolario 6. La dimensiÃ³n Hausdorff del triÃ¡ngulo de SierpinÌski es a lo mÃ¡s

El cÃ¡lculo de la dimensiÃ³n de semejanza para el espacio E(Ï‰ ) se usa en el cÃ¡lculo de la dimensiÃ³n
Hausdorff del triÃ¡ngulo de SierpinÌski S, pero no es suficiente pues la aplicaciÃ³n modelo para este
conjunto no tiene decrecimiento acotado (de hecho no es inyectiva como se probÃ³ en la proposiciÃ³n
10). AÃºn asÃ­ se puede calcular la dimensiÃ³n Hausdorff de este conjunto a partir de la definiciÃ³n.
ProposiciÃ³n 21. Sea s =

ln(3)
, entonces H s (S) = 1.
ln(2)

N

DemostraciÃ³n. Dado Îµ > 0 existe k âˆˆ
tal que Îµ â‰¥ 2âˆ’k . Considere { A1 , A2 , . . . , A3k }, la intersecciÃ³n de cada uno de los triÃ¡ngulos que forman Sk con S. Note que como los vÃ©rtices de cada
triÃ¡ngulo pertenecen a S, el diÃ¡metro de cada triÃ¡ngulo es el diÃ¡metro de Ak , luego estos forman
un Îµ-cubrimiento de S y

HÎµs (S) â‰¤

3k

âˆ‘ diam ( Ak )s =

i =1

3k

âˆ‘
i =1



1
2k

s

3k

=

âˆ‘
i =1



1
2s

Sea Î´ > 0 existe una Îµ-cubrimiento A de S tal que

HÎµs (S) >

âˆ‘
Aâˆˆ A

diam ( A)s âˆ’ Î´

k

= 3k

 k
1
= 1.
3

41

pero como âˆ€i = 1, . . . , 3k se cumple que
Ai âŠ‚ S âŠ‚

[

A

A âˆˆA

se tiene que
1âˆ’Î´

3k

=

âˆ‘ diam ( Ak )s âˆ’ Î´ â‰¤ âˆ‘

i =1

â‡’ HÎµs (S) = 1

Aâˆˆ A

diam ( A)s âˆ’ Î´ < HÎµs (S) â‰¤ 1

por lo tanto, como es vÃ¡lido para todo Îµ , al tomar lÃ­mites se obtiene que H s (S) = 1.



Por lo tanto la dimensiÃ³n Hausdorff del triÃ¡ngulo de SierpinÌski es ln(3)/ ln(2) â‰ˆ 1.58 y como en
la proposiciÃ³n 12 se viÃ³ que ind S = 1, se tiene que el triÃ¡ngulo de SierpinÌski es un fractal. Esta
medida depende de la mÃ©trica que se use, de hecho en [3] se prueba
âˆš que la medida anterior del
triÃ¡ngulo con vÃ©rtices (0,0), (1,0) y (0,1) con la mÃ©trica euclÃ­dea es 3, dÃ¡ndonos una referencia de
su â€œtamaÃ±oâ€.
Teorema 36. Sea s cualquier nÃºmero real positivo. Existe un espacio mÃ©trico S con dim S = s.

DemostraciÃ³n. Tome 0 < r0 < 1 y r1 = (1 âˆ’ (r0 )s )1/s . Es claro que r0s + r1s = 1 y la lista de razones
(r0 , r1 ) es contractiva. Considere E(Ï‰ ) como espacio de hileras infinitas sobre el alfabeto de dos
letras E = {0, 1}. Defina diam [0] = r0 , diam [1] = r1 y para Î± âˆˆ E(âˆ—) , diam [0Î±] = r0 diam [Î±]
y diam [1Î±] = r1 diam [Î±], con esto se define una mÃ©trica en E(Ï‰ ). Para definir los pesos en cada
no-do se toma wÎ± = (diam [Î±])s . Note que:
wÎ›

= 1 = r0s + r1s = w0 + w1

wÎ±

= wÎ± (r0s + r1s ) = wÎ± r0s + wÎ± r1s = w0Î± + w1Î±

Con esto se define una medida M y se cumplen todas las hipÃ³tesis del teorema 32 por lo que
M( E(Ï‰ ) ) = H s ( B) = 1 asÃ­ dim( E(Ï‰ )) = s.

Teorema 37. Dada la lista contractiva de razones (r1 , r2 , Â· Â· Â· , rn ) y s su dimensiÃ³n de semejanza, entonces
existe un espacio de hileras y una mÃ©trica sobre Ã©l tal que su dimensiÃ³n Hausdorff es igual a s.

DemostraciÃ³n. VÃ©ase [9, p. 160].



Corolario 7. Sea K el conjunto invariante de la realizaciÃ³n en un espacio mÃ©trico completo S de una lista de

razones contractivas con dimensiÃ³n s. Entonces dim K â‰¤ s.

DemostraciÃ³n. De la proposiciÃ³n 8, se sabe que h : E(Ï‰ ) â†’ S tiene crecimiento acotado. El resultado
se obtiene de la proposiciÃ³n 15.


Con el resultado anterior se tiene una cota superior para la dimensiÃ³n Hausdorff. La siguiente
definiciÃ³n da una condiciÃ³n para que esta sea a la vez una cota inferior, y asÃ­ obtener la igualdad.
Se dice que el sistema iterado de funciones ( f 1 , f 2 , Â· Â· Â· , f n ) satisface
la condiciÃ³n de conjunto abierto de MorÃ¡n si y solo si existe un
conjunto abierto no vacÃ­o U para el cual se cumple que f i [U ] âˆ© f j [U ] =
âˆ… para i 6= j y f i [U ] âŠ† U para todo i.
Como ejemplos considere el conjunto de Cantor C y el triÃ¡ngulo de SierpinÌski S: las semejanzas
2
del primero son f 0 ( x ) = x3 y f 1 ( x ) = x +
3 , el conjunto U =]0, 1[ satisface la condiciÃ³n de MorÃ¡n

42

DIMENSIÃ“N HAUSDORFF

pues las dos imÃ¡genes son ]0, 1/3[ y ]2/3, 1[, que son disjuntos y contenidos en U. Para el triÃ¡ngulo
de SierpinÌski S tome U como el interior del triÃ¡ngulo S0 , el primer conjunto que lo aproxima en
la construcciÃ³n por tremas. Las tres imÃ¡genes son tres triÃ¡ngulos a escala 12 , contenidos en U y
disjuntos.
El interior del dragÃ³n de Heighway satisface la condiciÃ³n de MorÃ¡n para el sistema iterado de
funciones que lo realizan, pues como el dragÃ³n de Heighway es el conjunto invariante para el
sistema iterado de funciones, proposiciÃ³n 4, se obtiene que las dos imÃ¡genes estÃ¡n contenidas en
el mismo. AdemÃ¡s se sabe que el polÃ­gono aproximante de este dragÃ³n nunca se cruza, Figura 1.6,
de donde las dos imÃ¡genes son disjuntas.
Se puede dar una condiciÃ³n mÃ¡s dÃ©bil para satisfacer la condiciÃ³n de conjunto abierto cuando se
sabe que el conjunto invariante es una uniÃ³n disjunta de compactos, bajo esta situaciÃ³n no hace
falta encontrar el abierto para tener la igualdad entre las dimensiones de semejanza y Hausdorff.
Teorema 38. Si el conjunto invariante K satisface f i [K ] âˆ© f j [K ] = âˆ… para i 6= j, entonces la condiciÃ³n de

MorÃ¡n se cumple.
DemostraciÃ³n. Si K tiene interior no vacÃ­o tome U como el interior de K. Sino, sea
dij = dist( f i [K ], f j [K ]),

que es positiva, pues son compactos. Sea r = mÃ­ni6= j dij defina Kr/2 = { x : dist( x, K ) < r/2}
que es abierto y no vacÃ­o. Suponga que f i [Kr/2 ] âˆ© f j [Kr/2 ] 6= âˆ… y sea y âˆˆ ( f i [Kr/2 ] âˆ© f j [Kr/2 ])
entonces existen x1 , x2 âˆˆ Kr/2 tal que y = f i ( x1 ) = f j ( x2 ) ademÃ¡s existen z1 , z2 âˆˆ K tales que
Ï( x1 , z1 ) < r/2 âˆ§ Ï( x2 , z2 ) < r/2 entonces
Ï(y, f i (z1 )) = Ï( f i ( x1 ), f i (z1 )) = ri Â· r/2 < r/2
Similarmente Ï(y, f j (z2 )) < r/2, entonces Ï( f i (z1 ), f j (z2 )) < r, pero esto contradice el hecho que
r sea el mÃ­nimo. Ahora se probarÃ¡ que f i [Kr/2 ] âŠ† Kr/2 para todo i. Sea y âˆˆ f i [Kr/2 ], entonces
existe x âˆˆ Kr/2 tal que y = f i ( x ) y existe z âˆˆ K tal que Ï( x, z) < r/2 entonces Ï(y, f i (z)) =
Ï( f i ( x ), f i (z)) = ri Â· r/2 < r/2 lo cual implica que y âˆˆ Kr/2 .

Teorema 39. Sea (re ) e âˆˆ E una lista de razones contractiva, sea s su dimensiÃ³n y ( f e ) e âˆˆ E su realizaciÃ³n en

Rd . Sea K su conjunto invariante. Si la condiciÃ³n de MorÃ¡n se satisface, entonces dim K = s y se cumple
0 < H s (K ) < âˆ.
DemostraciÃ³n. VÃ©ase [11, p. 118].

3.5



DimensiÃ³n Hausdorff vs dimensiÃ³n del grafo

Sea (V, E, i, t, r ) un grafo de Mauldin-Williams, estrictamente contractivo y fuertemente conectado,
que describe una lista (Kv )vâˆˆV de conjuntos autosemejantes en d . En la subsecciÃ³n 1.5, se dotÃ³ a
este grafo de una dimensiÃ³n por medio de los nÃºmeros de Perron s-dimensionales y se postergÃ³
para la presente secciÃ³n la tarea de calcular la dimensiÃ³n Hausdorff de cada conjunto compacto
no vacÃ­o, Kv . Para cumplir con dicho fin, se va a comparar la dimensiÃ³n Hausdorff de Kv con
la dimensiÃ³n del grafo que los genera. Y se estudiarÃ¡ bajo quÃ© condiciones ambas dimensiones
coinciden.
Por ser el grafo estrictamente contractivo el teorema 15 afirma que la lista (Kv )vâˆˆV existe y es Ãºnica,
satisfaciendo la igualdad

R

Ku =

[

vâˆˆV
e âˆˆ Euv

f e [Kv ]

(3.5)

43

para todo u âˆˆ V, y por otro lado, como el grafo es fuertemente conectado, se puede asegurar que
la dimensiÃ³n Hausdorff de cada uno de los conjuntos (Kv )vâˆˆV es la misma, lo que se garantiza con
el siguiente teorema.
Teorema 40. Sea (V, E, i, t, r ) un grafo de Mauldin-Williams estrictamente contractivo y fuertemente conec-

tado y sean (Kv )vâˆˆV la lista invariante de conjuntos compactos. Entonces dim Ku = dim Kw para todo
u, w âˆˆ V.

DemostraciÃ³n. Al calcular dim Ku usando la igualdad (3.5) y el resultado del teorema 29 se obtiene
que dim Ku = mÃ¡x{dim f e (Kv ) : e âˆˆ Euv }, agregando a esto la conclusiÃ³n del teorema 30 se tendrÃ¡
que dim Ku = mÃ¡x{dim Kv : e âˆˆ Euv }, esto dice que dim Ku es la mayor de las dimensiones de
todos los compactos Kv donde existe una arista e que une al nodo u con el nodo v. Luego considere u, w âˆˆ V dos nodos cualesquiera. Como el grafo es fuertemente conectado existe un camino
{u, u1 , u2 , . . . , un , w} que une a u con w, del mismo modo existe otro camino {w, w1 , w2 , . . . , wm , u}
que une a w con u, entonces dim Ku â‰¥ dim Ku1 â‰¥ Â· Â· Â· â‰¥ dim Kun â‰¥ dim Kw por lo tanto dim Ku â‰¥
dim Kw , utilizando el otro camino, anÃ¡logamente, se tiene que dim Kw â‰¥ dim Ku con lo que se
obtiene que dim Kw = dim Ku .

Para calcular la dimensiÃ³n Hausdorff de estos conjuntos se necesita calcular la dimensiÃ³n Haus(Ï‰ )

dorff de los espacios de caminos Ev , uno para cada nodo v âˆˆ V, correspondientes al grafo
Mauldin-Williams dado. Sea s â‰¥ 0 la dimensiÃ³n del grafo y sean qv los nÃºmeros de Perron, se
(Ï‰ )

pueden definir los corrimientos a la derecha, Î¸e : Ev

(Ï‰ )

â†’ Eu , para cada e âˆˆ Euv por:

Î¸e (Ïƒ ) = eÏƒ.
(Ï‰ )

Se pueden definir mÃ©tricas Ïv sobre los espacios Ev como en la proposiciÃ³n 6, cuando no exista confusiÃ³n se llamarÃ¡n Ï. En las proposiciones 19 y 20 se usaron los espacios de hileras para
simplificar el cÃ¡lculo de la dimensiÃ³n Hausdorff de algunos atractores, se desea hacer esto usando
grafos. Se definen las mÃ©tricas de modo que los corrimientos (Î¸e )eâˆˆ Euv realicen el grafo de Mauldin(Ï‰ )

Williams, es decir, si Ïƒ y Ï„ âˆˆ Ev con Î± el mayor prefijo comÃºn, entonces Ï(Ïƒ, Ï„ ) = r (Î±) y que estos
sean semejanzas de razÃ³n r (e), pues Ï(Î¸e (Ïƒ ), Î¸e (Ï„ )) = Ï(eÏƒ, eÏ„ ) = r (eÎ±) = r (e)r (Î±) = r (e)Ï(Ïƒ, Ï„ ).
AdemÃ¡s estas mÃ©tricas cumplen, para cada camino finito Î±, que r (Î±) es el producto de los nÃºmeros
(âˆ—)

r (e), para todos las aristas e en Î± y por Ãºltimo que si Î± âˆˆ Euv , entonces el diÃ¡metro de [Î±] es r (Î±)qv .
(âˆ—)

MÃ¡s aÃºn, definen ultramÃ©tricas Ï, con estos diÃ¡metros, una para cada espacio Ev que satisfacen:
Ï(eÏƒ, eÏ„ ) = r (e)Ï(Ïƒ, Ï„ )
(âˆ—)

para Ïƒ, Ï„ âˆˆ Ev y e âˆˆ Euv .
Ahora se definen medidas sobre los espacios de caminos, llamadas M, por la igualdad 1.14 que
satisfacen los nÃºmeros de Perron, los valores (diam [Î±])s satisfacen la condiciÃ³n de aditividad del
teorema 26 es decir:
(diam [Î±])s = âˆ‘ (diam [Î±e])s
i ( e )= t ( Î±)

(Ï‰ )

AsÃ­, existen medidas mÃ©tricas sobre cada uno de los espacios Ev

que satisfacen:

(âˆ—)

M([Î±]) = (diam [Î±])s , âˆ€ Î± âˆˆ Ev

ProposiciÃ³n 22. Sea (V, E, i, t, r ) un grafo de Mauldin-Williams estrictamente contractivo y fuertemente
(Ï‰ )

conectado, con las medidas mÃ©tricas anteriormente definidas, entonces dim Ev
donde s es la dimensiÃ³n del grafo.

= s, para cada v âˆˆ V,

44

DIMENSIÃ“N HAUSDORFF

DemostraciÃ³n. Sean r = mÃ¡x{r (e) : e âˆˆ E} < 1 y q = mÃ¡x{qv : v âˆˆ V }. Si Î± iene longitud
(Ï‰ )

k, entonces diam [Î±] â‰¤ qr k . Luego qr k â†’ 0 cuando k â†’ âˆ. AsÃ­ por el teorema 32, H s ( Ev ) =
(Ï‰ )

(Ï‰ )

M( Ev ) = qsv . Y como 0 < qsv < âˆ, entonces dim Ev

= s.



Una vez que se conoce la dimensiÃ³n Hausdorff para los espacios de caminos, se puede aplicar
esto a los conjuntos en d que interesa y tratar de encontrar una cota superior para la dimensiÃ³n
Hausdorff de Ã©stos. Dado un grafo de Mauldin-Williams (V, E, i, t, r ) y ( f e )eâˆˆ E un sistema iterado
de funciones que realiza dicho grafo en los conjuntos compactos (Kv )vâˆˆV de d , se construirÃ¡n
las aplicaciones modelo para estos espacios, que son anÃ¡logas a las de hileras consideradas en la
secciÃ³n 1.4 de modo que se cumpla

R

R

(Ï‰ )

h v : Ev
una para cada v âˆˆ V, tal que

â†’ Rd ,

hu (eÏƒ ) = f e (hv (Ïƒ )).

(âˆ—)

(Ï‰ )

Para Ïƒ âˆˆ Ev y e âˆˆ Euv . AdemÃ¡s se desea que hv [ Ev ] = Kv para cada v âˆˆ V. Lo anterior se
garantiza en el siguiente teorema que ya se habÃ­a enunciado en el caso de un nodo en el teorema
14.
Teorema 41. Sea S 6= âˆ… un espacio mÃ©trico completo, (V, E, i, t, r ) un grafo de Mauldin-Williams fuerte-

mente conectado y estrictamente contractivo. Sea ( f e )eâˆˆ E un sistema iterado de funciones que realiza dicho
grafo en los conjuntos compactos (Kv )vâˆˆV , donde cada f e tiene razÃ³n r (e). Entonces para cada u âˆˆ V ex(Ï‰ )

iste una Ãºnica funciÃ³n continua hu : Eu
(Ï‰ )

hv [ Ev ] = Kv para cada v âˆˆ V.

â†’ S tal que hu (eÏƒ ) = f e (hv (Ïƒ )) para todo e âˆˆ Euv . AdemÃ¡s

DemostraciÃ³n. Se harÃ¡ para el caso de dos nodos es decir V = {u, v}. Escoja dos puntos a y b âˆˆ S,
(Ï‰ )

(Ï‰ )

(Ï‰ )

Ïƒ âˆˆ Eu y Ï„ âˆˆ Ev . Se definen gk : Eu
recursivamente

(Ï‰ )

â†’ S y t k : Ev

â†’ S por g0 (Ïƒ ) = a y t0 (Ï„ ) = b y

gk+1 (eÏƒ ) = f e ( gk (Ïƒ )) si e âˆˆ Euu , y gk+1 (eÏ„ ) = f e (tk (Ï„ )) si e âˆˆ Euv

(3.6)

tk+1 (eÏƒ ) = f e ( gk (Ïƒ )) si e âˆˆ Evu , y tk+1 (eÏ„ ) = f e (tk (Ï„ )) si e âˆˆ Evv .

(3.7)

anÃ¡logamente

Por inducciÃ³n y usando el hecho de que [e] es abierto se puede demostrar que las gk y las tk son
continuas para todo k. Sea r = mÃ¡xeâˆˆ E re , como la lista es estrictamente contractiva se tiene que
r < 1. Para e âˆˆ Euu se tiene que
Ï ( gk+1 (eÏƒ ) , gk (eÏƒ ))

= Ï ( f e ( gk (Ïƒ )), f e ( gkâˆ’1 (Ïƒ )))

= re Ï ( gk (Ïƒ ) , gkâˆ’1 (Ïƒ ))
â‰¤ rÏu ( gk , gkâˆ’1 )
y para e âˆˆ Euv se tiene que
Ï ( gk+1 (eÏ„ ) , gk (eÏ„ ))

= Ï ( f e (tk (Ï„ )), f e (tkâˆ’1 (Ï„ )))

= re Ï (tk (Ï„ ) , tkâˆ’1 (Ï„ ))

â‰¤ rÏu (tk , tkâˆ’1 )
de donde se obtiene que

Ïu ( gk+1 , gk ) â‰¤ r mÃ­n{Ïu ( gk , gkâˆ’1 ), Ïu (tk , tkâˆ’1 )}

(3.8)

45

de la misma manera se obtiene
Ï u ( t k +1 , t k )

â‰¤ r mÃ­n{Ïu ( gk , gkâˆ’1 ), Ïu (tk , tkâˆ’1 )}
(Ï‰ )

Note que mÃ­n{Ïu ( g1 , g0 ), Ïu (t1 , t0 )} es finito dado que Eu
usando desigualdad triangular se tiene que:
Ï u ( gm , gk ) â‰¤

m âˆ’1

âˆ‘

j=k

(Ï‰ )

y Ev

(3.9)

son compactos. AsÃ­ para m â‰¥ k,

âˆ

âˆ‘ r j mÃ­n{Ïu ( g1, g0 ), Ïu (t1, t0 )}


Ï u g j +1 , g j â‰¤

j=k

y como esta Ãºltima serie tiende a cero cuando k â†’ âˆ, se tiene que la sucesiÃ³n ( gk ) es de Cauchy en
(Ï‰ )

C( Eu , S), por lo tanto converge uniformemente. De modo anÃ¡logo (tk ) converge uniformemente.
Denote hu = limkâ†’âˆ gk y hv = limkâ†’âˆ tk . Usando las igualdades (3.6) y (3.7), se tiene que hu (eÏƒ ) =
f e (hu (Ïƒ )), hu (eÏ„ ) = f e (hv (Ï„ )), hv (eÏƒ ) = f e (hu (Ïƒ )) y hv (eÏ„ ) = f e (hv (Ï„ )). Para la unicidad, suponga
que existen gu y gv que satisfacen lo mismo que hu y hv . Aplicando un razonamiento parecido al
de las desigualdades (3.8) y (3.9) se obtiene
Ï u ( h u , gu )
Ï u ( h v , gv )

â‰¤ r mÃ­n{Ïu (hu , gu ), Ïu (hv , gv )}
â‰¤ r mÃ­n{Ïu (hu , gu ), Ïu (hv , gv )}

(3.10)
(3.11)

y si el mÃ­nimo es Ïu (hu , gu ), la desigualdad (3.10) se satisface sÃ³lo si Ïu (hu , gu ) = 0 y usando esto en
la desigualdad (3.11) se tiene que Ïu (hv , gv ) = 0 por lo tanto hu = gu y hv = gv y similarmente si el
mÃ­nimo es Ïu (hv , gv ). Por la construcciÃ³n y usando la convergencia uniforme de las sucesiones ( gk )
(Ï‰ )

(Ï‰ )

y (tk ), los conjuntos hu [ Eu ] y hv [ Ev ] satisfacen la igualdad (3.5) y por el teorema 15 coinciden
con Ku y Kv respectivamente.

ProposiciÃ³n 23. Las aplicaciones h u para u âˆˆ V tienen crecimiento acotado.

n


o
(Ï‰ )
(Ï‰ )
DemostraciÃ³n. Sea B = mÃ¡x diam hu [ Eu ] : u âˆˆ V . Como se tiene que hu [ Eu ] es compacto
(Ï‰ )

para todo u âˆˆ V, B es finito y positivo. Sean Ïƒ y Ï„ en Eu , donde Î± es el mayor prefijo comÃºn de
Ïƒ y Ï„, es decir Ïƒ = Î±Ïƒ â€² y Ï„ = Î±Ï„ â€² . Si t(Î±) = v entonces Ï (hu (Ïƒ ) , hu (Ï„ )) = r (Î±)Ï (hv (Ïƒ â€² ) , hv (Ï„ â€² )) â‰¤
r (Î±) Â· B = B Â· Ï(Ïƒ, Ï„ ).

Corolario 8. dim Ku â‰¤ s para todo u âˆˆ V, donde s es la dimensiÃ³n del grafo.
(Ï‰ )

DemostraciÃ³n. Del teorema 41 se tiene que hu [ Eu ] = Ku y como las hu son de crecimiento acotado,
(Ï‰ )

de la proposiciÃ³n 15 se tiene que dim Ku â‰¤ dim Eu

= s.



Para la cota inferior se necesita limitar el traslape y es por ello que se necesita una â€œcondiciÃ³n de
conjunto abiertoâ€ como la considerada en la definiciÃ³n 3.4. Esto motiva la siguiente definiciÃ³n.

R

Si ( f e )eâˆˆ E es una realizaciÃ³n de (V, E, i, t, r ) en d , se dice que satisface la condiciÃ³n de conjunto abierto si existen conjuntos abiertos no
vacÃ­os Uv , uno para cada nodo v âˆˆ V, que satisfacen
Uu âŠ‡ f e [ Uv ]
para todo u, v âˆˆ V y e âˆˆ Euv y ademÃ¡s se cumpla:
f e [ Uv ] âˆ© f e â€² [ Uv â€² ] = âˆ…
para todo u, v, vâ€² âˆˆ V, e âˆˆ Euv , eâ€² âˆˆ Euvâ€² , con e 6= eâ€² .

46

DIMENSIÃ“N HAUSDORFF

Uniendo todo lo anterior, se obtiene un resultado anÃ¡logo al teorema 39, que permite establecer
cuÃ¡ndo la dimensiÃ³n Hausdorff de Kv y la dimensiÃ³n del grafo que los genera coinciden.
Teorema 42. Sea (V, E, i, t, r ) un grafo de Mauldin-Williams contractivo y fuertemente conectado que de-

R

scribe el grafo de autosemejanza de una lista (Kv )vâˆˆV de conjuntos compactos no vacÃ­os en d . Sea s > 0
la dimensiÃ³n del grafo. Entonces se tiene que dim Kv â‰¤ s para todo v. Si ademÃ¡s la realizaciÃ³n satisface la
condiciÃ³n de conjunto abierto, se tiene que dim Kv â‰¥ s, y por lo tanto se tendrÃ­a que dim Kv = s.
DemostraciÃ³n. VÃ©ase [9, p. 173].



Para finalizar esta secciÃ³n se desarrollan dos ejemplos en donde se aplicarÃ¡n los resultados anteriores.
Polvo en dos partes.. Fue considerado en la secciÃ³n 1.5. Mauldin y Williams lo inventaron para
ilustrar el cÃ¡lculo de la dimensiÃ³n Hausdorff usando dimensiÃ³n de un grafo. Su grafo asociado,
Figura 1.8, tiene dimensiÃ³n 1, con U y V los conjuntos autosemejantes. AquÃ­ se mostrarÃ¡ que U y
V tienen ambos dimensiÃ³n Hausdorff igual a 1. Por el teorema 40 se concluye que sus dimensiones
(Ï‰ )

(Ï‰ )

deben ser la misma. Por la proposiciÃ³n 22 los espacios EU y EV asociados al este grafo, tienen dimensiÃ³n Hausdorff 1. Para calcular la dimensiÃ³n Hausdorff de los conjuntos U y V, basta verificar
que se satisface la condiciÃ³n de conjunto abierto. Edgar en [9, p. 169], expone dos conjuntos, un
rectÃ¡ngulo y un hexÃ¡gono, cuyos interiores satisfacen la condiciÃ³n de conjunto abierto, definiciÃ³n
3.5, y son convenientemente escojidos para que las imÃ¡genes bajo las semejanzas sean disjuntas.
La siguiente proposiciÃ³n fundamenta el hecho de que al encontrar estos conjuntos se calcula la
dimensiÃ³n de U y V.
ProposiciÃ³n 24. Sean U y V las dos partes de P, entonces las aplicaciones:
(Ï‰ )

hU : EU

(Ï‰ )

hV : EV

â†’ R2
â†’ R2

tienen distorsiÃ³n acotada. Luego dim U = dim V = 1.
DemostraciÃ³n. Por la proposiciÃ³n 23, hU y hV tienen crecimiento acotado, basta probar que son de
(Ï‰ )

decrecimiento acotado. Sean Ïƒ, Î² en Eu
decir Ïƒ = Î±Ïƒ â€² y Î² = Î±Î²â€² . AsÃ­

si t(Î±) = u entonces

de modo que Î± es el mayor prefijo comÃºn entre ellos, es



Ï (hu (Ïƒ ) , hu ( Î²)) = r (Î±)Ï ht(Î±) (Ïƒ â€² , ht(Î±) ( Î²â€² )) = (âˆ—)


(âˆ—) = r (Î±)Ï hu (eÏƒ â€²â€² , hu (eâ€² Î²â€²â€² )) â‰¥ r (Î±) D (a(U ), b(V )) = A1 Â· Ï(Ïƒ, Î²)

donde e y eâ€² pertenecen uno a Euu y el otro a Euv . Si t(Î±) = v entonces,


(âˆ—) = r (Î±)Ï hv (eÏƒ â€²â€² , hv (eâ€² Î²â€²â€² )) â‰¥ r (Î±) D (c(U ), d(V )) = A2 Â· Ï(Ïƒ, Î²),

donde e y eâ€² pertenecen uno a Evv y el otro a Evu . Y tomando A = mÃ­n{ A1 , A2 } se tiene que
Ï (hu (Ïƒ ) , hu ( Î²)) â‰¥ A Â· Ï(Ïƒ, Î²) con lo que hu es de decrecimiento acotado. Similarmente se prueba
(Ï‰ )

que hv es de decrecimiento acotado, con esto se obtiene que dim U = dim Eu
(Ï‰ )
dim Ev

= 1.

= 1 y dim V =


47

Figura 3.1

Grafo para la frontera del dragÃ³n de Heighway.

Figura 3.2

UA y UB para el dragÃ³n de Heighway.

Frontera del dragÃ³n de Heighway.. En este segundo ejemplo se trabaja con la frontera K del dragÃ³n
de Heighway, Figura 1.7. Esta se descompone en dos partes, el lado derecho de K se denota con
A, y el lado izquierdo con B. El grafo de autosemejanza es ilustrado en la Figura 3.1, y se justifica
debido a la construcciÃ³n del dragÃ³n de Heighway. En [9, p. 175] se calculan los nÃºmeros de Perron
y con esto la dimensiÃ³n del grafo que es s â‰ˆ 1.52. Utilizando el teorema 42 faltarÃ­a Ãºnicamente
verificar la condiciÃ³n de conjunto abierto para concluir que K tiene esa misma dimensiÃ³n.
Considere las semejanzas a, b, c y d : 2 â†’ 2 tales que a y b son contracciones de factor âˆš1

R

R

2

seguidas de una rotaciÃ³n de 45o , c tiene un factor de contracciÃ³n 21 seguida de una rotaciÃ³n de
âˆ’90o y d tiene el mismo factor de contracciÃ³n 12 seguida de una rotaciÃ³n de 90o , estas realizan los
conjuntos A y B en 2 . En la parte superior de la Figura 3.2 se dan los conjuntos abiertos UA y UB
que son similares al interior del Twindragon y contienen respectivamente las curvas A y B. Note
que el abierto UB esta compuesto por dos copias de UA reducida por un factor de 21 , ademÃ¡s UA
incluye copias de UA y UB reducidas por un factor de âˆš1 y se cumplen:

R

2

a [ UA ] âˆª b [ UB ] âŠ† UA ,
c [ UA ] âˆª d [ UA ] âŠ† UB ,

a[UA ] âˆ© b[UB ] = âˆ…,
c[UA ] âˆ© d[UA ] = âˆ….

Se obtiene asÃ­ que dim K â‰ˆ 1.52.

3.6

Otras dimensiones fractales

De acuerdo con la definiciÃ³n 3.3, algunos conjuntos no serÃ¡n considerados como fractales pues la
dimensiÃ³n Hausdorff es igual a la topolÃ³gica, aunque por su semejanza deberÃ­an serlo. Esto hace
que se trabaje con otras definiciones de dimensiÃ³n fractal.

48

DIMENSIÃ“N HAUSDORFF

DimensiÃ³n de conteo.. Es una de las mÃ¡s populares, tambiÃ©n es conocida como â€œBox-counting".
Esta es utilizada para estimaciones y cÃ¡lculos empÃ­ricos, su definiciÃ³n fue dada en la dÃ©cada de los
treintas y es tambiÃ©n llamada â€œÃ­ndice de entropÃ­a".

R

Sea âˆ… 6= F âŠ† d un subconjunto acotado y N ( F, Î´) el menor nÃºmero
de subconjuntos de diÃ¡metro menor que Î´ que pueden cubrir a F. Defina
ln N ( F, Î´)
,
âˆ’ ln Î´
Î´ â†’0
ln N ( F, Î´)
lim sup
.
âˆ’ ln Î´
Î´ â†’0

dimC F

= lim inf

(3.12)

dimC F

=

(3.13)

Cuando estos lÃ­mites coincidan se le llamarÃ¡ dimensiÃ³n de conteo de
F, y se denota por dimC F.
En la definiciÃ³n anterior se puede sustituir N ( F, Î´) por el menor nÃºmero de bolas cerradas de radio
Î´ que cubren a F o por el mayor nÃºmero de bolas de radio Î´ con centro en F.
ProposiciÃ³n 25. Si F âŠ†

Rd y FÎ´ un Î´-vecindario de F, definiciÃ³n 1.2, entonces
ln Ld ( FÎ´ )
ln Î´

(3.14)

ln Ld ( FÎ´ )
.
ln Î´

(3.15)

dimC F

= d âˆ’ lim sup

dimC F

= d âˆ’ lim inf

Î´ â†’0

Î´ â†’0

DemostraciÃ³n. VÃ©ase [11, p. 42].



ProposiciÃ³n 26. dim F â‰¤ dimC F.

DemostraciÃ³n. Suponga que se cubre a F con N ( F, Î´) conjuntos de diÃ¡metro Î´. De la ecuaciÃ³n (3.2)
s
s
s
se tiene que H Î´ ( F ) â‰¤ N ( F, Î´)Î´s . Si 1 < HÎ´ ( F ) = limÎ´â†’0 H Î´ , entonces ln N ( F, Î´) + s ln Î´ > 0. Si Î´ es
suficientemente pequeÃ±o, despejando y tomando Î´ â†’ 0 se obtiene el resultado.

ProposiciÃ³n 27. Se cumple que dim C = dimC C.

DemostraciÃ³n. Tome el cubrimiento de 2k intervalos, de longitud 3âˆ’k , de Ck dado por NÎ´ (C) â‰¤ 2k
si 3âˆ’k < Î´ â‰¤ 3âˆ’k+1 , usando la definiciÃ³n 3.6 se tiene
dimC C = lim sup
Î´ â†’0

ln N ( F, Î´)
ln 2
ln 2k
=
â‰¤ lim sup
k
âˆ’
1
âˆ’ ln Î´
ln 3
k â†’ âˆ ln 3

usando el corolario 5 y la proposiciÃ³n 26, se tiene que
ln 2
ln 2
= dim C â‰¤ dimC C â‰¤
,
ln 3
ln 3
de donde se obtiene el resultado.



La dimensiÃ³n de conteo satisface propiedades similares a la dimensiÃ³n Hausdorff, sin embargo, se
esperarÃ­a que dimC F = 0 si F fuese un conjunto numerable, pero esto no siempre ocurre.
Por ejemplo considere el conjunto compacto F = {0, 1, 21 , 13 , . . . } sin embargo este cumple con
dimC F = 12 . Para ver esto, se considera para el cubrimiento, intervalos abiertos de longitud Î´ < 12
1
1
y k entero positivo que satisface
> Î´ â‰¥
. Se necesitan k + 1 intervalos de largo
( k âˆ’ 1) k
k ( k + 1)
Î´ para cubrir el intervalo [0, 1/k], quedando solamente k âˆ’ 1 puntos para terminar de cubrir a

49

ln N ( F, Î´)
ln 2k
â‰¤
y tomando Î´ â†’ 0 se tiene que
âˆ’ ln Î´
ln k(k âˆ’ 1)
dimC F â‰¤ 1/2. Para la otra desigualdad note que los abiertos pueden cubrir a lo mÃ¡s uno de los
ln N ( F, Î´)
ln k
elementos de F, y para cubrir a F se necesitan k abiertos, de donde
â‰¤
y
âˆ’ ln Î´
ln k(k + 1)
dimC F â‰¥ 1/2.
F, que se hace con k âˆ’ 1 intervalos. AsÃ­

4
4.1

APLICACIONES

Los dilemas espaciales de evoluciÃ³n

A travÃ©s de la historia y desde los tiempos de Darwin, uno de los problemas centrales de la evoluciÃ³n ha sido el origen y el mantenimiento de la cooperaciÃ³n o comportamiento altruista; esta cooperaciÃ³n es esencial para evolucionar, asÃ­, molÃ©culas cooperan para formar una cÃ©lula, cÃ©lulas
cooperan para formar plantas o animales, y los animales cooperan en familias para cuidar a sus
crÃ­os, para cazar o para reducir el riesgo de depredaciÃ³n. El altruismo es comÃºnmente observado
en el mundo animal.
La cooperaciÃ³n puede ser difÃ­cil de ubicar dentro de un marco de la TeorÃ­a Darwiniana clÃ¡sica, ya
que los menos adaptados buscan la cooperaciÃ³n y tienden a sobrevivir junto con los mejores adaptados, quienes por su naturaleza tienen caracterÃ­sticas ventajosas que los hacen particularmente
aptos para sobrevivir. Tres teorÃ­as principales han sido expuestas para explicar la evoluciÃ³n de la
cooperaciÃ³n:
1. La teorÃ­a de Hamilton [20] sobre la selecciÃ³n dice que la cooperaciÃ³n puede ser una opciÃ³n
relativamente prometedora, ya que un acto altruista puede ser pagado, y esto favorece la
supervivencia de algunos de nuestros genes.
2. La cooperaciÃ³n entre individuos no-relacionados puede ser explicada por altruismo recÃ­proco; esto funciona si dos individuos se acercan mÃ¡s que otros, y si existe alguna oportunidad
de que algÃºn movimiento cooperativo pueda ser reciprocidado en el siguiente encuentro. La
famosa metÃ¡fora es el Dilema del Prisionero.
3. Los cooperadores pueden tambiÃ©n evolucionar si la selecciÃ³n actÃºa mÃ¡s sobre grupos que
sobre individuos. AsÃ­, grupos con mÃ¡s cooperadores tienen mÃ¡s posibilidad de sobrevivir. Es
necesario un mecanismo que asegure que la totalidad de los grupos son en efecto la unidad
de selecciÃ³n, y que los individuos no puedan cambiar entre los grupos. Este tipo de explicaciÃ³n usualmente requiere que las poblaciones sean genÃ©ticamente homogÃ©neas, y que la
estructura de las poblaciones sea mantenido.

Cuando los individuos viven en grupos, es probable que la cooperaciÃ³n sea mÃ¡s frecuente dentro
del grupo. La teorÃ­a de juegos y evoluciÃ³n [31] no incluye el efecto de la estructura espacial de
la poblaciÃ³n. Individuos diferentes interactÃºan con cada otro en proporciÃ³n de sus frecuencias
relativas en la poblaciÃ³n. El pago del juego estÃ¡ relacionado con el Ã©xito reproductivo.
En esta parte se exponen algunas de las ideas presentadas por Martin Novak y Robert May [43],
la cuÃ¡l desarrolla la idea sugerida por Axelrod [2], de colocar a los â€œjugadores" individuales en un
arreglo bidimensional. En cada asalto todo individuo juega con sus vecinos inmediatos. DespuÃ©s,
cada sitio es ocupado o bien por su dueÃ±o original o por alguno de sus vecinos, dependiendo
de quien tenga el puntaje total mÃ¡s alto en este asalto. Esta teorÃ­a sirve como un marco determinÃ­stico de un aspecto poco estudiado en modelos de evoluciÃ³n biolÃ³gica: el efecto directo de
estructuras espaciales sobre organizaciones poblacionales y selecciones frecuentemente dependientes (i.e.,â€œteorÃ­a espacial de los juegos evolutivos").
4.1.1

Dilema del Prisionero

El â€œDilema del Prisionero" (DP) es un modelo que sirve para representar los juegos de evoluciÃ³n.
Se desarrolla entre jugadores teniendo cada uno dos opciones: ser C o D como abreviaciones de
cooperador y no cooperador (llamado â€œdelator"). Si dos jugadores deciden ser cooperadores al
enfrentarse, reciben R puntos cada uno, si deciden ser delatores reciben P puntos cada uno, y
si uno decide ser cooperador y el otro delator, el cooperador recibe S puntos y el delator recibe T
puntos, con T > R > P > S. Es claro que no hay dilema evidente, pues elegir siempre D es la mejor
opciÃ³n a lo largo del juego. En ausencia de cualquier estructura espacial los delatores representarÃ¡n
los mÃ¡s favorecidos por la selecciÃ³n, asÃ­, los cooperadores serÃ­an eliminados del juego.
Esta presentaciÃ³n supone que hay una elecciÃ³n al azar de quiÃ©n decide ser cooperador o no, y
los jugadores no recuerdan encuentros anteriores; considerando dos clases de individuos: los que
cooperan y los que delatan, se verÃ¡ que estos cooperadores y delatores pueden coexistir tanto en
patrones estÃ¡ticos y regulares, como en patrones dinÃ¡micos con fluctuaciones caÃ³ticas alrededor
de promedios pronosticados a largo plazo, dando un explicaciÃ³n de cÃ³mo normas determinÃ­sticas
permiten la subsistencia de los menos adaptados.
Reglas de juegos espaciales.. Considere una poblaciÃ³n heterogÃ©nea pero con ciertas estructuras
espaciales, y se supone que los animales o molÃ©culas (individuos) ocupan ciertas posiciones territoriales (cepas) o celdas, y estÃ¡n mÃ¡s propensos a interactuar con sus vecinos inmediatos. Se variarÃ¡
el pago de los encuentros a solo tres valores 1 , b y 0. Su interacciÃ³n estÃ¡ descrita en la siguiente
matriz de pagos.
C
D

C
1
b

D
0
0

Si dos cooperadores interactÃºan, ambos reciben un punto; si un delator explota a un cooperador
recibe b puntos y el cooperador 0 puntos; la interacciÃ³n entre dos delatores tambiÃ©n da el pago de
0 puntos. Este juego esta diseÃ±ado para mantener las cosas tan simples como sea posible; de hecho
solo hay un parÃ¡metro, b, que da la ventaja para los delatores (se puede considerar los cuatro valores asignando a la interacciÃ³n C-D un valor negativo muy pequeÃ±o). Este juego ahora es jugado
en un retÃ­culo cuadrado bidimensional. Cada celda es ocupada solo por un cooperador o por un
delator. En cada generaciÃ³n el pago para cierto individuo es la suma de todas las interacciones con
los 8 vecinos mÃ¡s cercanos y consigo mismo. Se incluye esta interacciÃ³n si uno supone que muchos
animales (una familia) pueden ocupar una sola cepa, pero las propiedades generales de este juego
no dependen de esta suposiciÃ³n y se puede explorar la situaciÃ³n sin esta autointeracciÃ³n.
51

52

APLICACIONES

Hay en total 225 celdas diferentes, pues dada una configuraciÃ³n inicial para determinar si una celda se mantiene o cambia, es suficiente conocer la disposiciÃ³n de una matriz compuesta por 25
cel-das en la cual el elemento del que se desea saber su evoluciÃ³n ocupa la posiciÃ³n (3, 3), por
ejemplo:
C
C
C
D
D

C
C
C
C
C

C
C
D
D
C

D
D
C
C
C

D
C
C
D
C

?
?
?
?
?

?
8
6
5
?

?
6
6b
7b
?

?
5b
5
6
?

?
?
?
?
?

la matriz de totales serÃ¡:

de manera que si 7b > 8 la casilla D central permanece, si no, cambia para la siguiente generaciÃ³n.
AsÃ­, este juego es caracterizado por una matriz de transiciÃ³n de 225 reglas diferentes, de esta forma
las reglas ya estÃ¡n totalmente definidas y el juego es determinÃ­stico.

Figura 4.1

Frecuencia de los cooperadores

La Figura 4.1 muestra la evoluciÃ³n de la frecuencia de cooperadores x comenzando con la misma
condiciÃ³n inicial aleatoria, pero con valores diferentes para el valor del parÃ¡metro b. Esta simulaciÃ³n es desarrollada en un retÃ­culo cuadrado de 25 Ã— 25 casillas con condiciones limÃ­trofes arregladas, de manera que cualquiera que se encuentre en la frontera tenga siempre 8 vecinos; este
mundo toroidal es escogido para deshacerse de los efectos limÃ­trofes. Se usÃ³ para esta simulaciÃ³n
el programa A.1.2. La configuraciÃ³n inicial es obtenida aleatoriamente asignando un cooperador a
una celda individual con probabilidad x = 0.9. El comportamiento es muy similar para b < 1.25.
Inicialmente la frecuencia de cooperadores decrece a cerca de x â‰ˆ 0.6, entonces el sistema oscila
con perÃ­odo 2 alrededor de x â‰ˆ 0.9. Para b = 1.3 mantienen un perÃ­odo oscilador de 2 luego de 12
generaciones; para b = 1.55 no se encuentra perÃ­odo oscilador en esta simulaciÃ³n, aunque en [43]
se indica un perÃ­odo oscilador de 24 despuÃ©s de 120 generaciones; b = 1.79 genera un oscilador
de perÃ­odo 6 casi constante despuÃ©s de 20 generaciones; b = 1.85 luce completamente irregular y
caÃ³tico (con un valor promedio alrededor de x â‰ˆ 0.31). Para este comportamiento podrÃ­a pensarse
que el perÃ­odo, si lo tiene, es muy grande.

53

Las diferentes regiones de parÃ¡metros.. El desarrollo dinÃ¡mico del sistema depende de la magnitud del parÃ¡metro b; como el pago total no es continuo deben haber solamente transiciones discretas de valores para b que influyen en las dinÃ¡micas.
1. Â¿Para cuÃ¡les valores de b, estructuras compuestas de solo D crecen? Primeramente se estudia
el destino de un solo delator aislado rodeado de cooperadores;
C
C
C
C
C

C
C
C
C
C

C
C
D
C
C

C
C
C
C
C

C
C
C
C
C

9
9
9
9
9

9
8
8
8
9

9
8
8b
8
9

9
8
8
8
9

9
9
9
9
9

con matriz de totales:

Para que la casilla D sobreviva 8b > 8, se reproduce si 8b > 9 y si esto sucede el delator
crecerÃ¡ hasta formar un grupo de delatores de 3 Ã— 3; para saber el destino de este grupo tome
las casillas alrededor de un delator esquinero:
C
C
C
C
C

C
C
C
C
C

9
9
9
9
9

9
8
7
6
7

C
C
D
D
D

C
C
D
D
D

C
C
D
D
D

9
6
3b
0
3b

9
7
5b
3b
5b

su matriz de totales es:
9
7
5b
3b
5b

de manera que si b < 7/5 regresarÃ¡ a un solo delator en la siguiente generaciÃ³n. Este es el
oscilador bÃ¡sico con perÃ­odo 2:
1D âˆ’â†’ 9D âˆ’â†’ 1D

Si 7/5 < b < 8/5, el oscilador mÃ¡s simple de perÃ­odo 3 es formado: 1D crece a 9D, el cual
pierde las esquinas pero mantiene los bordes para formar un 5D devolviendo los ciclos hasta
1D. Si b > 8/5 el delator crece hasta 9D que se mantiene estable si b < 9/5 y se puede esperar
que siga creciendo solo para valores de b > 9/5. Este serÃ¡ el comportamiento para un solo
delator. Si se toma como referencia grupos de 2 Ã³ 4 delatores se obtendrÃ¡ que solo se puede
asegurar que siga creciendo cuando b > 9/5, [43].

2. Â¿Para cuÃ¡les valores de b, estructuras compuestas de solo C crecen? Si b < 1 entonces un
simple cooperador rodeado de delatores crecerÃ¡. AquÃ­, los cooperadores siempre dejarÃ¡n
fuera de competencia a los delatores. Si b > 1 y un cooperador estÃ¡ aislado rodeado de

54

APLICACIONES

Nombre
Columpio

RegiÃ³n
7/5 < b < 2

HÃ©lice

5/4 < b < 2

Cultivador

7/4 < b < 2

CaracterÃ­stica
Once cooperadores que se mueven en
forma vertical y horizontal
Seis cooperadores formando
una escuadra que gira 90o
Diez cooperadores que pueden crecer

Tabla 4.1 Diferentes regiones y grupos de C.

delatores, este desaparecerÃ¡, entonces los cooperadores solo pueden sobrevivir y crecer si
forman grupos. Considere un grupo 2 Ã— 2 de C rodeado de delatores:
D
D
D
D

D
C
C
D

D
C
C
D

D
D
D
D

b
2b
2b
b

2b
4
4
2b

2b
4
4
2b

b
2b
2b
b

su matriz de totales es:

el resto de las casillas estÃ¡n compuestas por 0. Este grupo desaparece para b > 2. En forma
anÃ¡loga un grupo 3 Ã— 3 desaparece para b > 3, y como 9 es el pago mÃ¡s alto que puede
obtener un C, no importa que tan grande sea el grupo C estos siempre desaparecerÃ¡n. En la
Tabla 4.1 se mencionan algunos grupos especiales que pueden evolucionar frecuentemente
fuera de las condiciones originales aleatorias y son mostradas en la Figura 4.2, estos tambiÃ©n
pueden desaparecer si chocan con otras estructuras crecientes de C.

Figura 4.2 a) Columpio b) HÃ©lice y c) Cultivador.

Se puede inferir de estos comentarios que todas las transiciones deben ocurrir en las fracciones de
la forma ba para a, b âˆˆ {9, 8, 7, 6, 5, 4, 3, 2, 1} y 1 < ba < 3 o sea en 98 , 87 , 76 , 56 , 54 , 79 , 43 , 75 , 32 , 58 , 35 , 74 , 95 , 2,

55
9 7 5
4, 3, 2

y 83 .

Conjetura: Sea 1 < b < 3 entonces
(i) Si b < 1.8 entonces solo los grupos C se mantendrÃ¡n creciendo.
(ii) Si b > 2 entonces solo los grupos D se mantendrÃ¡n creciendo.
(iii) Si 1.8 < b < 2 entonces ambos grupos C y D pueden mantenerse en crecimiento.

Figura 4.3 ConfiguraciÃ³n dependiendo de b.

La Figura 4.3 muestra configuraciones tÃ­picas para diferentes valores del parÃ¡metro b. Estas simulaciones estÃ¡n desarrolladas en un retÃ­culo cuadrado de 25 Ã— 25 casillas con condiciones toroidales.
Dichas simulaciones comienzan con una frecuencia inicial de cooperadores en forma aleatoria de
x0 = 0.9 y la figura muestra cada simulaciÃ³n luego de 75 generaciones. El cÃ³digo de color es como
sigue: Azul: un C que fue un C en la generaciÃ³n anterior, Verde: un D que fue C en la generaciÃ³n
anterior, Rojo: un D que fue D en la anterior generaciÃ³n, Amarillo: un C que fue D en la generaciÃ³n
previa.
La cantidad de verdes y amarillos indican cuÃ¡ntas celdas estÃ¡n cambiando de una generaciÃ³n a la
siguiente. El patrÃ³n puramente rojo o azul es estÃ¡tico.
Para b = 1.24 casi todas las celdas estÃ¡n ocupadas por cooperadores. Los delatores ocurren tanto en
una celda aislada con oscilaciones entre 1D y 9D, o en pequenÃ£s lÃ­neas estables no conectadas. Para
b = 1.3 las lÃ­neas de delatores llegan a conectarse. Los osciladores bÃ¡sicos son otra vez delatores
simples, pero las lÃ­neas pueden oscilar tambiÃ©n. Estos osciladores son generalmente de perÃ­odo
2. Para b = 1.55 hay largas lÃ­neas conectadas y todas las lÃ­neas pueden oscilar (usualmente con
perÃ­odo 2). Delatores simples oscilan ahora con perÃ­odo 3, el oscilador
1D âˆ’â†’ 9D âˆ’â†’ 5D âˆ’â†’ 1D
La interacciÃ³n entre estructuras grandes pueden conducir a osciladores con un perÃ­odo muy alto.
Las cosas son diferentes para b = 1.79. AquÃ­ el patrÃ³n es casi completamente estÃ¡tico. Una red
irregular de delatores se extiende por todo el retÃ­culo. Para b = 1.85 la estructura aparece completamente caÃ³tica, hay alrededor del 31 % de cooperadores; una gran fracciÃ³n de celdas estÃ¡
cambiando de una generaciÃ³n a la siguiente. El mundo estÃ¡ cubierto con delatores, pero los cooperadores existen en muchos grupos pequeÃ±os; estos grupos tienen tendencia a crecer, pero en

56

APLICACIONES

cualquier momento que dos de estos grupos estÃ©n muy cerca, los delatores entre ellos obtienen el
mÃ¡s alto pago y comienzan a crecer. Los cooperadores ganan a lo largo de lÃ­neas rectas, los delatores ganan a lo largo de fronteras irregulares; el resultado es un equilibrio dinÃ¡mico, de manera
que el arreglo estÃ¡ siempre cambiando pero dinÃ¡micamente estable. Para b = 2.01 otro patrÃ³n
estÃ¡tico es observado, los cooperadores no crecen pero no todos desaparecen.
La frecuencia de cooperadores.. Para frecuencias iniciales de delatores muy pequeÃ±as, es fÃ¡cil
calcular la frecuencia promedio aproximada aÃºn cuando b estÃ© cercano pero menor a 1.8, esto
puede ser hecho asumiendo que la mayorÃ­a de los delatores ocurrirÃ¡n en celdas aisladas; en este
caso se sabe exactamente el destino para cada individuo D. Sea y0 la frecuencia inicial de delatores,
y y la frecuencia de equilibrio para los delatores. Para b < 1 se tiene y = 0. Los siguientes resultados
se mantienen para valores muy pequeÃ±os de y0 . Para 1 < b < 9/8 se tiene y = y0 . Si 9/8 < b < 7/5
se tiene y = 5y0 . Este es el promedio del oscilador 1D âˆ’â†’ 9D âˆ’â†’ 1D. Si 7/5 < b < 8/5 se tiene
nuevamente y = 5y0 , el promedio del oscilador 1D âˆ’â†’ 9D âˆ’â†’ 5D âˆ’â†’ 1D. Si 8/5 < b < 9/5 se
tiene y = 9y0 , porque todos los delatores aislados se convierten en cuadrados estables de 3 Ã— 3. Si
9/5 < b un delator aislado ocasiona una estructura creciente y el cÃ¡lculo de la frecuencia promedio
de cooperadores comienza a no ser fÃ¡cil. No se intenta calcular el promedio de las frecuencias de
cooperadores en las simulaciones que comienzan con una gran fracciÃ³n de delatores, pues para una
configuraciÃ³n inicial aleatoria los delatores siempre estÃ¡n en ventaja, ya que ellos se encuentran
a ellos mismos en el vecindario de muchos cooperadores. Muchos cooperadores desaparecen en
las primeras dos generaciones, aÃºn asÃ­ estructuras conectadas de delatores crecen y la situaciÃ³n
se hace difÃ­cil. Fluctuaciones aleatorias nos pueden dejar con pocos grupos de C que no pueden
crecer como columpios o hÃ©lices, o como un simple cuadrado de cooperadores que crecen para
ganar el mundo completo. Para 1 < b < 1.8 casi todas las condiciones iniciales llevan la frecuencia
promedio de cooperadores entre 0.7 y 0.95. Para 1.8 < b < 2 las frecuencias rondan el 0.3.

4.1.2 La invasiÃ³n de delatores: Un caleidoscopio evolutivo.
Una interesante secuencia de patrones resulta de un Ãºnico delator invadiendo un mundo de cooperadores en una regiÃ³n del parÃ¡metro 1.8 < b < 2. En la generaciÃ³n t = 0 se empieza con un
delator. Este delator primero crece para formar un cuadrado 3 Ã— 3 y luego un cuadrado 5 Ã— 5 de
delatores, se sabe que los delatores ganan en las esquinas pero pierden a lo largo de las lÃ­neas. El
resultado es un interesante y bello patrÃ³n de crecimiento. Se pueden estudiar estos patrones en un
arreglo finito (con condiciones limÃ­trofes arregladas o cÃ­clicas) o en un arreglo infinito. La Figura
4.4 muestra un â€œcaleidoscopio evolutivo" que es generado por un Ãºnico delator invadiendo un
arreglo finito de 51 Ã— 51 cooperadores con condiciones limÃ­trofes. Cada generaciÃ³n muestra una
nueva pintura. La simetrÃ­a inicial nunca es quebrada porque las reglas son simÃ©tricas pero la frecuencia de cooperadores oscila caÃ³ticamente. Estas oscilaciones no pueden continuar para siempre.
El nÃºmero total de posibles estados es solo finito (aunque muy grande: para un arreglo de n Ã— n se
2
tienen aproximadamente 2n /8 diferentes configuraciones). El caleidoscopio debe eventualmente
converger a algÃºn oscilador con perÃ­odo finito. Caleidoscopios mÃ¡s pequeÃ±os van a un estado
donde todas las celdas estÃ¡n ocupadas por delatores. Este estado â€œtodo D" es un estado atractor, lo
que significa que una vez que usted estÃ© ahÃ­ permanecerÃ¡ allÃ­. Otro estado atractor es el â€œtodo C",
pero este estado nunca se puede alcanzar por un caleidoscopio que empiece con un delator en el
medio, porque este delator nunca va a ser reemplazado por un cooperador.
Las caracterÃ­sticas geomÃ©tricas de estos caleidoscopios se originan de una combinaciÃ³n de las reglas, la impredecibilidad determinÃ­stica, el caos transitorio y para algunos casos especiales, simetrÃ­a.
Es interesante el caso cuando un Ãºnico delator invade grandes retÃ­culos de cooperadores, Figura
4.4. Por la reglas, las secuencias se repiten, aunque este retÃ­culo es finito; si se piensa en un arreglo

57

Figura 4.4 Caleidoscopio evolutivo con b = 1.85

infinito estos conjuntos tienen una frontera irregular presentando mÃ¡s irregularidades en cada iteraciÃ³n; esto es una de las caracterÃ­sticas de los fractales. Si se toma por ejemplo las generaciones
2n âˆ’ 1, Figura 4.5, y se extrae la fracciÃ³n de la figura que representa el rojo o sea las casillas que
permanecen D, se nota que hay un patrÃ³n repetitivo similar al provocado por un sistema iterado
de funciones, en el cuÃ¡l la frontera aumenta en cada generaciÃ³n de este tipo. El conjunto lÃ­mite (si
existe) debe tener frontera infinita y Ã¡rea mayor que cero por lo que no serÃ¡ un fractal, pero su
frontera es posible que lo sea, ademÃ¡s como el tamaÃ±o de cada cuadro disminuye, la dimensiÃ³n de
conteo puede ser aplicable.
May y Novak llaman a todas estas generaciones Fractales DinÃ¡micos. La estructura completa D
toma siempre la forma de un cuadrado en la generaciÃ³n t = 2m , m = 0, 1, 2, 4, 8 y 16. Se puede
mostrar que el nÃºmero de delatores despuÃ©s de t = 0, 1, 2, 4, . . . generaciones, es (2n + 1)2 comenzando con un Ãºnico delator invadiendo un mundo infinito de cooperadores. Estas generaciones
corresponden a las estructuras de cuadrados de estos fractales dinÃ¡micos. Estos cuadrados consisten solo en delatores. Para t = 32 hay 8 grupos de cooperadores, pero ellos desaparecen en
la siguiente generaciÃ³n. Para generaciones mayores los cuadrados contienen muchos grupos de
cooperadores que pueden persistir.
4.1.3

Un fractal dinÃ¡mico

Aunque las estructuras involucradas son finitas, se puede pensar en el tiempo como una variable
infinita. Se ha notado que para la regiÃ³n ]1.8, 2[, las estructuras C y D crecen con una frecuencia de
cooperadores caÃ³tica, (los fractales estÃ¡n muy relacionados a procesos con caos).
Estos fractales dinÃ¡micos sirven como modelo para describir el patrÃ³n de crecimiento que evoluciona de un Ãºnico delator invadiendo un arreglo infinito de cooperadores, y calcular la frecuencia

58

APLICACIONES

Figura 4.5 ConstrucciÃ³n de un fractil usando DP.

de cooperadores (dentro de la estructura de crecimiento) mientras el tiempo tiende a infinito. Esto
servirÃ¡ para predecir esta frecuencia en los casos donde hay escogencia aleatoria. Se supone que
esta frecuencia de delatores es pequeÃ±a. Se asume que en la generaciÃ³n 2n existe un cuadrado que
consiste en (2n+1 + 1)2 delatores. Se desprecia el hecho de que hay en este momento muchos grupos de cooperadores dentro de este cuadrado para t â‰¤ 32. Se supone que este cuadrado ahora
crece en las esquinas y se reduce en el medio. Esto resulta en la formaciÃ³n de 4 nuevos cuadrados
pequeÃ±os en las esquinas y un cuadrado grande en el centro. Se asume que este simple patrÃ³n de
crecimiento continÃºa , los cuatro cuadrados en las esquinas se hacen mÃ¡s grandes y el del centro
se hace mÃ¡s pequeÃ±o. No se toma en cuenta que los 4 cuadrados tambiÃ©n crecen en las esquinas y
pierde en las lÃ­neas de los lados. Bajo estas suposiciones el nÃºmero de delatores en la generaciÃ³n
t + i, con t = 2n y 0 â‰¤ i < t es dado por:
ND = (2t + 2i + 1)2 âˆ’ 8i (2t âˆ’ 2i âˆ’ 1).

(4.1)

La fracciÃ³n de cooperadores dentro del cuadrado (2t + 2i + 1)2 en el tiempo t + i es dado por:
x (t + i)

=

8i (2t âˆ’ 2i âˆ’ 1)
(2t + 2i + 1)2

(4.2)

4i (t âˆ’ i )
( t + i )2

(4.3)

Para t muy grande esto es:
x (t + i)

â‰ˆ

Esto describe oscilaciones con perÃ­odos crecientes. El mÃ­nimo ocurre en t = 2n (i = 0) y el mÃ¡ximo
cuando i = t/3. El promedio de cooperadores sobre un ciclo, conforme i va de 0 a t, es dado por:
x=

1 t 4i (t âˆ’ i )
â‰ˆ4
2
t iâˆ‘
=0 ( t + i )

Z 1
s(1 âˆ’ s)
0

(1 + s)2

ds = 12 ln 2 âˆ’ 8 = 0.31776617 . . . .

Este promedio es un arreglo con los valores numÃ©ricos del modelo original, parece que ambos
coinciden con el lÃ­mite de la fracciÃ³n de cooperadores en los patrones de crecimiento simÃ©trico y
con el promedio en las simulaciones comenzando en condiciones iniciales aleatorias no simÃ©tricas.

59

La invasiÃ³n de cooperadores. Cooperadores pueden tambiÃ©n invadir un mundo de delatores.
Comenzando al menos con un cuadrado de 2 Ã— 2 de cooperadores, se observan cuadrados crecientes de cooperadores que se expanden hasta sacar de competencia todos los delatores. Esto
pasa aÃºn para valores b cercanos y menores que 1.8.
Patrones de crecimiento mÃ¡s interesantes ocurren si se comienza con grupos de cooperadores de
formas irregulares, como un Cultivador, vÃ©ase Figura 4.2c). Para 1.75 < b < 1.8, este crecimiento
se expande hasta generar un patrÃ³n geomÃ©trico peculiar. Eventualmente la mayorÃ­a de las celdas
van a estar ocupadas con cooperadores. A travÃ©s de una lÃ­nea diagonal hay una â€œtira" intermitente
de delatores que sobran, hay tambiÃ©n bloques estÃ¡ticos de delatores alineados bellamente en lÃ­neas
y columnas, Figura 4.6(inferior). Para 1.8 < b < 2, el crecimiento tambiÃ©n se expande indefinidamente pero es comido en el medio por estructuras fractales como delatores, recordando aquellos
que se encuentran en los caleidoscopios simÃ©tricos.

Figura 4.6 InvasiÃ³n de cooperadores.

4.1.4

Conclusiones

Al considerar la cooperaciÃ³n de individuos no relacionados usando como modelo de simulaciÃ³n el
Dilema del Prisionero, se puede observar como estructuras rÃ­gidas, como el determinismo, sugiere
una habilidad de la naturaleza para jugar a los dados y provocar caos dentro de este determinismo.
Se nota ademÃ¡s cÃ³mo las reglas de este juego definen una funciÃ³n, la cual se aplica iteradamente y
aunque el atractor es geomÃ©tricamente diferente, es estadÃ­sticamente estable para algunos valores
de b, mientras que en otros el patrÃ³n estable es el estado â€œtodo D". Cuando se utiliza un solo
delator el patrÃ³n de movimiento es ciclÃ­co o caÃ³tico, en este Ãºltimo el patrÃ³n simÃ©trico es usado
para predecir la frecuencia de los cooperadores para valores de b en este rango.
Las figuras simÃ©tricas cambiantes forman patrones similares a las construcciones de fractales, de
hecho sus fronteras presentan una variedad sorprendente, en donde se fomenta la irregularidad
(â€œlos delatores ganan en fronteras irregulares y los cooperadores sobre lÃ­neas rectas").
Aunque los conjuntos de delatores no tienen frontera fractal, en el sentido que se ha definido pues
son finitos, brindan un lenguaje adecuado para estudiar estos fenÃ³menos biolÃ³gicos. AdemÃ¡s si se
utilizan algunas generaciÃ³nes particulares Ã©stas presentan autosemejanza.
Si se usa otro nÃºmero de vecinos interactuando con el dueÃ±o, las caracterÃ­sticas se mantienen en lo
visto cuando hay 8 vecinos y la auto-interacciÃ³n.

60

APLICACIONES

4.2

CompresiÃ³n de imÃ¡genes

La compresiÃ³n de imÃ¡genes juega un papel importante en el almacenamiento de imÃ¡genes con
un menor costo, asÃ­ como en la rÃ¡pida transmisiÃ³n de datos. Claro que al comprimir y luego descomprimir estos datos se puede perder informaciÃ³n, esta informaciÃ³n perdida muchas veces no
se percibe por el ojo humano o es redundante, y los mÃ©todos de compresiÃ³n eficientes son los que
logran extraer el â€œespÃ­ritu" de la imagen, para despuÃ©s de descomprimir, reproducir una imagen
muy cercana a la original. En la naturaleza muchos objetos mantienen una autosemejanza que se
puede representar como el atractor de un sistema iterado de funciones, tal es el caso de las nubes,
helechos, plantas, Ã¡rboles, arbustos, etc. La teorÃ­a de los fractales tiene aplicaciones en la compresiÃ³n de imÃ¡genes, en el sentido que se puede pensar que un objeto de esta naturaleza se puede
transmitir o guardar eficientemente, reproduciÃ©ndolo en el momento que se desee.
En el aÃ±o de 1987 dos matemÃ¡ticos del Instituto TecnolÃ³gico de Georgia, Michael Barnsley y Alan
Sloan, formaron Iterated Systems Inc., una compaÃ±Ã­a con base en Atlanta, en donde se usa el desarrollo de la teorÃ­a fractal aplicado a la compresiÃ³n. Uno de los productos mÃ¡s conocidos es la
enciclopedia Encarta, publicada por Microsoft Corp., que incluye en un CD-Rom, 700 fotografÃ­as a
color, en su Ãºltima versiÃ³n de 1997 se incluyen mÃ¡s de 30000 artÃ­culos, fotos, mapas, etc. Otro producto es el Fractal Imager5, un programa que recibe un archivo, preferiblemente en formato .JPG,
y lo comprime en otro .FIF (fractal image format), que se puede descomprimir y ver con el Fractal
Viewer, aumentando secciones de ella a cualquier nivel.
El primer esquema de compresiÃ³n de este tipo publicado, fue la tesis doctoral de Arnaud Jacquin,
estudiante de Barnsley, en 1989. Otros aportes importantes los dieron Y. Fisher, R. D. Boss y E. W.
Jacobs entre otros.
Una imagen es guardada en el computador como una colecciÃ³n de valores que indican el nivel de
gris o color en cada punto (pixel) de la imagen inicial. Los archivos en formato BMP, abreviado de
BitMaP, son formatos de mapas de bits para Windows y tienen extensiÃ³n .BMP, y algunas veces
llevan la extensiÃ³n .RLE, iniciales de run length encoding que indica que los datos del mapa de
caracteres fueron comprimidos usando uno de los dos mÃ©todos de compresiÃ³n RLE. Los archivos
.BMP comprimen la informaciÃ³n del color usando 1, 4, 8 Ã³ 16 bits por pixel (bpp). El cÃ¡lculo de los
bpp determinan el mÃ¡ximo nÃºmero de colores que la imagen puede tener, y estÃ¡ dado por 2bpp .
Si la imagen es un 1-bpp hay 2 colores posibles, si la imagen es un 8-bpp, lo mÃ¡s usual, hay 256
colores mientras que si es 24-bpp se tendrÃ­an mÃ¡s de 16 millones de colores. La estructura de cada

.BMP
.GIF
JPEG
.PCX
.PNG
TIFF

MÃ¡x.
bpp
24
8
24
24
48
24

NÃºmero mÃ¡ximo
de colores
16777216
256
16777216
16777216
281474976710656
16777216

TamaÃ±o mÃ¡ximo
de la imagen en pixeles
65535 Ã— 65535
65535 Ã— 65535
65535 Ã— 65535
65535 Ã— 65535
2147483647 Ã— 2147483647
4294967295
en total

MÃ©todo de
compresiÃ³n
RLE
LZW
JPEG
RLE
deflaciÃ³n
LZW, RLE
otros

Tabla 4.2 Diferentes formatos grÃ¡ficos.

5 En Internet se pueden conseguir en http://www.iterated.com, junto con una gran variedad de fotos comprimidas en
formato .FIF.

61

uno de los diferentes formatos que aparecen en la Tabla 4.2 y como guardan la informaciÃ³n se
puede encontrar en [46].
4.2.1

Comprimiendo imÃ¡genes con IFSâ€™s

â†’ Rn funciones de crecimiento acotado âˆ€i =
1, . . . , m, y suponga que para todo i se tiene |Si ( x ) âˆ’ Si (y)| â‰¤ c| x âˆ’ y| para todo x, y âˆˆ Rn , con c < 1.
Sea E âŠ‚ Rn compacto no vacÃ­o, entonces
!
m
[
1
D ( E, F ) â‰¤ D E,
Si ( E )
(4.4)
1âˆ’c
i =1
Teorema 43. (Collage). Suponga que se tienen Si :

Rn

donde F es el conjunto invariante de los Si y D la mÃ©trica Hausdorff.
DemostraciÃ³n. VÃ©ase [11, p. 134].



El teorema 43 garantiza que el conjunto invariante puede ser una buena aproximaciÃ³n del conjunto
inicial si la uniÃ³n de copias pequeÃ±as estÃ¡n cerca de Ã©ste, pues en este caso se tendrÃ­a que D ( E, F )
se acercarÃ­a a cero. En este sentido y como consecuencia de este teorema, el siguiente resultado nos
dice que un conjunto compacto se puede aproximar tanto como se quiera, bajo la mÃ©trica Hausdorff, por un conjunto autosemejante e invariante de un sistema iterado de funciones. Si el conjunto es mÃ¡s complicado, este se puede ver como la superposiciÃ³n de varios conjuntos invariantes
de varios sistemas de funciones.
Corolario 9. Sea E âŠ‚

Rn compacto no vacÃ­o. Para todo Î´ > 0 existe un sistema iterado de funciones de

crecimiento acotado S1 , . . . , Sn con conjunto invariante F tal que D ( E, F ) < Î´.
DemostraciÃ³n. VÃ©ase [11, p. 134].



Se puede pensar que una imagen en una escala de gris, con todos los tonos de gris entre el blanco
y el negro, se puede ver como z = f ( x, y) que representa el nivel de gris en el pixel ( x, y), donde
el menor valor de f es blanco y el mayor es negro. Se asumirÃ¡ que f : I Ã— I â†’ I, donde I =
[0, 1]. Los mÃ©todos de compresiÃ³n de imÃ¡genes se pueden evaluar usando la razÃ³n de compresiÃ³n,
que es la razÃ³n de la memoria requerida para guardar la imagen como colecciÃ³n de pixeles y la
memoria requerida para guardar la representaciÃ³n de la imagen en forma comprimida. Un archivo
de alrededor de 720KB se puede comprimir en .FIF en 12KB, para una razÃ³n de compresiÃ³n de
720:12, es decir, 60:1.
Las aplicaciones afines, definiciÃ³n 1.1, son en general rotaciones, reflexiones, traslaciones, contracciones o cambios en los ejes, que se pueden representar por
vi



x
y



=



ai
ci

bi
di



x
y



+



ei
fi



.

(4.5)

Se pueden usar diferentes mÃ©tricas para medir la distancia entre dos imÃ¡genes, dos de ellas son la
mÃ©trica rms y la mÃ©trica sup que es mÃ¡s sencilla:
rZ
(4.6)
drms ( f , g) =
( f ( x, y) âˆ’ g( x, y))2 dx dy
I2

dsup ( f , g)

R

R

=

sup | f ( x, y) âˆ’ g( x, y)|.

(4.7)

( x,y )âˆˆ I 2

Sean f 0 , f 1 , f 2 : 2 â†’ 2 tal que f 0 (( x, y)) = 12 ( x, y), f 1 (( x, y)) = 12 ( x, y) + 12 (1, 0) y f 2 (( x, y)) =
1
1
o
2 ( x, y ) + 2 (0, 1). RÃ³tese el eje Y un Ã¡ngulo de 30 a favor de las manecillas del reloj, note que estas

62

APLICACIONES

se define un sistema iterado de funciones (IFS) que
funciones son semejanzas de razÃ³n 21 . Con
 esto 
1 1 1
realizan la lista contractiva de razones 2 , 2 , 2 . Antes de dar la relaciÃ³n de estas tres funciones
con S, el triÃ¡ngulo de SierpinÌski, se puede pensar en este sistema iterado de funciones como una
mÃ¡quina de fotocopiar con tres lentes, la primera lente forma una copia reducida al 50% en la parte
izquierda de la figura, la segunda lente forma una copia reducida al 50% en la parte derecha de
la figura y la tercera lente forma una copia reducida al 50% en la parte superior centrada de la
figura. Ahora se toma una figura cualquiera, le sacamos la primera copia en nuestra mÃ¡quina y
Ã©sta se vuelve a copiar, se hace esto varias veces y se debe obtener una figura similar al atractor del
sistema.
Esta mÃ¡quina de copiado de reducciÃ³n mÃºltiple (MCRM), se puede representar como en la Figura
4.7, donde se indica ademÃ¡s la orientaciÃ³n de la copia. El atractor de este MCRM es el triÃ¡ngulo
de SierpinÌski, con un cambio de ejes. En total hay 83 posibles MCRM, tomando en cuenta las posi-

Figura 4.7 MCRM cuyo atractor es el TriÃ¡ngulo de SierpiÂ«ski.

bles rotaciones, reflexiones, traslaciones y contracciones a escala 1/2, anÃ¡logas a la Figura 4.7. Un
anÃ¡lisis de la simetrÃ­a y conexidad de ellas se puede ver en [44, sec. 5.3].
A estas MCRM, se les puede permitir algÃºn estiramiento de la copia, asÃ­ se obtienen gran variedad
de sistemas iterados, con atractores muy variados: Helecho de Barnsley, Figura 4.9 parte (b); Ã¡rbol, Figura 4.10. Estos atractores, a pesar de ser tan naturales, se obtienen de la misma forma que
algunos â€œmonstruos" como la curva de Koch, el triÃ¡ngulo de SierpinÌski, el Twindragon etc.
Figura
4.8

Figura
4.10

f1
f2
f3
f4
f1
f2
f3
f4
f5

a
0.849
0.197
âˆ’0.15
0
0.195
0.462
âˆ’0.058
âˆ’0.035
âˆ’0.637

b
0.037
âˆ’0.226
0.283
0
âˆ’0.488
0.414
âˆ’0.07
0.07
0

c
âˆ’0.037
0.226
0.26
0
0.344
âˆ’0.252
0.453
âˆ’0.469
0

d
0.849
0.197
0.237
0.16
0.443
0.361
âˆ’0.111
âˆ’0.022
0.501

e
0.075
0.4
0.575
0.5
0.4431
0.2511
0.5976
0.4884
0.8562

f
0.183
0.049
âˆ’0.084
0
0.2452
0.5692
0.0969
0.5069
0.2513

Tabla 4.3 Funciones generadoras.

4.2.2 Descomprimiendo imÃ¡genes con IFSâ€™s.
Con este esquema de guardar solamente el sistema iterado de funciones y reproducir una aproximaciÃ³n de su atractor en el momento que se desee, pueden presentarse algunos problemas en
cuanto al tiempo de descompresiÃ³n, aunque la razÃ³n de compresiÃ³n es muy buena, en algunos de
estos el tiempo de descompresiÃ³n no lo es.

63

Para la descompresiÃ³n del helecho de Barnsley se usÃ³ el sistema de funciones descrito en la Tabla
4.3. Aplicando este sistema iterado de funciones a x0 se obtienen 4 imÃ¡genes, es decir, f 1 ( x0 ), f 2 ( x0 ),
f 3 ( x0 ), f 4 ( x0 ) y al aplicar de nuevo el sistema se obtienen 16 imÃ¡genes, asÃ­ sucesivamente. En este
procedimiento el programa que se usÃ³, A.1.3, representÃ³ 47 puntos, pero muchos de ellos estÃ¡n
cerca de su imagen, sobre todo los que se obtienen al aplicar f 4 y la resoluciÃ³n que se obtiene no es
muy buena, Figura 4.8.

Figura 4.8

Helecho de Barnsley aplicando el IFS de Tabla 4.3.

Figura 4.9 (a) Juego del Caos. (b) Juego del Caos con probabilidades diferentes.

Pensando en este problema, se puede modificar la aplicaciÃ³n del sistema usando el Juego del Caos,
en donde en cada paso no se aplican todas las funciones sino solamente una funciÃ³n de manera
aleatoria, todas con la misma probabilidad. Esto quiere decir que si x0 es el punto inicial, se tiene
que xn = f ik ( xnâˆ’1 ) escogiendo ik con igual probabilidad del conjunto {1, 2, 3, 4}. Con este procedimiento se obtuvo la Figura 4.9 parte (a). AÃºn asÃ­, el Juego del Caos descrito aquÃ­ se puede modificar tomando diferentes probabilidades pi para cada funciÃ³n f i , este proceso recibe el nombre
de sistema iterado recurrente de funciones (RIFS); una excelente exposiciÃ³n sobre la existencia,
unicidad, convergencia y caracterizaciÃ³n del atractor se puede encontrar en [5]. La aplicaciÃ³n a
compresiÃ³n de imÃ¡genes lo ilustra John Hart en [21], con algunos ejemplos. Un buen Ã­ndice, para

64

APLICACIONES

Î´ pequeÃ±o, estÃ¡ dado por
pi =

mÃ¡x(Î´, |Ci |)

n

,

(4.8)

âˆ‘ mÃ¡x(Î´, |Ci |)

i =1



 a i bi 

 y se tiene que âˆ‘ pi = 1.
donde |Ci | = det Ci = 
ci di 
Con Î´ = 0.01 y usando el programa A.1.4, se obtuvo la Figura 4.9 parte (b), que tiene una mejor
resoluciÃ³n con la misma cantidad de puntos que las Figuras 4.8 y 4.9 parte (b).
Otros ejemplos de descompresiÃ³n de un RIFS, aplicado a un punto como imagen inicial, son el
Ã¡rbol de la Figura 4.10, para el sistema de funciones descrito en la Tabla 4.3 y la rama de la Figura
4.11.

Figura 4.10

Un Ã¡rbol como atractor.

Figura 4.11

Una rama como atractor.

Si a la mÃ¡quina de fotocopiado se le agrega el control del contraste y del brillo, entonces se pueden
comprimir imÃ¡genes en una escala de gris. Para esto se consideran las aplicaciones afines vi sobre
2 dadas en (4.5) con una dimensiÃ³n mÃ¡s que controla el contraste y el brillo, a estas aplicaciones
se las denotarÃ¡ wi , es decir
ï£«
ï£¶ ï£«
ï£¶ï£«
ï£¶ ï£«
ï£¶
x
a i bi 0
x
ei
wi ï£­ y ï£¸ = ï£­ ci di 0 ï£¸ ï£­ y ï£¸ + ï£­ f i ï£¸
(4.9)
z
0 0 si
z
oi

R

65

donde si controla el contraste y oi el brillo de wi . Sean Di y Ri el dominio y el rango de vi , es
S
decir, vi ( Di ) = Ri . Se pide ademÃ¡s que Ri = I 2 y Ri âˆ© R j = âˆ… para i 6= j, es decir, las copias
cubren todo I 2 y las imÃ¡genes no se traslapan, Teorema 5. Sea f 0 una imagen inicial, se quiere
encontrar el atractor f = xW del sistema iterado de funciones, o sea W ( f ) = w1 ( f ) âˆª w2 ( f ) âˆª Â· Â· Â· âˆª
w N ( f ) = f . El Teorema 3 garantiza la existencia y unicidad del atractor para cualquier f 0 inicial.
Para codificar una imagen se necesita encontrar los Di , Ri y wi . Y para decodificar la imagen, se
aplicarÃ­a repetidamente W a cualquier imagen inicial, por ejemplo un punto hasta que estÃ© â€œcerca"
de xW .
Lo Ã³ptimo serÃ­a encontrar el atractor del sistema iterado, pero basta encontrar una imagen f â€² , que
en algÃºn paso de la iteraciÃ³n estÃ© cerca de f , es decir, drms ( f â€² , f ) sea pequeÃ±o. Para esto es claro
que se necesita minimizar la distancia entre f âˆ© ( Ri Ã— I ) y wi ( f ), la distancia entre la porciÃ³n de la
imagen y su imagen, es decir, encontrar el mÃ­nimo de
dsup ( f âˆ© ( Ri Ã— I ), wi ( f )),

âˆ€i = 1, . . . , N

(4.10)

asÃ­ el problema se resume en encontrar los Ri y los Di y por consiguiente los wi .
De lo anterior, para codificar una imagen usando algÃºn esquema que use los elementos de la teorÃ­a
fractal, se necesita particionar la imagen por alguna colecciÃ³n de rangos Ri ; para cada Ri se fija de
alguna colecciÃ³n de imÃ¡genes un Di que tenga un error rms pequeÃ±o cuando se aplica en Ri y por
S
Ãºltimo de la ecuaciÃ³n (4.9) se determinan ai , bi , ci , di , ei , f i , si y oi . Con esto se obtiene W = wi que
codifica la imagen original.
4.2.3

MÃ©todos de particiÃ³n de imÃ¡genes

Algunos de los mÃ©todos que se usan para encontrar los Ri son: particiÃ³n Quadtree, particiÃ³n HV y
la particiÃ³n triangular.
En el particionamiento usando Quadtree, Ã¡rboles de cuadrados, se supone que la imagen inicial es
de 256 Ã— 256 pixeles y con 8 bpp. Al partir esta imagen en subcuadrados de 8 Ã— 8 pixeles que no se
traslapen, se obtienen como elementos del rango: R1 , . . . , R1024. Como un cuadrado de 16 Ã— 16 se
particiona en cuatro de 8 Ã— 8, se puede considerar D como la colecciÃ³n de todos los dominios posibles que consta de cuadrados de tamaÃ±o 32 Ã— 32 pixeles, y para cada Ri se busca el respectivo Di ,
que se asigna cuando se minimiza (4.6). Para una tolerancia ec predeterminada, si (4.6) es menor
que ec , Ri y Di quedan en la particiÃ³n, si no, entonces se divide Ri en cuatro cuadrados iguales y
en cada cuadrado se repite el proceso. Cada transformaciÃ³n requiere de 8 bits en cada direcciÃ³n x
y y para determinar la posiciÃ³n sobre Di , 7 bits para oi , 5 bits para si y 3 bits para determinar la
operaciÃ³n de rotaciÃ³n de la aplicaciÃ³n Di sobre Ri , es decir, un total de 31 bits por transformaciÃ³n.
Como se tienen 1024 transformaciones, esto darÃ­a 31744 bits que es igual a 3968 bytes. Una imagen en formato .BMP se almacena en 65536 bytes, Tabla 4.2, con lo que se obtiene una razÃ³n de
compresiÃ³n de 65536:3968 es decir 16.5:1.
Algo muy importante en este algoritmo de compresiÃ³n es que se puede escoger una base de
cuadrados como posibles dominios de las funciones, es decir, los posibles dominios se escogen
de esta base. La fase de formar la imagen resulta en ir pegando estos cuadrados en el orden correcto uno al lado del otro. CÃ³mo se encuentra esta base, cuÃ¡ntos elementos debe tener y algunas
consideraciones sobre el tiempo de compresiÃ³n se pueden ver en [14, Cap. 4].
En el particionamiento HV se usan rectÃ¡ngulos horizontales y verticales. Dados dos cuadrados que
contienen n pixeles de intensidad, a1 , . . . , an de Di y b1 , . . . , bn de Ri , se quiere encontrar s y o que
minimizen
n

R=

âˆ‘ (sai + o âˆ’ bi )2,

i =1

(4.11)

66

APLICACIONES

se debe tener que

âˆ‚R
âˆ‚R
= 0 y ademÃ¡s
= 0, ello ocurre cuando
âˆ‚s
âˆ‚o

s

=

n

n

i =1

i =1

n

n

n âˆ‘ a i bi âˆ’ âˆ‘ a i
n âˆ‘ a2i âˆ’

o

=

"

âˆ‘ bi

i =1

âˆ‘ ai

i =1

1
n

n

i =1

n

n

i =1

i =1

âˆ‘ bi âˆ’ s âˆ‘ bi

(4.12)

!2

#

(4.13)

en este caso, se tiene R es igual a
1
n

"

n

âˆ‘
i =1

b2i + s

n

sâˆ‘
i =1

a2i âˆ’ 2

n

n

i =1

i =1

âˆ‘ ai bi +2o âˆ‘ ai

!

2

n

#

+ no âˆ’ 2o âˆ‘ bi
i =1

(4.14)

En la Figura 4.12, se muestra la idea del esquema de particiÃ³n. La parte (a) es la figura inicial, la
parte (b) representa la primera particiÃ³n que genera dos rectÃ¡ngulos: R1 que se cruza de vÃ©rtice
al vÃ©rtice opuesto y R2 que no se cruza, la parte (c) particiona R1 en cuatro rectÃ¡ngulos, dos que
pueden ser bien cubiertos por R1 ya que son partidos diagonalmente y dos que son bien cubiertos
por R2 , pues no tienen diagonal. En [14, ApÃ©ndice A] se da un programa, en lenguage C, para

Figura 4.12

Esquema HV.

comprimir y descomprimir imÃ¡genes usando este esquema.
En el particionamiento triangular una imagen rectangular se divide en dos triÃ¡ngulos, y estos a su
vez se subdividen en cuatro triÃ¡ngulos que se obtienen de unir tres puntos, uno de cada uno de los
lados de cada triÃ¡ngulo, Figura 4.13, en cada uno de estos se repite el proceso hasta que la distancia
entre las imÃ¡genes no exceda una tolerancia predeterminada. Los puntos que se escogen pueden
ser los puntos medios de los lados.

Figura 4.13

ParticiÃ³n Triangular.

4.2.4 Conclusiones
En estos esquemas de compresiÃ³n de imÃ¡genes usando la teorÃ­a fractal, hay un proceder automÃ¡tico. Estos mÃ©todos dependen de algunos parÃ¡metros como el nÃºmero mÃ¡ximo de iteraciones,

67

una tolerancia o distancia mÃ¡xima permitida entre Ri y la imagen de Di , etc. Se encuentra un sistema iterado de funciones que es el que guarda la imagen. En la etapa de descompresiÃ³n se aplica
el sistema a una imagen inicial arbitraria y luego de algunas iteraciones se obtiene una imagen
muy cercana a la imagen que se comprimiÃ³. En esta etapa de aplicar el sistema a una imagen inicial arbitraria, que puede ser un punto, se debe tener en cuenta el tiempo de decodificaciÃ³n. Para
esto se puede pensar en los RIFS, que aplican las funciones del IFS con diferentes probabilidades.
En algunos casos este procedimiento no ayuda y la imagen que se reproduce no tiene una mejor
resoluciÃ³n que la que se obtiene por aplicar el IFS, por ejemplo la Figura 4.10. En otros, como la
Figura 4.9 parte b), el RIFS supera ampliamente la resoluciÃ³n del IFS.
Existen ademÃ¡s otros esquemas de compresiÃ³n de imÃ¡genes usando la teorÃ­a fractal, [14, Caps.
9,13], [22]. En la prÃ¡ctica, el que mejores resultados de compresiÃ³n da es el particionamiento por el
esquema HV, en donde una imagen comprimida en JPEG con una razÃ³n de compresiÃ³n de 54.3:1 se
puede comprimir usando el esquema HV con una razÃ³n de 58.1:1, y la resoluciÃ³n es mucho mejor,
[14, ApÃ©ndice D].
En estos esquemas, la razÃ³n de compresiÃ³n es muy buena sin embargo el tiempo de descompresiÃ³n
no lo es, este es uno de los mayores problemas que enfrenta.
Desde finales de los 80â€™s el desarrollo de los mÃ©todos de compresiÃ³n usando la teorÃ­a fractal va en
aumento, el problema no esta resuelto completamente y son muchos los matemÃ¡ticos que trabajan
en nuevos esquemas, aceleraciÃ³n de convergencia etc. En esta secciÃ³n se presenta un pequeÃ±o
resumen de algunos tÃ³picos relacionados con el tema tomando como base el desarrollo dado en
[4], [5], [11], [14], [21], [22], [44].

4.3

Crecimiento Fractal y el modelo D.L.A.

En la naturaleza se encuentran muchos objetos cuya forma podrÃ­a ser mejor descrita a travÃ©s de la
geometrÃ­a fractal, que por los mÃ©todos convencionales tales como lÃ­neas y curvas diferenciables de
la geometrÃ­a clÃ¡sica. La lÃ­nea costera es el ejemplo fÃ­sico mÃ¡s conocido, fue planteado por Richardson en el aÃ±o 1961 y retomado por Mandelbrot en 1967, quien reanimÃ³ el interÃ©s de cÃ³mo encontrar
con exactitud la longitud de una lÃ­nea costera, y ademÃ¡s seÃ±alÃ³ que dichas lÃ­neas eran un caso de
una clase mucho mÃ¡s grande de objetos, en los que la longitud en una dimensiÃ³n no tiene sentido
sino que podÃ­an ser caracterizadas por una dimensiÃ³n fractal mayor que uno pero menor que dos.
Lo mÃ¡s interesante de este problema es que los fractales nunca habÃ­an sido restringidos a problemas fÃ­sicos, ni por Mandelbrot. Al encontrar una evidencia empÃ­rica de la existencia de fractales
en la naturaleza es que se inicia la investigaciÃ³n para explicar como se forman estos objetos.
Dentro de estos objetos naturales tambiÃ©n se encuentran otros fractales, por ejemplo: movimiento
de burbujas de aire en aceite, crecimiento de algunos cristales, entorno de las nubes, bifurcaciones
de relÃ¡mpagos, plantas tales como helechos, y ciertos Ã¡rboles. Sin embargo, existen dificultades
para aplicar la matemÃ¡tica fractal a estos casos reales; un ejemplo fÃ­sico concreto fue tratar de estimar la dimensiÃ³n de conteo de lado Î´ para la lÃ­nea costera de BretaÃ±a, ver [11, p. 265] donde
las leyes de potencia consideradas se volvieron imprecisas cuando Î´ tendÃ­a a cero. AsÃ­ que no se
puede lograr en la realidad los aspectos teÃ³ricos estudiados en la secciÃ³n 3.6, pero tambiÃ©n en la
fÃ­sica clÃ¡sica se eliminan aspectos tal como la fricciÃ³n de algunos objetos, que en la realidad no es
posible. A pesar de estos problemas tÃ©cnicos, se ha utilizado la teorÃ­a de fractales â€œexactos" a los
fractales â€œaproximados" de la naturaleza y se ha trabajado desde tres frentes distintos: experimental, simulaciones computacionales y fÃ­sica teÃ³rica.
Los objetos fÃ­sicos son observados, medidos, y sus dimensiones son estimadas sobre un rango
apropiado de escalas. Por supuesto, para que una dimensiÃ³n tenga algÃºn significado, al repetir

68

APLICACIONES

un experimento se debe obtener el mismo valor. La dimensiÃ³n fractal de un objeto fÃ­sico es una
propiedad â€œuniversal", pues es independiente de los muchos detalles de cÃ³mo Ã©ste se forma. Algo
mÃ¡s satisfactorio serÃ­a que las propiedades fractales puedan ser explicadas en tÃ©rminos fÃ­sicos, lo
que requiere alguna clase de mecanismos que expliquen estos fenÃ³menos naturales. Es aquÃ­ donde
las simulaciones computacionales nos permiten evaluar varios modelos y comparar algunas de
sus caracterÃ­sticas, tales como dimensiÃ³n de la simulaciÃ³n contra la dimensiÃ³n real. A menudo se
han obtenido valores para la dimensiÃ³n, ya sean experimentales, simulados, o bien teÃ³ricos que
resultan sorprendentemente parecidos.

4.3.1 Procesos de crecimiento fractal.
Se ha mencionado que muchos objetos naturales crecen en una forma aparentemente fractal, con
ramas repetidamente dividiÃ©ndose en otras mÃ¡s pequeÃ±as a sus lados, ver Figura 4.11. Las descargas elÃ©ctricas tambiÃ©n presentan esta forma fractal rameada. Otro trabajo de gran importancia,
vÃ©ase [8, p. 43], es tratar la estructura espacial de las ciudades involucrando la idea de autosemejanza, ya que la morfologÃ­a de algunas ciudades produce una extraÃ±a semejanza con â€œclusters" de
dendritas. Los procesos fractales pueden generar clusters en dos dimensiones que son altamente
ordenados, por lo que sugieren que los mÃ©todos y modelos de tales procesos puedan constituir
analogÃ­as Ãºtiles para estudiar el crecimiento urbanÃ­stico. Estos procesos generan clusters que estÃ¡n
lejos del equilibrio, con un crecimiento irreversible y con forma de Ã¡rbol: dendritas con autosemejanza en sus ramas. TambiÃ©n se ha investigado, durante largo tiempo, sobre la agregaciÃ³n de
partÃ­culas que forman grandes clusters en la ciencia de materiales y en inmunologÃ­a.
Es por todo esto que se desarrollan algunos modelos para simular el crecimiento fractal, entre los
que se encuentran algunos probabilÃ­sticos y otros determinÃ­sticos. Entre estos modelos se puede
citar por ejemplo el de AgregaciÃ³n de DifusiÃ³n Limitada conocido por sus siglas en InglÃ©s como
D.L.A. y el D.B.M. (Dielectric Breakdown Model). Se va a estudiar Ãºnicamente el D.L.A., que es un
modelo simple de una partÃ­cula de difusiÃ³n cuya conducta podrÃ­a ser simulada por un camino al
azar sobre un retÃ­culo en dos dimensiones. Este modelo estÃ¡ basado en la agregaciÃ³n de partÃ­culas,
una a la vez, cuya difusiÃ³n es limitada a un campo fijo de influencia alrededor del cluster en crecimiento y por el hecho de que si una partÃ­cula llega al cluster, Ã©sta se adhiere permanentemente.
El modelo D.L.A. es parte de una clase de procesos que estÃ¡n basados en el crecimiento gobernado por el gradiente y se puede mostrar que la dimensiÃ³n fractal y otras propiedades pueden ser
medidas y estimadas, se presenta con mÃ¡s detalles a continuaciÃ³n.
El modelo D.L.A.. En 1981, Thomas A. Witten y Leonard M. Sander en [52, 53], sugirieron un modelo estocÃ¡stico elemental. Este utiliza los principios bÃ¡sicos de difusiÃ³n y agregaciÃ³n, produciendo
una convincente simulaciÃ³n del crecimiento. El nombre de â€œDiffusion Limited Aggregation" fue
dado por Witten y Sander debido a que la agregaciÃ³n de las partÃ­culas se da por medio de caminos
al azar.
Este modelo, Figura 4.14, estÃ¡ basado en un retÃ­culo dos-dimensional. Un cuadrado inicial es sombreado, y llamado semilla, y un cÃ­rculo de radio RmÃ¡x es dibujado centrado en esta semilla. Luego,
es escogido un punto al azar en otra circunferencia de radio menor, R, que realizarÃ¡ un movimiento
Browniano (camino al azar) hasta que este punto o bien abandone el cÃ­rculo de radio RmÃ¡x (como
el punto S2 ) y es por lo tanto desechado, o alcance un cuadrado adyacente al cluster actual, en cuyo
caso este cuadro es tambiÃ©n sombreado; es decir se adhiere al cluster (como el punto S1 ). Cuando
este proceso es repetido un gran nÃºmero de veces, forma un conjunto conectado de cuadrados que
crece hacia afuera hasta alcanzar un cierto tamaÃ±o o que cruce un cierto umbral, con un radio de
R âˆ’ M donde M es una constante positiva.

69

Figura 4.14

Modelo D.L.A. en dos dimensiones.

Es computacionalmente mÃ¡s conveniente permitir que el punto siga un camino al azar, asÃ­, cada
vez que Ã©ste se mueve lo hace con probabilidad de 1/4 (izquierda, derecha, arriba, abajo). El proceso parece favorecer una forma compacta de crecimiento, pero no es asÃ­, pues inicialmente cada
uno de los sitios adyacentes la semilla tienen una misma probabilidad de ser ocupado, pero una
vez que el primer sitio es escogido los sitios adyacentes a estos dos tienen una probabilidad ligeramente mÃ¡s alta de ser ocupados. Cuando el proceso de crecimiento continÃºa, los clusters se
expanden en dendritas, donde los sitios adyacentes a las puntas tienen una mayor probabilidad
de ser elegidos que aquellos sitios localizados en los huecos interiores o cavernas, algo semejante
a lo que sucede en el crecimiento de los Ã¡rboles. Este modelo presenta las ventajas de ser conceptualmente simple y fÃ¡cilmente programable. Lo mÃ¡s importante es que Ã©ste parece explicar el
crecimiento de algunos fractales de la naturaleza.
Este modelo produce clusters dendrÃ­ticos, extremadamente ricos y complejos pero sin embargo
altamente ordenados, por lo que sugieren que los mÃ©todos y modelos de tales procesos puedan
constituir analogÃ­as Ãºtiles para estudiar el crecimiento urbanÃ­stico. Este modelo parece explicar el
crecimiento de algunos fractales de la naturaleza, asÃ­ para Sander, ver [49], lo mÃ¡s importante de
este modelo es que muestra la relaciÃ³n que existe entre fractales y crecimiento. Es un proceso de
agregaciÃ³n pues cada partÃ­cula, una a la vez, se adhiere permanentemente y no se dan reacomodos
de las partÃ­culas, por lo que es un ejemplo extremo de un proceso de no equilibrio.
Uno de los hallazgos mÃ¡s sorprendentes es que la dimensiÃ³n fractal D, de la mayorÃ­a de las simulaciones computacionales, es aproximadamente igual a 1.71 Â± 0.02 para retÃ­culos de 1000 Ã— 1000
en adelante. AdemÃ¡s, Meakin revelÃ³ que la dimensiÃ³n podrÃ­a depender del tamaÃ±o del retÃ­culo, y
del nÃºmero de partÃ­culas que crezcan en el cluster, asÃ­, para simulaciones de mÃ¡s de un millÃ³n de
partÃ­culas, notÃ³ que su dimensiÃ³n podrÃ­a tender a la unidad, cuando el sistema crece en forma de
cruz y estÃ¡ basado en cuatro dendrÃ­tas todos ellos dominantes. El fÃ­sica teÃ³rico, Muthukuman, en
d2 + 1
[42], utilizando la TeorÃ­a de Campos formulÃ³ que D =
, donde d es la dimensiÃ³n euclÃ­dea
d+1
del espacio. AdemÃ¡s ha existido mucho trabajo para extender las simulaciones a tres o mÃ¡s dimensiones. AsÃ­ por ejemplo, en [33, 34] se ha llegado a obtener una dimensiÃ³n fractal de 2.49 para el
caso de tres dimensiones.

70

APLICACIONES

4.3.2 Simulaciones de algunos procesos de crecimiento.
Simulaciones computacionales usando D.L.A.. A pesar de que la ejecuciÃ³n del algoritmo del
D.L.A. es bastante directa, la cantidad de tiempo computacional requerido es dependiente del
tamaÃ±o del retÃ­culo y del nÃºmero de partÃ­culas simuladas. La mayorÃ­a de las simulaciones desarrolladas en los 80â€™s, producidas por Meakin, requirieron de supercomputadoras y procesadores
paralelos, y los sistemas reales a los que estas simulaciones pueden ser comparados requieren casi
siempre una alta resoluciÃ³n. AdemÃ¡s, en [8] se trabaja con simulaciones de D.L.A. sobre un retÃ­culo
de 500 Ã— 500 y con 10.000 partÃ­culas; y la forma del cluster resultante se compara con la forma urbana del pequeÃ±o pueblo inglÃ©s de Taunton, donde la dimensiÃ³n fractal D = 1.652 de esta simulaciÃ³n fue estimada usando un anÃ¡lisis de correlaciÃ³n en dos puntos. Por otro lado la dimensiÃ³n de
Taunton fue de 1.636, donde los detalles tÃ©cnicos son dados por Batty, Longley y Fotheringhen.

Figura 4.15

SimulaciÃ³n usando D.L.A. sobre un retÃ­culo 321 Ã— 321 con 1504 partÃ­culas.

Figura 4.16

SimulaciÃ³n usando D.L.A. sobre un retÃ­culo 321 Ã— 321 con 2020 partÃ­culas.

En este trabajo, el modelo D.L.A. fue programado usando cuadrados en lugar de circunferencias
con el fin de simplificar las coordenadas del punto que se escoge al azar. AdemÃ¡s, para la distancia se usa la norma mÃ¡xima, es decir |( x, y) âˆ’ (z, w)| = mÃ¡x{| x âˆ’ z|, |y âˆ’ w|}. Se hicieron dos
programas para generar estas simulaciones. En el primero de ellos (A.1.5), la partÃ­cula sigue un
camino Browniano, donde se permite dar pasos de tamaÃ±o k = 5, 4, 3, 2, 1, dependiendo de Dist,
la distancia mÃ¡xima del cluster a la semilla, en cada avance se analiza un cuadrado de tamaÃ±o

71

2k + 1 Ã— 2k + 1. Esto es mÃ¡s rÃ¡pido que cuando se avanza una Ãºnica unidad, pero aÃºn asÃ­ es demasiado lento para generar el cluster final, tardando 8 a 10 horas para generar Ãºnicamente 500
partÃ­culas. Las figuras 4.15 y 4.16 han sido simuladas usando el programa A.1.6, que se acelera
tomando el punto inicial en un cuadrado a una distancia Dist+ N, donde el nÃºmero N es un entero
positivo, en dichas figuras se usÃ³ N = 8 y N = 7 respectivamente. El proceso ha sido simulado
sobre un retÃ­culo 321 Ã— 321, y donde Rmax = 160; R = 140; y el nÃºmero de partÃ­culas es de 1504 y
2020 respectivamente. AdemÃ¡s, el tiempo de corrida fue de 5 a 6 horas en ambos casos.
El modelo D.L.A ha sido usado en una gama de sistemas fÃ­sicos que emplean la difusiÃ³n de
partÃ­culas de alguna fuente y ha simulado crecimientos fÃ­sicos tales como cristalizaciÃ³n, electrodeposiciÃ³n, dedos viscozos y algunas formas de percolaciÃ³n. En la mayorÃ­a de las simulaciones
hechas usando D.L.A., primero se nota que hay autosemejanza en sus ramas a travÃ©s de varias
escalas. Segundo, a pesar de que el nÃºmero acumulativo de partÃ­culas crece cuando Dist crece, Ã©ste
no lo hace tan rÃ¡pido en el Ã¡rea que contiene al cluster. En resumen, la densidad del cluster baja
cuando esta distancia llega a ser mÃ¡s grande. El nÃºmero de partÃ­culas, denotado por N (r ), a una
distancia r de la semilla estÃ¡ dado por
N (r ) = Gr D

(4.15)

Ï(r ) = Zr D âˆ’2

(4.16)

y las escalas de densidad como

donde G y Z son constantes de proporcionalidad y D la dimensiÃ³n fractal, con 1 < D < 2.
Simulaciones experimentales.. Falconer en [11] expone el experimento de la electrÃ³lisis de la
soluciÃ³n de sulfato de cobre, donde el depÃ³sito de cobre que se forma crece siguiendo un patrÃ³n
fractal. Se va a describir otro experimento similar al anterior, presentado por Mitsugu Matsushita y
cuya descripciÃ³n estÃ¡ en [44, p. 475]. Este trata de una deposiciÃ³n electroquÃ­mica de hojas del metal
de zinc que lleva al resultado de una estructura dendrÃ­tica y presenta la ventaja de que el equipo y
las sustancias quÃ­micas a utilizar son fÃ¡ciles de conseguir y no es peligroso, siempre que se tengan
las prevenciones del caso. La modelaciÃ³n matemÃ¡tica esta deposiciÃ³n estÃ¡ fundamentada sobre el
concepto de movimiento Browniano, que se trata del movimiento aleatorio de algunas pequeÃ±as
partÃ­culas de materia sÃ³lida suspendida en un lÃ­quido. AsÃ­ por ejemplo, Robert M. Brady y Robin
C. Ball de la Universidad de Cambridge, indicaron en 1984 que el modelo D.L.A. es una razonable
idealizaciÃ³n del depÃ³sito de zinc que se forma en el experimento mencionado. Los materiales que
se utilizan son: una fuente de poder, una caja petri (15 cm de diÃ¡metro, y 2.5 cm de profundidad),
sulfato de zinc (ZnSO4 ), acetato de tilo (CH3 COO(CH2 )3 CH3 ), una mina de carbÃ³n de 0.5 mm,
un aro plano de metal de zinc (1 cm de ancho y 15 cm de diÃ¡metro), una prensa. Se prepara una
disoluciÃ³n acuosa de sulfato de zinc: 2 moles de ZnSO4 , que se deposita en la caja junto con el
acetato, este Ãºltimo al no ser soluble con sulfato forma una capa que hace la interfaz (frontera
entre ambos lÃ­quidos), luego se coloca una mina de modo que quede perpendicular al centro de
la caja y que coincida con la interfaz si se quiere generar una estructura en dos dimensiones o se
sumerge en el sulfato de zinc para obtener una estructura tridimensional. Posteriormente se aplica
una corriente directa de 5 voltios, donde la mina se toma como el cÃ¡todo (âˆ’) y el aro colocado
dentro de la caja como el Ã¡nodo (+), rÃ¡pidamente comienzan a agragarse partÃ­culas a la punta de la
mina y despuÃ©s de aproximadamente 25 minutos se genera una figura tridimensional. Para poder
describir mejor el experimento se realizÃ³ un vÃ­deo que puede ser presentado en una exposiciÃ³n.
Lo impresionante de este proceso es la semejanza que guardan estas estructuras, en el caso dos
dimensional, con los clusters generados por computadora, ver Figuras 4.15 y 4.16.

72

APLICACIONES

4.3.3 Estimando la dimensiÃ³n fractal.
EstimaciÃ³n de la dimensiÃ³n de simulaciones usando D.L.A..
que la funciÃ³n de correlaciÃ³n de densidad es la siguiente,

En [52], Witten y Sander mostraron

C ( r ) = N âˆ’1 âˆ‘ Ï ( r â€² ) Ï ( r + r â€² )

(4.17)

râ€²

que fue obtenida de simulaciones en dos dimensiones, y se asume que depende Ãºnicamente de la
distancia r que separa los dos sitios. Luego, esta funciÃ³n es ajustada a una ley de potencia,
C (r ) â‰ˆ r âˆ’ Î±

(4.18)

para r mayor que el espaciado del retÃ­culo, pero mucho menor que el tamaÃ±o del cluster. En (4.17) la
densidad Ï(r ) se define como 1 si el sitio estÃ¡ ocupado y 0 en caso contrario. Donde N representa el
nÃºmero de partÃ­culas contenidas en el cluster. Por otro lado la ley de potencia (4.18) es consistente
con la dimensiÃ³n de Hausdorff-Besicovitch, DÎ± = d âˆ’ Î±, donde d es la dimensiÃ³n euclÃ­dea del
cluster. La dimensiÃ³n Hausdorff puede obtenerse tambiÃ©n usando el radio de rotaciÃ³n, R g , pues se
tiene una ley de potencia dependiente del nÃºmero de partÃ­culas N, R g = N Î² y la dimensiÃ³n fractal
asociada, ver [34], estÃ¡ dada por
DÎ² =

1
Î²

(4.19)

3
En [52] se utiliza una cierta curva de Koch, con dimensiÃ³n Hausdorff D = ln
ln 2 â‰ˆ 1.583, para
verificar la validez de la funciÃ³n C (r ). El cÃ¡lculo de C (r ), se hizo sobre un promedio de siete curvas
y se obtuvo Î± = 0.416, y por lo tanto DÎ± = 1.584, un valor muy cercano a D. En [33], se muestran
algunos resultados que junto con otros expuestos en [52] que se resumen en la siguiente tabla,

Modelo utilizado
D.L.A. con espaciado
5 â‰¤ s â‰¤ 50 promediado ,
sobre 6 cluster 9700 puntos.
D.L.A. original, promediado
sobre 3 cluster, 16300 pts.
D.L.A. sobre retÃ­culo
triangular promediado sobre,
3 cluster, 1500 a 2997 pts.

Î²
0.595 Â± 0.016

Î±
0.32 Â± 0.07

DÎ²
1.68 Â± 0.04

DÎ±
1.68 Â± 0.07

0.579 Â± 0.045

0.292 Â± 0.055

1.73 Â± 0.13

1.71 Â± 0.55

0.37 Â± 0.01

1.673 Â± 0.01

Tabla 4.4 EstimaciÃ³n de DÎ± y DÎ² para algunas simulaciones.

EstimaciÃ³n de la dimensiÃ³n de simulaciones experimentales.. En el depÃ³sito de metal de zinc
por ejemplo se obtuvo una dimensiÃ³n de 1.7, lo que concuerda con la medida de la dimensiÃ³n
del fractal generado en la computadora, ver [49], que fue de 1.71, y se usÃ³ un nÃºmero de 50.000
partÃ­culas mientras que la cantidad de Ã¡tomos en el depÃ³sito es enorme, casi un billÃ³n. En el caso
de la morfologÃ­a de las ciudades, la dimensiÃ³n es estimada de las relaciones de la distancia entre
las partÃ­culas dadas por las ecuaciones (4.15) y (4.16). En general, Ã©stas muestran que el nÃºmero de
partÃ­culas N (r ) en una distancia r mide como r D y la densidad mide como r D âˆ’2 . TambiÃ©n existen
otras relaciones que pueden ser estimadas para dar la dimensiÃ³n fractal, como el conteo de las
ramas basado en dN (r )/dr, propuesta por Pietronero, Evertz y Wiesmann [45].
Estas relaciones pueden ser estimadas de dos modos. Primero, N (r ) puede ser calculado con respecto a la distancia r desde la semilla. Esto da una medida de la poblaciÃ³n en una distancia, lo

73

que ha sido usado para describir la morfologÃ­a de las ciudades en los estudios urbanÃ­sticos, donde
la densidad Ï(r ) es calculada estadÃ­sticamente sobre las variables relacionadas. Segundo, las funciones de correlaciÃ³n en dos puntos pueden ser calculadas si N (r ) es calculado respecto a cualquier
sitio ocupado en el cluster y luego promediados. Hay dos principales problemas con el uso de estas estadÃ­sticas. Primero, hay graves problemas de frontera en las relaciones entre la distancia y
la poblaciÃ³n. Alrededor de la frontera del cluster crecido, mÃ¡s y mÃ¡s sitios que podrÃ­an ser desarrollados no lo son pues el cluster estÃ¡ todavÃ­a creciendo; esto hace que la dimensiÃ³n fractal baje.
Es necesario excluir una gran Ã¡rea de esta zona en crecimiento a la hora de hacer los cÃ¡lculos. Segundo, hay tambiÃ©n efectos volÃ¡tiles en distancias cortas de los puntos alrededor de los que estas
relaciones son formadas, y estos tambiÃ©n deben de ser excluidos. Debido a la arbitrariedad de estas
zonas que se eliminan, la dimensiÃ³n fractal puede variar bastante en un mismo cluster.
Para algunas simulaciones del D.L.A. hechas en [8], el valor de la dimensiÃ³n estadÃ­stica, D, para las
relaciones funcionales en un punto variÃ³ de 1.174 a 1.686 para el cluster completo, y de 1.659 a 1.739
para el cluster excluyendo los pequeÃ±os y grandes efectos de frontera. Para las relaciones en dos
puntos, D variÃ³ de 0.161 a 1.136 para el cluster original, con un rango mucho mÃ¡s limitado de 1.640
a 1.677 para el cluster modificado para eliminar los efectos de frontera. El mejor estimado de la dimensiÃ³n fractal de este cluster fue de 1.652, basado en un ajuste perfectamente cercano (r2 = 0.999)
de la ecuaciÃ³n (4.15). Si se toma en cuenta que cada simulaciÃ³n producirÃ¡ un Ãºnico y diferente
cluster, se puede estimar mejor la dimensiÃ³n, promediando sobre varias corridas. AdemÃ¡s, el cÃ¡lculo de las correlaciones de dos puntos toman una cantidad sustancial de tiempo computacional.
Combinado con la volatividad de los efectos de frontera, y la dificultad de identificar estos en una
forma no ambigua, junto con la necesidad de promediar dimensiones sobre varias corridas, esto
los condujo a desarrollar un mucho mÃ¡s rÃ¡pido y por lo tanto mÃ¡s fuerte mÃ©todo de estimaciÃ³n.
Notando que el retÃ­culo es cuadrado y que el nÃºmero de partÃ­culas a una distancia r de la semilla
puede ser aproximado por Ï€r D . El Ã¡rea asociada con esta poblaciÃ³n es tambiÃ©n aproximadamente
igual al Ã¡rea del cÃ­rculo de radio r, es decir Ï€r2 , y que su razÃ³n da la densidad.
Ï (r ) =

Ï€r D
= r D âˆ’2
Ï€r2

(4.20)

Para un valor dado de r, el valor de la dimensiÃ³n fractal en ese punto, D (r ), puede ser calculado
de la ecuaciÃ³n (4.20),
D (r ) = 2 +

log Ï(r )
log(r )

(4.21)

Por Ãºltimo, en el experimento de electrodeposiciÃ³n, el modelo D.L.A. se puede considerar como
una representaciÃ³n de una sucesiÃ³n de iones que son liberados desde una distancia determinada,
uno despuÃ©s del otro. AdemÃ¡s de modelar el depÃ³sito, esta simulaciÃ³n tambiÃ©n da una idea del
crecimiento del cluster con respecto al tiempo. Este crecimiento depende de una gran cantidad
de iones que se mueven aleatoria y simultÃ¡neamente hasta adherirse al cluster. Por lo tanto esto
sugiere que se puede tratar el crecimiento en una forma continua, donde se supone que para una
gran cantidad de iones se cumple que u( x, t) es la densidad en un punto x y un tiempo t. Luego,
el nÃºmero de iones en un disco de radio Î´x es u( x, t)Î´x, y asumiendo que los iones siguen caminos
Brownianos independientes, entonces los iones que estÃ¡n en este disco en un tiempo t hacen que
la densidad en el tiempo t + h estÃ© dada por la distribuciÃ³n normal bidimensional6
Î´u( x â€² , t + h) =
6 En

1 âˆ’ ( x âˆ’ x â€² )2
2h
e
u( x, t)Î´x,
2Ï€h

[44] se hace simulaciones en el caso de una dimensiÃ³n

74

APLICACIONES

asÃ­ que, integrando a travÃ©s de la regiÃ³n del fluido se obtiene:
u( x â€² , t + h ) =

1
2Ï€h

Z

eâˆ’

( x âˆ’ x â€² )2
2h

u( x, t)dx,

luego derivando bajo el signo intregral con respecto a x â€² y h se tiene
âˆ‚u
1
= âˆ‡2 u
(4.22)
âˆ‚t
2
Ã©sta es la ecuaciÃ³n del calor en dos dimensiones. Las condiciones de frontera que se requieren son
las siguientes, la primera sobre la frontera exterior
u = u0

con | x | = r0

(4.23)

sobre Ft

(4.24)

y la segunda sobre Ft que representa la frontera del depÃ³sito en un instante t, y donde los iones
que se encuentran muy cerca de Ft pierden virtualmente su carga, entonces se tiene que
u=0

y dado que los iones descargados son depositados en el metal de zinc, el porcentaje de avance v de
la frontera Ft debe ser igual a la derivada de la concentraciÃ³n en la direcciÃ³n normal N a Ft , la cual
es igual a
vn = kN Â· âˆ‡u

sobre Ft

(4.25)

Como este crecimiente se mantiene lejos del electrodo exterior, el porcentaje de difusiÃ³n para una
buena aproximaciÃ³n es independiente del tiempo, por lo que la ecuaciÃ³n (4.22) puede ser sustituida
por la ecuaciÃ³n de Laplace

âˆ‡2 u = 0

(4.26)

y resolviendo esta con las condiciones de frontera (4.23), (4.24) se puede encontrar el porcentaje de
crecimiento del depÃ³sito, claro que se debe utilizar la condiciÃ³n (4.25)
4.3.4 Conclusiones
Al concluir este trabajo, nos queda muy claro la estrecha relaciÃ³n que existe entre los fractales â€œexactos" y los fractales â€œaproximados" de la naturaleza. Algunos de los procesos de crecimiento que se
presentan en la naturaleza pueden ser simulados usando modelos computacionales. Uno de ellos
es el modelo D.L.A., que a pesar de ser tan sencillo, ha sido muy aprovechado en algunas Ciencias
de Materiales, InmunologÃ­a; para simular procesos tales como cristalizaciÃ³n, electrodeposiciÃ³n, asÃ­,
como para desarrollar algunos modelos urbanÃ­sticos. AdemÃ¡s, es importante destacar el gran esfuerzo que se ha realizado, para llevar a la prÃ¡ctica todos los aspectos teÃ³ricos necesarios, para
encontrar la dimensiÃ³n fractal de simulaciones computacionales y de algunas simulaciones experimentales. En los estudios realizados sobre dimensionÌ fractal de estos dos tipos de simulaciones,
se revela un sorprendente resultado, una dimensiÃ³n fractal de 1.71 en ambos casos. Lo anterior es
inesperado debido a que las simulaciones computacionales cuentan con un nÃºmero de partÃ­culas
o puntos mucho menor que el nÃºmero de partÃ­culas de las simulaciones experimentales.
Las simulaciones computacionales del modelo D.L.A. se llevaron a cabo utilizando el paquete computacional Mathematica para aprovechar se resoluciÃ³n grÃ¡fica. A pesar de que el algoritmo es sencillo, el tiempo computacional requerido es mucho para el modelo original, por lo que hubo que
acelar el proceso. Se realizaron dos programas, A.1.6 y A.1.5, y con ellos se realizaron algunas simulaciones dentro de las cuales se eligieron 4.15 y 4.16. Por otro lado, se realizÃ³ el experimento de
electrodeposiciÃ³n del metal de zinc, donde las simulaciones experimentales en dos dimensiones,
nos muestran la aparente analogÃ­a con las simulaciones computacionales generadas con el D.L.A.,
no solo en forma sino que tambiÃ©n en dimensiÃ³n.

ApÃ©ndice A
Programas

Algunos de los programas computacionales que se han utilizado.

A.1

Mathematica

1. b=2-I;
Norbcuad=5; (*norma de b cuadrado*)
k=7;
(*Dig[i] representan los digitos que se usan*)
Dig[0]=0;
Dig[1]=1;
Dig[2]=2;
Dig[3]=3;
Dig[4]=4;
K=Table[0,{i,1,k}];
z=Table[0+0I,{i,1,Norbcuad\^\,k}];
For[i=0, i<Norbcuad\^\,k, i++,
Aux=i;
Do[K[[j]]=Dig[Mod[Aux,Norbcuad]];
Aux=Quotient[Aux,Norbcuad],{j,k}];
z[[i]]=Sum[K[[j]]*Power[b,-j],{j,1,k}];];
ListPlot[Table[{Re[z[[i]]],Im[z[[i]]]},
{i,0,Norbcuad\^\,k-1}],
Axes->True,AspectRatio->1/1,
Prolog->AbsolutePointSize[2]]
2. b=1.3; n:=29;azul= 3/5; verde =2/5; amarillo = 4/25;
rojo=0;maxitera=75; Co="C";De="D";
X=Table[0,{i,0,maxitera}];
Gen=Table["C",{i,1,n},{j,1,n}];
Gen1=Table["C",{i,1,n-4},{j,1,n-4}];
Esc=Table["C",{i,1,5},{j,1,5}];
Scor=Table[0,{i,1,3},{j,1,3}];
Color=Table[1,{i,1,n-4},{j,1,n-4}];
P[x_,y_]:=If[x==Co&&y==Co,1,If[x==De && y==Co,b,0]];
Ganador="C";mayor= 0;
Gen=Table[If[Random[Integer,{1,10}]>9,"D","C"],
*

Fractales.. M. Alfaro, M. Murillo, A. Soto.
c 2010 Revista digital MatemÃ¡tica, EducaciÃ³n e Internet (www.cidse.itcr.ac.cr/revistamate/)
Derechos Reservados 

75

76

PROGRAMAS

{i,1,n},{j,1,n}];
coop=0;dela=0;
For[i=3,i<n-1,i++,
For[j=3,j<n-1,j++,
If[Gen[[i,j]]=="C",coop=coop+1,dela=dela+1]
]];
X[[0]]=coop/(n-4)^2;h=1;
Do[
Gen[[2]]=Gen[[n-2]];
Gen[[1]]=Gen[[n-3]];
Gen[[n-1]]=Gen[[3]];
Gen[[n]]=Gen[[4]];
For[i=1,i<n+1,i++,Gen[[i,2]]=Gen[[i,n-2]]];
For[i=1,i<n+1,i++,Gen[[i,1]]=Gen[[i,n-3]]];
For[i=1,i<n+1,i++,Gen[[i,n-1]]=Gen[[i,3]]];
For[i=1,i<n+1,i++,Gen[[i,n]]=Gen[[i,4]]];
For[i=3,i<n-1,i++,
For[j=3,j<n-1,j++,
Esc=Table[Gen[[i+k-3,j+l-3]],{k,1,5},{l,1,5}];
For[p=2,p<5,p++,
For[q=2,q<5,q++,
Scor[[p-1,q-1]]=Sum[P[Esc[[p,q]],
Esc[[p+s-2,q+t-2]]],{s,1,3},{t,1,3}]
]];
Ganador=Esc[[3,3]];mayor=-2;
For[p=2,p<5,p++,
For[q=2,q<5,q++,
If[Scor[[p-1,q-1]]>mayor, Ganador=Esc[[p,q]];
mayor= Scor[[p-1,q-1]]];
]];
If[Gen[[i,j]]=="D",If[Ganador=="C",coop=coop+1],
If[Ganador=="D",coop=coop-1]];
If[h==maxitera,
If[Gen[[i,j]]=="C",
If[Ganador=="C",Color[[i-2,j-2]]=azul,
Color[[i-2,j-2]]=verde],
If[Ganador=="D",Color[[i-2,j-2]]=rojo,
Color[[i-2,j-2]]=amarillo]]];
Gen1[[i-2,j-2]]=Ganador;
]];
X[[h]]=coop/(n-4)^2;Print[h,N[X[[h]]]];
h=h+1;
For[i=3,i<n-1,i++,
For[j=3,j<n-1,j++,Gen[[i,j]]=Gen1[[i-2,j-2]]
]],{maxitera}];
Show[Graphics[Raster[Color,{{0,0},{1,1}},
ColorFunction->Hue]]];
ListPlot[Table[X[[i]],{i,0,75}],
PlotJoined->True, PlotRange->{0,1}]

PROGRAMAS

3. A=Table[1,{i,1,2},{j,1,2}];
A[[1,1]]=.849; A[[1,2]]=-.037; A[[2,1]]=.037;
A[[2,2]]=.849;
B=Table[1,{i,1,2},{j,1,2}];
B[[1,1]]=0.197; B[[1,2]]=0.226; B[[2,1]]=-0.226;
B[[2,2]]=0.197;
Ci=Table[1,{i,1,2},{j,1,2}];
Ci[[1,1]]=-.15; Ci[[1,2]]=.26; Ci[[2,1]]=.283;
Ci[[2,2]]=.237;
Da=Table[1,{i,1,2},{j,1,2}];
Da[[1,1]]=0;Da[[1,2]]=0;Da[[2,1]]=0;Da[[2,2]]=.16;
F1[{x_,y_}]={x,y}.A+{.075,.183};
F2[{x_,y_}]={x,y}.B+{0.4,.049};
F3[{x_,y_}]={x,y}.Ci+{.575,-.084};
F4[{x_,y_}]={x,y}.Da+{.5,0};k=6;
X=Table[{0,0},{i,1,4^(k+1)}];
X[[1]]=F1[{0,0.5}];
X[[2]]=F2[{0,0.5}];
X[[3]]=F3[{0,0.5}];
X[[4]]=F4[{0,0.5}];
i=4; j=5;
While[j< 4^(k+1)+1,
X[[j]]=F1[X[[Floor[j/4]+1]]];
X[[j+1]]=F2[X[[Floor[j/4]+1]]];
X[[j+2]]=F3[X[[Floor[j/4]+1]]];
X[[j+3]]=F4[X[[Floor[j/4]+1]]];
j=j+4]; ListPlot[X,
Axes->False,AspectRatio->2/1,
Prolog->AbsolutePointSize[1]]
4. A=Table[1,{i,1,2},{j,1,2}];
A[[1,1]]=.849;A[[1,2]]=-.037;A[[2,1]]=.037;
A[[2,2]]=.849;
B=Table[1,{i,1,2},{j,1,2}];
B[[1,1]]=0.197;B[[1,2]]=0.226;B[[2,1]]=-0.226;
B[[2,2]]=0.197;
Ci=Table[1,{i,1,2},{j,1,2}];
Ci[[1,1]]=-.15;Ci[[1,2]]=.26;Ci[[2,1]]=.283;
Ci[[2,2]]=.237;
Da=Table[1,{i,1,2},{j,1,2}];
Da[[1,1]]=0;Da[[1,2]]=0;Da[[2,1]]=0;Da[[2,2]]=.16;
F1[{x_,y_}]={x,y}.A+{.075,.183};
F2[{x_,y_}]={x,y}.B+{0.4,.049};
F3[{x_,y_}]={x,y}.Ci+{.575,-.084};
F4[{x_,y_}]={x,y}.Da+{.5,0};
k=13000; (*Numero de puntos que plotea*)
X=Table[{0,0},{i,1,k}];
X[[1]]=F1[{.5,0.2}];
i=4; j=2;

77

78

PROGRAMAS

While[j< k+1, RAN=Random[Integer,{0,100}];
If
(*Los p_i son las probabilidades en el RIFS*)
[RAN<p_1,
X[[j]]=F1[X[[j-1]]],
If[RAN<p_2,
X[[j]]=F2[X[[j-1]]],
If[RAN<p_3,
X[[j]]=F3[X[[j-1]]],
X[[j]]=F4[X[[j-1]]]]]
];
j=j+1;
If[Mod[j-1,k/4]==0,X[[1]]=F1[{.5,0.2}]]
];
ListPlot[X,
Axes->False,AspectRatio->2/1,Prolog->
AbsolutePointSize[1]]
5. Rmax=120; R=100;
A=Table[0,{i,1,2Rmax+1},{j,1,2Rmax+1}];
Np=2000;conta=1;Dist=0;
A[[Rmax+1,Rmax+1]]=1/2;
M=(Rmax-R)/4;
Norm[{a_,b_},{c_,d_}]=Max[Abs[a-c],Abs[b-d]];
While[conta < Np&&Dist<=R-M,
If [Random[Integer,1]==0,
x=Random[Integer,{Rmax-R,Rmax+R}];
If[Abs[x-Rmax]==R,y=Rmax+1,
y=If[Random[Integer,1]==0, Rmax-R, Rmax+R ],],
y=Random[Integer,{Rmax-R,Rmax+R}];
If[Abs[y-Rmax]==R, x=Rmax+1,
x=If[Random[Integer,1]==0,Rmax-R, Rmax+R ] ]];
While[Norm[{x,y},{Rmax+1,Rmax+1}]<=Rmax-M,
If[Dist>=0&&Dist<=R/5, k=5,
If[Dist>R/5&&Dist<=R/4, k=4,
If[Dist>R/4&&Dist<=R/3, k=3,
If[Dist>R/3&&Dist<=R/2, k=2,
If[Dist>R/2&&Dist<=R,k=1,]]]]];
suma=Sum[A[[x+i,y+j]],{i,-k,k},{j,-k,k}];
If[suma==0,
p=Random[Integer,3];If[p==0,x=x+k,
If[p==1,x=x-k,If[p==2,y=y+k,y=y-k]]],
If[suma>0, z=x;w=y;
While[A[[z,w]]==0, s=z;t=w;
p=Random[Integer,3];
If[p==0,z=z+1,If[p==1,z=z-1,If[p==2,w=w+1,w=w-1]]];
While[Norm[{z,w},{x,y}]>k, z=s;w=t]; ];];
A[[s,t]]=1/2;Print[s,t];Print[conta];conta=conta+1;
If[Dist<Norm[{x,y},
{Rmax+1,Rmax+1}],Dist=Dist+1 ];Break[];];

PROGRAMAS

]; ];
Show[Graphics
[Raster[A,{{0,0},{1,1}},ColorFunction->Hue]]];
6. Rmax=160; R=140;
A=Table[0,{i,1,2Rmax+1},{j,1,2Rmax+1}];
Np=3000;conta=1;
Dist=0;A[[Rmax+1,Rmax+1]]=1/2;
While[conta < Np&&Dist<=R-8,
If [Random[Integer,1]==0,
x=Random[Integer,{Rmax-(Dist+8),Rmax+Dist+8}];
If[Abs[x-Rmax]==Dist+8,y=Rmax+1,
y=If[Random[Integer,1]==0,
Rmax-(Dist+8), Rmax+Dist+8 ],],
y=Random[Integer,{Rmax-(Dist+8),Rmax+Dist+8}];
If[Abs[y-Rmax]==Dist+8,x=Rmax+1,
x=If[Random[Integer,1]==0, Rmax-(Dist+8),
Rmax+Dist+8 ]]];
While[conta < Np&&Max[Abs[Rmax+1-x],
Abs[Rmax+1-y]]<=Dist+15,
If[Sum[A[[x+i,y+j]],{i,-1,1},{j,-1,1}]>0&&A[[x,y]]==0,
A[[x,y]]=1/2;Print[x,y];Print[conta];conta=conta+1;
If[Dist<Max[Abs[Rmax+1-x],Abs[Rmax+1-y]],
Dist=Dist+1];Break[];];p=Random[Integer,3];
If[p==0,x=x+1,
If[p==1,x=x-1,If[p==2,y=y+1,y=y-1]]];];];
Show[Graphics[Raster[A,{{0,0},{1,1}},
ColorFunction->Hue]]];

A.2

Logo

1. to heighway :depth :size :parity
if :depth=0 [forward :size stop]
left :parity*45
heighway :depth-1 :size*:factor 1
right :parity*90
heighway :depth-1 :size*:factor (-1)
left :parity*45
end
2. to ens :d :s
pu
left 120
forward :s
right 120
pd
make "p 1
Fractales.. M. Alfaro, M. Murillo, A. Soto.
c 2010 Revista digital MatemÃ¡tica, EducaciÃ³n e Internet (www.cidse.itcr.ac.cr/revistamate/)
Derechos Reservados 

79

80

PROGRAMAS

repeat 6 [sd :d :s (-:p) right 60 make "p :p*-1]
end
to SD :d :s :p
if :d=0*:p [forward :s stop]
left 60*:p
SD :d-1 :s/2 (:p)
right 60*:p
SD :d-1 :s/2 (-:p)
right 60*:p
SD :d-1 :s/2 (:p)
left 60*:p
end
3. to U :depth :size
if :depth=0 [forward :size stop]
left 30
U :depth-1 :size/2
penup
back :size/2
right 30
forward :size
right 60
back :size/4
pendown
V :depth-1 :size/4 left 60
end
to V :depth :size
if :depth=0 [forward :size stop]
left 90
U :depth-1 :size/2
penup
back :size/2
right 90
forward :size
right 120
back :size* (0.75)
pendown
V :depth-1 :size*(0.75) left 120
end
to POLVO :depth :size
make "P :depth
make "T :size
U :P :T
pu
fd 50
pd
V :P :T
end
end

PROGRAMAS

A.3

DraTEX

1. ------CONJUNTO DE CANTOR CLASICO-------\Draw(400pt,20pt)
\Define\Cantor(1){
\IF \GtInt(\I,0) \THEN
\I-1; \K*3; \Move(#1,0)
\Line(1,0)
\Scale(0.333,0.333)
\Move(-2,-\Val\K)
{\Cantor(-1)} \Cantor(1) \FI}
\I=6;\MoveTo(0,-.5)
\J=\I; \K=1; { \Cantor(0)}
\K=0;
\MoveTo(-.03,-.5)\MarkLoc(A)
\Do(1,\Val\J){\Text(--$C_{\Val\K}$--)\MoveToLoc(A)
\K+1\Move(0,-\Val\K) ;}
\EndDraw
2. -------DRAGON DE HEIGHWAY ------\Draw(40pt,40pt)
\Define\Heighway(1){
\IF \EqInt(#1,1) \THEN \J=45;\ELSE \J=-45;\FI
\IF \EqInt(\I,0) \THEN
\LineF(1)
\ELSE{ \I-1;
\Scale(0.7071,0.7071)
\Rotate(\Val\J)
{\Heighway(1)}\MoveF(1)\J*-2;\Rotate(\Val\J)
{\Heighway(-1)}\MoveF(1)\J*-2;\Rotate(\Val\J)
}\FI}
\RotateTo(90)
\I=0;\K=0;\MarkLoc(A)
\Do(1,2){\Do(1,4){{\Heighway(1)}
\K+1;\I=\K;
\Move(1.2,0)}\MoveTo(0,-1.5)}
\EndDraw
3. -------TRIANGULO DE SIERPINSKI ------\Draw(10pt,10pt)
\Define\TSirp(1){
\IF \GtInt(\I,0) \THEN
\I-1; \K+1;
\MarkLoc(A)
\LineF(10)\MarkLoc(B)
\Rotate(120)
\LineF(10)\MarkLoc(C)
Fractales.. M. Alfaro, M. Murillo, A. Soto.
c 2010 Revista digital MatemÃ¡tica, EducaciÃ³n e Internet (www.cidse.itcr.ac.cr/revistamate/)
Derechos Reservados 

81

82

PROGRAMAS

\Rotate(120)\LineF(10)
%\IF \GtInt(\K,\J) \THEN
\PaintQuad(A,A,B,C)\FI
\Rotate(120)\Scale(0.5,0.5)
{\TSirp(0)}\Move(5,8.660254)
{\TSirp(0)}\Move(5,-8.660254){\TSirp(0)} \FI }
\I=7;\J=\I;
\K=1;\TSirp(0)
\EndDraw

PROGRAMAS

83

BibliografÃ­a
[1] Ãlvarez, Milton & Macaya, Gabriel, Chaos game representation of nucleotide sequence, Memorias VI Congreso Internacional de BiomatemÃ¡ticas, 279-288, Costa Rica, (1993).
[2] Axelrod, R.,The evolution of cooperation, Basic Book, (1984).
[3] Barnsley, M. F., Fractals Everywhere, Academic Press, Inc. Second Edition, 1993.
[4] Barnsley, M. F., Fractal Image Compression, Notices of the American Mathematical Society,
Vol. 43, Num. 6, 657-662, (1996).
[5] Barnsley, Michael F.; Elton John H. & Hardin Douglas P., Recurrent Iterated Function Systems,
Constructive Approximation, Vol. 5, 3-31, (1989).
[6] Burde, Klaus, NumeraciÃ³n fraccionariaNumeraciÃ³n fraccionaria, InvestigaciÃ³n y Ciencia (EspaÃ±a), Num. 227, (1995).
[7] Castillo, Ileana, Bifurcaciones y caos en dos sistemas dinÃ¡micos, Memorias del V ECADIM, 4551, Liberia, Costa Rica. (1997).
[8] Crilly, A. J.; Earnshaw, R. A. & Jones, H., Fractals and Chaos, Springer-Verlag, New York,
1991.
[9] Edgar, Gerald A., Measure, Topology, and Fractal Geometry, Springer-Verlag, New York, 1990.
[10] Falconer, Kenneth, The Geometry of Fractal Sets, Cambridge University Press, 1985.
[11] Falconer, Kenneth, Fractal Geometry, John Wiley & Sons, England, 1990.
[12] FayÃ³, Alicia & CÃ¡nepa Ana. Entre el plano y el Espacio. La dimensiÃ³n Fractal con Cabri, en
Memorias del XVII encuentro de geometrÃ­a y V de aritmÃ©tica, Colombia, 2006.
[13] Feder, Jens, Fractals, Plenum Press, New York, 1988.
[14] Fisher, Yuval, Fractal Image Compression, Springer-Verlag, New York, 1994.
[15] Gantmacher, F.R., Matrices with non-negative elements, Chelsea, 1959.
[16] Gilbert, William J., Fractal Geometry Derived from Complex Bases, The Mathematical Intelligencer, Vol. 4, 78-86, (1982).
[17] Gilbert, William J., The Fractal Dimension of Sets Derived from Complex Bases, Canad. Math.
Bull., Vol. 29, 495-500, (1986).
[18] Goffinet, Daniel, Number Systems with a Complex Base: a Fractal Tool for Teaching Topology ,
American Mathematical Monthly, Vol. 98, Num. 3, 249-255, 1991.
[19] Halmos, Paul R., Measure Theory, Springer-Verlag, New York, 1974.
[20] Hamilton, W. D., The genetical evolution of social behaviour, J. Theory Biol., 1-52, (1964).
[21] Hart, John C., Fractal Image Compression and Recurrent Iterated Function Systems, IEEE Computer Graphics, Vol. 16, Num. 4, (1996).
[22] Jacquin, Arnaud E., Image Coding Based on a Fractal Theory of Iterated Contractive Image Transformations, IEEE Transactions on Image Processing, Vol. 1, Num. 1, 18-30, (1992).
[23] Jeffrey, H. J., Chaos game representation of gene structure, Nucl. Acids Res., Vol. 18, 2163-2170,
(1990).
[24] KÃ¡tay, I. & SzabÃ³, J., Canonical Number Systems for Complex Integers, Acta Sci. Math (Szeged,
HungrÃ­a), Vol. 37, 255-260, (1975).
[25] Kraft, Roger L., Whatâ€™s the Difference Between Cantor Sets, American Mathematical Monthly,
Vol. 101, Num. 7, (1993).
[26] Lambert, William, La Ubicuidad de los Monstruos, Ciencias MatemÃ¡ticas (Costa Rica), Vol. 1,
Num. 1, 21-28 (1990).
[27] Mandelbrot, Benoit B., Fractals Forms, Chance and Dimension, Freeman, San Francisco, 1977.

84

PROGRAMAS

[28] Mandelbrot, Benoit B., The Fractal Geometry of Nature, Freeman, New York, 1983.
[29] Mauldin, R. Daniel & Williams, S.C., Hausdorff Dimension in Graph Directed Constructions,
Trans. Amer.Math. Soc., 309, 811-829, (1988).
[30] May, Robert M., Necessity and Chance: Deterministic Chaos in Ecology and Evolution, Bull. of
the American Mathematical Society, Vol. 32, Num. 3, (1995).
[31] Maynard Smith, J., Evolution and the theory of games, Cambridge University Press, 1982.
[32] McWorter, William & Tazelaar, Jane M., Creating Fractals, Byte, Vol. 12, Num. 9, (1987).
[33] Meakin, P., Diffusion-controlled cluster formation in two, three, and four dimensions, Phys. Rev.
A., Vol. 27, Num. 1, 604-607, (1983).
[34] Meakin, P. & Tolman S., Diffusion-limitated aggregation, Proc. R. Soc. Lond., A. 423, 133-148,
(1989).
[35] Murillo T. Manuel & Soto A. Alberto. Sobre los Conjuntos de Cantor, Memorias del IV
ECADIM, Antigua, Guatemala. (1996).
[36] Murillo T. Manuel & Soto A. Alberto. Sobre Bases Complejas y Dragones, Memorias del V
ECADIM, Liberia, Costa Rica. (1997).
[37] Murillo T. Manuel & Soto A. Alberto. Sobre intersecciones, tamaÃ±o y prisioneros de los conjuntos
de Cantor, Revista del Profesor de MatemÃ¡tica, AÃ±o 3, Num. 1, pÃ¡g. 21-30, Chile, 1998.
[38] Murillo T. Manuel & Soto A. Alberto. Representaciones numÃ©ricas en bases complejas, Revista
del Profesor de MatemÃ¡tica, AÃ±o 4, Num. 1, pÃ¡g. 36-46, Chile, 1999.
[39] Murillo T. Manuel. Sobre la compresiÃ³n de imÃ¡genes y atractores de sistemas, Revista TecnologÃ­a
en Marcha, ITCR, Vol. 14, Num. 3, 2001.
[40] Murillo T. Manuel. Sobre fractales como atractores de sistemas, Revista MatemÃ¡tica, EducaciÃ³n
e Internet, ITCR, Vol. 3, Num. 1, 2002.
[41] Murillo T. Manuel & GonzÃ¡lez A. Fabio. TeorÃ­a de nÃºmeros, Editorial TecnolÃ³gica de Costa
Rica, 2006.
[42] Muthukumar, M., Mean field theory for diffusion-limited cluster formation, Phys. Rev. Lett., Vol.
52, 839-842, (1983).
[43] Nowak, M. & May, R.,The spatial dilemmas of evolution, Int. J. Bifurcation and Chaos, Vol. 3
Num. 1, 35-78, (1993).
[44] Peitgen, H.-O.; Saupe, D. & JÃ¼rgens, H., Chaos and Fractals: New Frontiers of Science, SpringerVerlag, New York, 1992.
[45] Pietronero, L.; Evertsz, C & Wiesmann, H., Scaling Properties of Growing Zone and Capacity of
Laplacian Fractals, Fractals in Physics, Amsterdam (Holanda) 159-163, (1986).
[46] Prosise, Jeff, A Look Inside Bitmap Files, PC Magazine, Vol. 15, Num. 21, 322-324, diciembre
3, (1996).
[47] Rudin, Walter, Real and Complex Analysis, McGraw-Hill, 1974.
[48] Sannami, Atsuro, An example of a regular Cantor set whose difference set is a Cantor set with
positive measure, Hokkaido Mathematical Journal (JapÃ³n), Vol. 21, 7-24, (1992).
[49] Sander, Leonard, Fractal Growth, Sci. Amer., Vol. 256, Num. 1, 82-88, (1987).
[50] Soto A. Alberto. El Fascinante TriÃ¡ngulo de SierpinÌski, Memorias del V ECADIM, Liberia,
Costa Rica. (1997).
[51] Willard, Stephen, General Topology, Addison-Wesley, 1970.
[52] Witten, T. A. & Sander, L. M., Diffusion-limitated aggregation: A kinetic critical phenomenon,
Phys. Rev. Lett., Vol. 47, Num. 19, 1400-1403, (1981).
[53] Witten, T. A. & Sander, L. M., Diffusion-limitated aggregation, Phys. Rev. B, Vol. 27, Num. 9,
5686-5697, (1983).

Indice

A

acotada, distorsiÃ³n, 1
acotado, crecimiento, 1
afÃ­n, aplicaciÃ³n, 2
aplicaciÃ³n contractiva, teorema de la, 3
arista, de un grafo, 17
arreglos, espacio de, 8
atractor, 3
autosemejante, conjunto, 2
autosemejanza, 1
Axelrod, 46

B

Barnsley, 54, 75
helecho de, 56
Bases numÃ©ricas,fraccionarias, 75

C

camino, 18
Cantor, 5
conjunto de, 5, 24, 28
Caos, juego del, 56
ciclo, 18
clopen, 30
Collage, teorema, 55
columpio, 49
CompresiÃ³n de imÃ¡genes, 54
compresiÃ³n, razÃ³n de, 55
condiciÃ³n de
HÃ¶lder, 1
Lipschitz, 1
MorÃ¡n, 38
conjunto
autosemejante, 2
invariante, 2
contractiva, lista, 2
cooperador, 46
corrimiento, funciÃ³n de, 15
crecimiento fractal, 61
cultivador, 49
curva de Koch, 65

D

Darwin, 45
delator, 46
Dilema del Prisionero, 45
dimensiÃ³n
de semejanza, 2
del grafo, 21
fractal, 33
Hausdorff, 33
inductiva pequeÃ±a, 30
direcciÃ³n, 8

E

Edgar G., 75

Eisenstein, fracciones de, 27
entropÃ­a, Ã­ndice de, 43
espacio
de arreglos, 8
de hileras, 14
mÃ©tricos, 1
espectral, radio, 20

F

Falconer, 64, 75
finita, medida, 31
Fisher, 54, 75
flecha, de un grafo, 17
fracciones de Eisenstein, 27
fractal, 35
crecimiento, 61
dimensiÃ³n, 33
fractales dinÃ¡micos, 52
fuertemente conectado, grafo, 18

G

grafo, 17
de Mauldin-Williams, 19
dimensiÃ³n del, 21

H

Hamilton, teorÃ­a de, 45
Hausdorf
mÃ©trica, 55
Hausdorff, 30
dimensiÃ³n, 33
mÃ©trica, 3
Heighway, 5
dragÃ³n de, 5, 14, 42
HÃ©lice, 49
hileras, 14
HÃ¶lder, condiciÃ³n de, 1

I

imÃ¡genes, compresiÃ³n de, 54
Ã­ndice de entropÃ­a, 43
invariante, conjunto, 2

K

KÃ¡tai, 26
KÃ¡tay, 75
Koch, curva de, 56, 65

L

lazo, 18
Lebesgue, medida de, 2
Lipschitz, condiciÃ³n de, 1
longitud, 18

M

Fractales.. M. Alfaro, M. Murillo, A. Soto.
85
c 2010 Revista digital MatemÃ¡tica, EducaciÃ³n e Internet (www.cidse.itcr.ac.cr/revistamate/)
Derechos Reservados 

86

INDICE

mÃ©trica Hausdorff, 3
Mandelbrot, 26, 61, 75
Mathematica, 67
Mauldin-Williams, grafo de, 19
May, Robert, 46
medida, 31
exterior, 31
mÃ©todos de compresiÃ³n, 54
modelo, aplicaciÃ³n, 16
multigrafo dirigido, 18

N

nodo, de un grafo, 17
Novak, Martin, 46

P

palabras, 14
Perron, nÃºmeros de, 20
Prisionero, Dilema del, 45
radio espectral, 20
razÃ³n de compresiÃ³n, 55

S

semejanza, 2
dimensiÃ³n de, 2
SierpinÌski, 5
triÃ¡ngulo de, 5, 11, 28, 56
sistema
iterado, 2
triÃ¡dico, 6
Sloan, Alan, 54
SzabÃ³, 26, 75

T

teorema
Collage, 55
de Heine-Borel, 7
de la aplicaciÃ³n contractiva, 3
teselaciÃ³n, 25
tremas, 5
Twindragon, 25

U

ultramÃ©trica, 15

V

vecindarios, 3
vÃ©rtice, de un grafo, 17

Sobre los autores

Manuel Alfaro Arias
Licenciado en matemÃ¡tica pura en la Universidad de Costa Rica. Profesor Asociado del Instituto
TecnolÃ³gico de Costa Rica.

Manuel Murillo Tsijli
Licenciado en matemÃ¡tica pura en la Universidad de Costa Rica y Master en EducaciÃ³n en la Universidad Americana. Profesor CatedrÃ¡tico del Instituto TecnolÃ³gico de Costa Rica y Profesor CatedrÃ¡tico de la Universidad Estatal a Distancia.

Alberto Soto Aguilar
Licenciado en matemÃ¡tica pura en la Universidad de Costa Rica. Profesor Asociado de la Universidad Estatal a Distancia.

87


